[
  {
    "id": 1,
    "year": 2026,
    "title": "Bridge: High-Order Taint Vulnerabilities Detection in Linux-based IoT Firmware",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00001",
    "abstract": " The rapid proliferation of IoT devices has led to a surge in security incidents stemming from vulnerabilities in firmware. IoT device security is critical, as failures can result in privacy breaches, system downtime, and life-threatening situations. While taint analysis has been a standard approach for detecting vulnerabilities, the increasing complexity of modern IoT devices has introduced high-order taint vulnerabilities that traditional methods cannot address. These vulnerabilities often require the coordination of multiple requests and components, making detection particularly challenging. This paper presents Bridge, a novel approach to detecting high-order taint vulnerabilities in IoT firmware. Bridge operates in three stages: identifying entry points (i.e., the initial handlers corresponding to different action requests) and taint source functions (i.e., functions for parsing user-controllable data), constructing binary dependency graphs for tainted data propagation, and constructing action dependency graphs to trace taint vulnerability triggering control relationships. Extensive evaluation on 44 real-world firmware samples demonstrates that Bridge outperforms state-of-the-art tools, detecting 1,168 true positive vulnerabilities including 566 high-order vulnerabilities. Moreover, among the results, 90 vulnerabilities (including 45 high-order vulnerabilities) have been confirmed by vendors (CVE/PSV) and pose a threat to device security, including remote code execution and denial of service. ",
    "status": "notchecked"
  },
  {
    "id": 2,
    "year": 2026,
    "title": "Camveil: Unveiling Security Camera Vulnerabilities through Multi-Protocol Coordinated Fuzzing",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00002",
    "abstract": " Security cameras are widely deployed in safety-critical environments, supporting real-time video streaming and device control via protocols such as RTSP, ONVIF, and HTTP. Vulnerabilities in these systems can lead to frozen video feeds or surveillance failures, potentially resulting in property or safety losses. While fuzzing is a useful technique for discovering vulnerabilities, existing protocol and IoT fuzzers typically treat each protocol independently, overlooking the cross-protocol dependencies present in real-world cameras. To address this gap, we propose CAMVEIL, a fuzzing framework designed to uncover vulnerabilities in security cameras through multi-protocol coordinated fuzzing. The key insight is that certain protocols can modify the internal state of the camera, indirectly affecting the behavior of other protocols, making some vulnerabilities only discoverable through state-dependent, cross-protocol interaction. To exercise such interactions, CAMVEIL builds a protocol-aware camera status model that abstracts internal camera states and defines their dependencies across protocols. Guided by this model, CAMVEIL generates coordinated test sequences to explore interleaved protocol behaviors. Additionally, it integrates a logic-aware monitoring component that continuously analyzes response packets to detect semantic inconsistencies or abnormal control flows. Using this approach, CAMVEIL has discovered 22 previously unknown vulnerabilities across 9 industrial camera models from Hikvision, Honeywell, TP-Link, FOSCAM, EZVIZ, and Santachi. These flaws could allow attackers to disrupt live video streams or disable camera functionality, potentially causing critical surveillance failures. ",
    "status": "notchecked"
  },
  {
    "id": 3,
    "year": 2026,
    "title": "Agentic Concolic Execution",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00003",
    "abstract": " Concolic execution is a practical test generation technique that explores execution paths by coupling concrete execution with symbolic reasoning. It runs programs on given inputs while capturing symbolic path representations, then mutates and solves these constraints to generate new test inputs for alternative paths. This approach has several fundamental challenges, such as (C1) the inherent complexity of symbolically modeling diverse programming language constructs and environmental interactions, and (C2) the scalability issues of constraint solvers when handling large, complex formulas. In this work, we investigate whether LLM agents can help address these longstanding challenges in test generation. We propose a novel workﬂow which we call agentic concolic execution. Using an LLM agent for symbolization, our approach is language-agnostic and can handle environmental constraints without additional manual modeling effort. To ease pressure on the constraint solver, we allow an LLM agent to summarize and even reason about constraints directly in natural language. In a significant evaluation of 12 real-world subjects, our research prototype ConcoLLMic attains significantly higher code coverage (115%-233% higher) than state-of-the-art symbolic executors like KLEE that have been painstakingly hand-crafted over many years, and identifies 11 new vulnerabilities. Our results show that multi-step planning and tool integration enable agents to effectively mitigate reliability issues inherent in LLM-based analysis and even reason symbolically about code. ",
    "status": "notchecked"
  },
  {
    "id": 4,
    "year": 2026,
    "title": "Concretely-Efficient Multi-Key Homomorphic Secret Sharing and Applications",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00004",
    "abstract": " Homomorphic secret sharing (HSS) is a powerful cryptographic primitive that enables efficient, low-communication secure computation without the use of fully homomorphic encryption. Public-key HSS is a well-known variant that supports inputs from multiple parties, but all parties must agree on a joint public key before any party can encode their inputs, requiring extra rounds of communication in applications. Recently, Couteau et al. (EUROCRYPT 2025) constructed multi-key HSS (MKHSS)---a new primitive which allows parties to encode their inputs under independent keys---under the DCR assumption. MKHSS assumes only a reusable common reference string, without the need for prior interactions between parties or a public-key infrastructure. In this paper, we construct and implement the first concretely-efficient MKHSS scheme under the same assumptions used by Couteau et al. Using an algorithmic insight that reduces the largest modulus in Couteau et al. from N^4 to N^2, our optimized implementation can homomorphically multiply inputs in 5.0 milliseconds---while an implementation of Couteau et al. requires 224.6 milliseconds---thereby achieving a 45x speedup. A powerful application of MKHSS is to realize attribute-based non-interactive key exchange (ANIKE), which generalizes the password-authenticated key exchange (PAKE) to arbitrary attribute policies. ANIKE is currently only known from MKHSS. We use our implementation to evaluate the first concretely-efficient ANIKE schemes for a range of practically useful policies. Using our implementation, two parties can perform a geolocation-based key exchange in under one second and a fuzzy PAKE on an 8-word passphrase in a few seconds for realistic parameters, on a single core, achieving a roughly 30x speedup over Couteau et al. for both applications. ",
    "status": "notchecked"
  },
  {
    "id": 5,
    "year": 2026,
    "title": "\"I Wonder if These Warnings Are Accurate\": Security and Privacy Advice in Nine Majority World Countries",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00005",
    "abstract": " Security and privacy (S&P) advice plays a crucial role in how people stay safe online. While prior work shows that the plethora of advice from varied sources makes it difficult for users to prioritize advice, the insights are primarily based on studies conducted in Western contexts. Other work shows that users outside the West have different S&P needs and thus, we cannot simply rely on advice curated in the West to generalize to the majority world—regions of Africa, Asia, Latin America, and the Middle East, where most of the world’s population lives. We fill this gap by investigating S&P advice across nine majority world countries via 70 semi-structured interviews with local experts: cybercafe operators, tech repair specialists, and other community figures that people commonly rely on for tech support and S&P advice. We find that the advice provided by local experts in the majority world largely matches the advice they provide to their constituents and the advice from the West. However, we surface various significant barriers that hinder majority world users from implementing advice, including economic constraints, language barriers, and social friction from taking protective measures. Our findings further show how factors such as social norms and gender shape advice practices, e.g., by driving gendered advice-seeking. We discuss how S&P advice in the majority world can be improved and reflect on how the S&P community can better engage with local communities in conducting similar research. ",
    "status": "notchecked"
  },
  {
    "id": 6,
    "year": 2026,
    "title": "Practical Multi-party Private Set Intersection with Reducible Zero-sharing",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00006",
    "abstract": " Multi-party Private Set Intersection (mPSI) enables $n(n\\geq3)$ parties, each holding a set of size $m$, to jointly compute their intersection while preserving the confidentiality of each set, which is essential for privacy-preserving data analysis and secure database queries. Existing mPSI protocols have limitations in achieving both sufficient security and practical efficiency. This paper presents a novel and efficient mPSI construction in the semi-honest model while resisting arbitrary collusion attacks. Our construction works in the offline/online paradigm. Given the corruption threshold $t$, the online phase achieves linear total computational and communication complexity, that is $O((n+t)m)$, and solely uses symmetric operations. This makes our construction theoretically outperform the existing works. The technical core of the construction is our newly extracted primitive called reducible zero-sharing, which allows $t(t ",
    "status": "notchecked"
  },
  {
    "id": 7,
    "year": 2026,
    "title": "Leafblower: a Leakage Attack Against TEE-Based Encrypted Databases",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00008",
    "abstract": " Trusted execution environments (TEEs) have emerged as a common solution for database systems to provide encryption in use. Several encrypted databases (EDBs) have been deployed within TEEs using library operating system toolchains that transparently allow existing applications to run within TEEs without modification. This \"lift-and-shift\" paradigm greatly simplifies the design of EDBs but leaves open questions about the security of the resulting system. In this work, we propose a new leakage attack against TEE-based EDBs which use B+-trees in the multi-snapshot external memory model, a weaker adversary which only observes snapshots of the encrypted database index files after each operation. We show how to approximately order insertions by their inserted value by exploiting the \"structural leakage\" of the on-disk index format. Then, we leverage auxiliary information to recover the approximate plaintext values of insert operations with significant advantage over a naive adversary that makes guesses based on equivalent auxiliary information. Under optimal conditions—when the auxiliary is accurate and the domain is small—we achieve up to 96% exact recovery in experiments on real-world datasets which increases to 100% when scoped to later operations in the transcript. Our attack requires no injections and no information about read operations. While our work is primarily motivated by TEE-based encrypted databases, we demonstrate that our attack generalizes to other kinds of page-level encryption systems including encrypted storage engines and disaggregated database systems. ",
    "status": "notchecked"
  },
  {
    "id": 8,
    "year": 2026,
    "title": "Mechanized Safety and Liveness Proofs for the Mysticeti Consensus Protocol under the LiDO-DAG Framework",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00009",
    "abstract": " Directed acyclic graphs (DAG) have recently become a popular building block for high-throughput consensus protocols used in blockchains. Mysticeti is a state-of-the-art DAG-based consensus protocol that is currently deployed in the Sui blockchain and the IOTA blockchain. Compared to previous protocols, Mysticeti achieves lower commit latency by eliminating reliable broadcast and increasing leader vertex frequency. However, this comes at the cost of significantly more complex security proofs than previous protocols. In fact, shortly after Mysticeti was published, flaws were found in its liveness proof, leaving the correctness of the protocol uncertain. In this work, we resolve the controversy around correctness of Mysticeti by presenting the first complete analysis of the safety and liveness properties of Mysticeti. Our key finding is that, unlike previous DAG-based protocols like Narwhal and Bullshark, liveness of Mysticeti is highly sensitive to the round-jumping behavior of honest participants. If honest processes are allowed to jump over rounds arbitrarily, then we present an explicit counterexample to the liveness of Mysticeti: an infinite trace where no data blocks are ever committed. We then introduce a simple restriction on the round-jumping behavior, and show that our modification is sufficient to restore liveness of Mysticeti. We mechanized proofs of safety and liveness of Mysticeti under the LiDO-DAG framework, an abstract model of DAG-based consensus protocols proposed by Qiu et al., confirming that our modified protocol is fully correct. We also audited the current implementation of Mysticeti in the Sui blockchain and found it is susceptible to the described liveness bug. We have contacted Mysten Labs and are working with them to fix the liveness issues. ",
    "status": "notchecked"
  },
  {
    "id": 9,
    "year": 2026,
    "title": "C-Verifier: Understanding and Formally Verifying Cross-Service Flaws in AWS Cognito",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00010",
    "abstract": " Managed cloud‑identity services issue short‑lived credentials so that mobile and web clients can access storage, database, and serverless APIs without passing through application servers. These services are layered on top of a security‑token engine and an account‑wide policy system, yet prior work has examined each layer in isolation. We present the first end‑to‑end analysis of this multi‑plane workflow, using Amazon Cognito as a representative case. Treating Cognito, the Security Token Service and IAM as a single security graph, we (i) provide the first in‑depth security analysis of session‑bypass risk and (ii) uncover two additional design flaws that allow users to exploit overly permissive or divergent trust policies and to assume ``hanging'' roles left behind after reconfiguration. A crawl of 844 Cognito‑backed Android apps reveals these flaws in 179 deployments, affecting at least 1.7 million users. To detect such drift automatically, we build C-Verifier, a tool that converts an account snapshot into Satisfiability Modulo Theories formulas spanning all three control planes and checks five security properties. C-Verifier yields precise counter‑examples, outperforms four state‑of‑the‑art tools, and analyzes 400 identity pools with 1,400 roles in under 40s. We release both the tool and a curated benchmark, Cognito Configuration Bench, to facilitate reproducible cross‑service policy research. ",
    "status": "notchecked"
  },
  {
    "id": 10,
    "year": 2026,
    "title": "SmuFuzz: Enable Deep System Management Mode Fuzzing in Fully Featured UEFI Runtime Environment",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00011",
    "abstract": " As part of the UEFI standard, System Management Mode (SMM) was introduced on x86 processors to handle critical hardware events. With strict access control to this operating mode, SMM applications run at a high privilege level (known as Ring -2), in which they have (almost) unlimited access to system resources. However, vendors commonly use memory-unsafe system programming languages to develop SMM applications, which makes them vulnerable to memory corruption and an appealing target for attackers. Fuzzing is an effective method for detecting memory corruption vulnerabilities across a wide range of applications. Unfortunately, existing approaches for testing SMM applications lack a UEFI runtime environment to properly support SMM application execution. Without this environment, application data is often not correctly initialized. Once such uninitialized data is accessed during fuzzing, it causes premature exits or unintentional crashes. As a result, existing methods can only explore shallow parts and often produce high false-positive rates. In this paper, we propose SmuFuzz, a fuzzing framework designed to detect vulnerabilities in closed-source SMM applications distributed by vendors. SmuFuzz overcomes prior limitations by partially rehosting SMM applications within a custom infrastructure that provides a fully featured UEFI runtime environment. This infrastructure provides the necessary dependencies and runtime for SMM application preparation, initialization, and finalization. In addition, SmuFuzz automatically infers the complex SMM application input semantics for deep exploration. In our experiment, SmuFuzz achieved 4.45x higher unique basic block coverage compared to state-of-the-art fuzzers. It also found more vulnerabilities while significantly reducing false positives. Using SmuFuzz, we identified 38 new vulnerabilities in firmware from major vendors, all of which were disclosed responsibly. ",
    "status": "notchecked"
  },
  {
    "id": 11,
    "year": 2026,
    "title": "Audience Injection Attacks: A New Class of Attacks on Web-Based Authorization and Authentication Standards",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00116",
    "abstract": " We introduce audience injection attacks, a novel class of vulnerabilities that impact widely used Web-based authentication and authorization protocol standards, including OAuth 2.0, OpenID Connect, FAPI, CIBA, the Device Authorization Grant, and various well-established extensions, such as Pushed Authorization Requests, Token Revocation, Token Introspection, and their numerous combinations. These protocols underpin services for billions of users across diverse ecosystems worldwide, spanning low-risk applications like social logins to high-risk domains such as open banking, insurance, and healthcare. Audience injection attacks exploit a critical weakness in a core security mechanism of these standards – the handling of so-called audiences in signature-based client authentication mechanisms. This vulnerability allows attackers to compromise fundamental security objectives whenever these mechanisms are utilized across two or more server endpoints. They enable the attacker to impersonate users and gain unauthorized access to their resources, even in high-security protocol families specifically designed for sensitive applications. We responsibly disclosed these vulnerabilities to the relevant standardization bodies, which recognized their severity. In collaboration with these organizations, we developed fixes and supported a coordinated response, leading to an ongoing effort to update a dozen standards. ",
    "status": "notchecked"
  },
  {
    "id": 12,
    "year": 2026,
    "title": "The Threat Landscape of IP Leasing in the RPKI Era",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00012",
    "abstract": " Short-term IPv4 leasing is on the rise, allowing address owners (lessors) to rent out spare address blocks to lessees who rely on them for critical operations. Yet under existing RPKI practices, the lessor remains the recognized authority, retaining full control over the ROAs needed to validate BGP announcements. This paper uncovers how such arrangements fundamentally clash with the assumptions of route origin validation: even after leasing out an address block, the lessor can unilaterally invalidate the lessee's announcements, causing RPKI-enforcing ASes to drop or redirect traffic. We show that a malicious lessor can leverage RPKI to covertly hijack a leased prefix by feeding \"lease-compliant\" ROAs to select relying parties while presenting \"rogue\" ROAs to the rest of the Internet. Through experiments on two major cloud platforms and the PEERING testbed, spanning multiple continents, we confirm that these attacks can reroute leased-prefix traffic with little visibility to the lessee or standard monitoring tools. We further illustrate scenarios in which a rogue lessor intercepts TLS certificate validation or executes region-specific hijacks, highlighting the severity of such threats. Finally, we propose practical mitigations, including multi-RP ROA verification, delegating ROA authority to neutral brokers, and adopting partial delegation in RIR portals. By exposing the interplay between IP leasing and RPKI, we aim to spur both policy reforms and technical advancements that strengthen routing security in the face of ever-growing address shortages. ",
    "status": "notchecked"
  },
  {
    "id": 13,
    "year": 2026,
    "title": "Fine-Grained Kernel Auditing using Augmented Syscall Reference Behavior Analysis and Virtualized Selective Tracing",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00013",
    "abstract": " Audit logs are widely used for attack investigation in enterprises, but their granularity (system calls and related events) is too coarse-grained to be useful for attack forensics when adversaries launch advanced kernel exploits. Such exploits manipulate kernel memory to hijack kernel control-flow, and these aspects (i.e., the executed anomaly control flows and their capabilities) are not visible in today's audit logs. Appare is an auditing framework designed to comprehensively and efficiently capture sophisticated in-memory kernel exploit behaviors. Appare implements anomalous control-flow logging, where it leverages an augmented hybrid approach to (a) dynamically profile representative system call workloads, and (b) generalize the profiles by using LLM-assisted code semantics reasoning to differentiate reference (benign) and anomalous function executions within the kernel. Appare uses efficient hardware tracing techniques to record anomaly control flow behaviors, as well as the historical contexts to reveal where control flow divergences (hijacking) happen. Appare leverages virtualization extensions and features available in modern architectures to achieve end-to-end tamper-proof logging, persistence, and management. Our analysis and evaluation show that Appare effectively captures attack behaviors in the exploits we analyzed, while incurring a geometric mean slowdown of only 2.0% across diverse programs. ",
    "status": "notchecked"
  },
  {
    "id": 14,
    "year": 2026,
    "title": "Privacy Perspectives and Practices of Chinese Smart Home Product Teams",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00014",
    "abstract": " Previous research has explored the privacy needs and concerns of device owners, primary users, and different bystander groups with regard to smart home devices like security cameras and smart speakers, but little is known about the privacy views and practices of smart home product teams, particularly those in non-Western contexts. This paper presents findings from 27 semi-structured interviews with Chinese smart home product team members. We examine their privacy perspectives, practices, and risk mitigation strategies. Our results show that participants emphasized compliance with Chinese data privacy laws, which typically prioritized national security over individual privacy rights. China-specific cultural, social, and legal factors also influenced participants' ethical considerations and attitudes toward balancing user privacy and security with convenience. Drawing on our findings, we propose a set of recommendations for smart home product teams, along with socio-technical and legal interventions to address smart home privacy issues---especially those belonging to at-risk groups---in Chinese multi-user smart homes. ",
    "status": "notchecked"
  },
  {
    "id": 15,
    "year": 2026,
    "title": "Defeating Transient Execution Attacks by Limiting Secret Reachability through Register Hiding and ShadowCFI",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00015",
    "abstract": " Modern processors incorporate aggressive branch prediction mechanisms for indirect branches, offering various unanticipated ways to influence speculative behavior during a transient execution attack. Existing mitigations against these so-called Spectre v2-style attacks are often ad-hoc, highly specific to the discovered attack and the targeted microarchitecture, and thus fail to generalize. In this paper, we identify a core requirement previously overlooked that all of these attacks share: secret reachability. Building upon this, we propose REGISTER HIDING and SHADOWCFI, two complementary but independent software-based and hardware-agnostic techniques which target the attacker’s ability to reach secrets in registers and memory. REGISTER HIDING hides the architectural register state before a misprediction can occur, while SHADOWCFI ensures the architectural register state can only be restored at the correct target. To demonstrate their merit, we implement a fully functional patch for Linux kernel version 6.8.0, protecting against known and futuristic Spectre v2-style attacks, including all those which target indirect jumps, indirect calls and returns. We provide a security analysis and corresponding scanner to verify that an attacker cannot restore the register state during misprediction in our proof-of-concept. Replacing the most recently deployed Spectre v2 defenses with REGISTER HIDING and SHADOWCFI reduces the overall mitigation overhead on AMD Zen 4 from 114.1% to 75.9% for LEBench, and from 33.4% to 25.8% on average across server workloads. ",
    "status": "notchecked"
  },
  {
    "id": 16,
    "year": 2026,
    "title": "APIEcho: Training-less Anomaly Detection via Intra-API Behavioral Comparison for Web Applications",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00016",
    "abstract": " Anomaly detection is crucial for web application security, yet existing methods like rule-based validation and learning-based models face significant limitations. Rule-based systems struggle with novel attacks, while learning-based approaches require frequent, costly retraining to adapt to dynamic application updates, often leading to high false positives. While recent self-comparison methods address retraining by comparing replicas in microservice scenarios, they are ill-suited for monolithic applications due to functional heterogeneity, offer coarse-grained detection, lack adaptive comparison baselines, and are vulnerable to coordinated poisoning. This paper presents APIEcho, a novel web server intrusion detection method for monolithic applications that operates without large-scale pre-training. APIEcho's core insight is that legitimate requests to the same API endpoint exhibit highly similar underlying behavioral patterns. Our system shifts the comparison granularity from replicas to individual requests within the same API, employing dynamic API classification, fine-grained behavioral feature extraction (including sequential and set-based features), per-API adaptive similarity thresholds, and an anti-poisoning sliding window update mechanism. Extensive evaluations on 16 real-world scenarios demonstrate that APIEcho significantly outperforms state-of-the-art methods. It effectively adapts to application updates without retraining, resists coordinated poisoning attacks, surpasses existing methods in average detection score, and achieves attack recall rates exceeding 90% while maintaining benign event detection accuracy above 99%, all with low overhead, processing more than 12000 log events per second with less than 7GB memory consumption. ",
    "status": "notchecked"
  },
  {
    "id": 17,
    "year": 2026,
    "title": "Searching for a Farang: Collective Security among Women in Pattaya, Thailand",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00017",
    "abstract": " We report on two months of ethnographic fieldwork in a women's centre in Pattaya, and interviews with 76 participants. Our findings, as they relate to digital security, show how (i) women in Pattaya, often working in the sex and massage industries, perceived relationships with farang men as their best, and sometimes only, option to achieve security; (ii) the strategies used by the women to appeal to a farang involved presenting themselves online, mirroring how they were being advertised by bar owners to attract customers; (iii) appealing to what they considered `Western ideals', the women sought out `Western technologies' and appropriated them for their benefit; (iv) the women navigated a series of online security risks, such as scams and abuse, which shaped their search for a farang; (v) the women developed collective security through knowledge-sharing to protect themselves and each other in their search for a farang. We situate our work in emerging digital security scholarship within marginalised contexts. ",
    "status": "notchecked"
  },
  {
    "id": 18,
    "year": 2026,
    "title": "Towards Automating Data Access Permissions in AI Agents",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00018",
    "abstract": " As AI agents attempt to autonomously act on users' behalf, they raise transparency and control issues. We argue that permission-based access control is indispensable in providing meaningful control to the users, but conventional permission models are inadequate for the automated agentic execution paradigm. We therefore propose automated permission management for AI agents. Our key idea is to conduct a user study to identify the factors influencing users' permission decisions and to encode these factors into an ML-based permission management assistant capable of predicting users' future decisions. We find that participants' permission decisions are influenced by communication context but importantly individual preferences tend to remain consistent within contexts, and align with those of other participants. Leveraging these insights, we develop a permission prediction model achieving 85.1% accuracy overall and 94.4% for high-confidence predictions. We find that even without using permission history, our model achieves an accuracy of 66.9%, and a slight increase of training samples (i.e., 1–4) can substantially increase the accuracy by 10.8%. ",
    "status": "notchecked"
  },
  {
    "id": 19,
    "year": 2026,
    "title": "Single-server Stateful PIR with Verifiability and Balanced Efficiency",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00019",
    "abstract": " Recent stateful private information retrieval (PIR) schemes have significantly improved amortized computation and amortized communication while aiming to keep client storage minimal. However, all the schemes in the literature still suffer from a poor tradeoff between client storage and computation. We present BALANCED-PIR, a stateful PIR scheme that effectively balances computation and client storage. For a database consisting of 2^20 entries, each of 8 bytes, our scheme requires 0.2 MB of client storage, 0.2 ms of amortized computation, and 11.14 KB of amortized communication. Compared with the state-of-the-art scheme using a similar storage setting, our scheme is 8.9 times better in amortized computation and 39 times better in offline computation. Verifiable private information retrieval has been gaining more attention recently. However, all existing schemes require linear amortized computation and huge client storage. We present Verifiable BALANCED-PIR, a verifiable stateful PIR scheme with sublinear amortized computation and small client storage. In fact, our Verifiable BALANCED-PIR adds modest computation, communication, and storage costs on top of BALANCED-PIR. Compared with the state-of-the-art verifiable scheme, the client storage of our scheme is 100 times smaller, the amortized computation is 15 times faster, and the amortized communication is 2.5 times better. ",
    "status": "notchecked"
  },
  {
    "id": 20,
    "year": 2026,
    "title": "Parasol Compiler: Pushing the Boundaries of FHE Program Efficiency",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00020",
    "abstract": " Fully Homomorphic Encryption (FHE) is a key technology to enable privacy-preserving computation. While optimized FHE implementations already exist, the inner workings of FHE are technically complex. This makes it challenging, especially for non-experts, to develop highly-efficient FHE programs that can exploit the advanced hardware of today. Although several compilers have emerged to help in this process, due to design choices, they are limited in terms of application support and the efficiency levels they can achieve. In this work, we showcase how to make FHE accessible to non-expert developers while retaining the performance provided by an expert-level implementation. We introduce Parasol, a novel end-to-end compiler encompassing a virtual processor with a custom Instruction Set Architecture (ISA) and a low-level library that implements FHE operations. Our processor integrates with existing compiler toolchains, thereby providing mainstream language support. We extract parallelism at multiple levels via our processor design and its computing paradigm. Specifically, we champion a Circuit Bootstrapping (CBS)-based paradigm, enabling efficient FHE circuit composition with multiplexers. Furthermore, Parasol's underlying design highlights the benefits of expressing FHE computations at a higher level–producing highly compact program representations. Our experiments demonstrate the superiority of Parasol, in terms of runtime (up to 17x faster), program size (up to 22x smaller), and compile time (up to 32x shorter) compared to the current state-of-the-art. We expect the FHE computing paradigm underlying Parasol to attract future interest since it exposes added parallelism for FHE accelerators to exploit. ",
    "status": "notchecked"
  },
  {
    "id": 21,
    "year": 2026,
    "title": "Zelda: Efficient Multi-server Preprocessing PIR with Unconditional Security",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00021",
    "abstract": " Private Information Retreival~(PIR) schemes without preprocessing are known to incur linear server computation per client query. Several recent works have shown that by relying on a one-time preprocessing phase, we can get around this barrier, and achieve sublinear computation per query without relying on any cryptographic assumptions. Beimel et al. (CRYPTO'00) first showed a family of schemes whose bandwidth and computation per query scale as fast as $n^{O(1/S)}$ where $S$ denotes the number of servers and $n$ denotes the database size. Unfortunately, their schemes are not practical partly because the servers must each store an encoded version of the database, and the encoding length grows sharply as we increase $S$. The recent work of Singh et al. (TCC'24) showed how to achieve similar bandwidth scaling but without the server space blowup. To get this, they rely on a different type of preprocessing called client-specific preprocessing, where the stateful client stores some hints and the servers store only the original database. Unfortunately, Singh et al.'s result is completely impractical due to the reliance on Dvir and Gopi's PIR as a building block. We propose Zelda (short for ZEro-Leakage Data Access), the {\\it first} concretely efficient, information-theoretic multi-server PIR scheme with sublinear computation. Our work makes both theoretical and practical contributions. On the theoretical front, we devise a unified framework for constructing multi-server PIR with client-specific preprocessing. This gives us a parametrizable family of schemes that asymptotically outperform all prior constructions in the same setting, including Singh et al. (TCC'24) and Ishai et al. (CRYPTO'24). On the practical front, Zelda is conceptually simple, self-contained, and does not rely on any underlying PIR as a building block. We implemented Zelda and open sourced our code. We compared the concrete performance of Zelda with a state-of-the-art PIR scheme called QuarterPIR (Eurocrypt'24), which relies on pseudorandom functions for security. Experimental results show that Zelda outperforms QuarterPIR in terms of online response time and client space (assuming typical fiber optical links), at the price of increased costs for offline maintenance operations. ",
    "status": "notchecked"
  },
  {
    "id": 22,
    "year": 2026,
    "title": "No Password, No Problem? A Large-Scale Field Study of Passkey Adoption and Usage",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00022",
    "abstract": " Passkeys were introduced to mitigate password-related security risks. However, passwords remain prevalent, and the usability of synchronization, one of the core benefits of passkeys, has not yet been studied. To address this gap, we conducted a large-scale field study examining passkey adoption and usage by partnering with an industrial healthcare service. In Phase 1 (n=5,057), users chose between a passkey and a password with 2FA during registration. We reveal that (especially inexperienced) users struggle with passkey adoption but still perceive passkeys to offer superior usability and acceptance. Our survey results identified novel reasons why users decline passkeys, notably the habit of using passwords and lack of passkey experience, and pinpointed adoption barriers, including new misconceptions and manual passkey activation. In Phase 2 (n=2,716), we monitored authentication behavior over six months and captured immediate feedback through surveys. We found that passkey usability and acceptance continued to increase, and success rates surpassed the declining metrics of passwords. Still, we uncovered new issues with cross-platform synchronization, passkey sharing, and interactions with password managers. Finally, we provide recommendations to streamline the adoption and usability of passkeys. ",
    "status": "notchecked"
  },
  {
    "id": 23,
    "year": 2026,
    "title": "Usable Anonymity in Reproductive Health Privacy",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00023",
    "abstract": " Anonymity is a key strategy for internet users to manage privacy and mitigate data surveillance risks. While tools like Tor support strong anonymity, they are often inaccessible to non-technical users, who instead rely more on platforms' built-in privacy features to seek anonymity. However, the usability of these features remains underexplored. This study focuses on period and fertility tracking (PFT) apps as a research context due to heightened privacy concerns about reproductive health surveillance, which intensify users' need for usable privacy designs to achieve anonymity. We conducted usability testing with 32 participants across six PFT apps, revealing that the usability of anonymity-preserving features (APFs) significantly influences users' privacy perceptions. We identified key usability challenges, such as a lack of transparency regarding APFs and unintuitive processes for avoiding disclosure of personally identifiable information (PII). To address these issues, we propose recommendations for more accessible and usable anonymity in online platforms. ",
    "status": "notchecked"
  },
  {
    "id": 24,
    "year": 2026,
    "title": "Verifiable PIR with Small Client Storage",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00024",
    "abstract": " Efficient Verifiable Private Information Retrieval (vPIR) protocols, and more generally Verifiable Linearly Homomorphic Encryption (vLHE), suffer from high client storage. VeriSimplePIR (USENIX Security 2024), the state-of-the art vPIR protocol, requires clients to persistently maintain over 1 GiB of local storage to privately access an 8 GiB remote database. We present a new vPIR protocol that reduces the client state by orders of magnitude while preserving online latency. In our protocol, clients only need to store 512 KiB for an 8 GiB database, achieving a 2000x improvement. Our vPIR protocol is built over our new vLHE scheme. Unlike VeriSimplePIR, our scheme doesn’t use random oracles and relies only on standard lattice assumptions - (R)LWE and SIS. These improvements come at a 2.5x cost in server throughput over VeriSimplePIR. Despite this throughput overhead, we achieve a comparable online latency to VeriSimplePIR by implementing several optimizations including query-level preprocessing. We also introduce the notion of covert vPIR (cvPIR), where stateful clients enjoy full vPIR security, while even stateless clients benefit from covert security against a malicious server. ",
    "status": "notchecked"
  },
  {
    "id": 25,
    "year": 2026,
    "title": "WebCloak: Characterizing and Mitigating Threats from LLM-Driven Web Agents as Intelligent Scrapers",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00025",
    "abstract": " The rise of web agents powered by large language models (LLMs) is reshaping the landscape of human-computer interaction, enabling users to automate complex web tasks with natural language commands. However, this progress introduces significant, yet largely unexplored security concerns: adversaries can employ such web agents to conduct largescale web scraping, particularly of visual content. This paper presents the first systematic characterization of the danger represented by such LLM-driven web agents as intelligent scrapers. We develop LLMCrawlBench, a large test set of 237 extracted real-world webpages (10,895 images) from 50 popular high-traffic websites in 5 critical categories, designed specifically for adversarial image extraction evaluation. Our metrics across over 32 scraper implementations, including LLM-to-Script (L2S), LLM-Native crawlers (LNC), and LLM-based web agents (LWA), demonstrate that while some tools exhibit working issues, advanced LLM-powered frameworks lower the bar for effective scraping. Such new agent-as-attacker threats motivate us to introduce WebCloak, an effective, lightweight defense that specifically targets the main weakness of LLM crawler agents' fundamental \"Parse-then-Interpret\" mechanism. Our key idea is dual-layered: (1) Dynamic Structural Obfuscation, which not only randomizes structural cues but also restores visual content client-side using non-traditional methods less amenable to direct LLM exploitation, and (2) Optimized Semantic Labyrinth to mislead the central LLM interpretation of the agent through added harmless-yet-misleading contextual clues, all while not sacrificing visual quality for legitimate users. Our evaluations demonstrate that WebCloak significantly reduces scraping recall rates from 88.7% to 0% against leading LLM-driven scraping agents, offering a robust and practical countermeasure. ",
    "status": "notchecked"
  },
  {
    "id": 26,
    "year": 2026,
    "title": "The Secrets Must Not Flow: Scaling Security Verification to Large Codebases",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00026",
    "abstract": " Existing program verifiers can prove advanced properties about security protocol implementations, but are difficult to scale to large codebases because of the manual effort required. We develop a novel methodology called *Diodon* that addresses this challenge by splitting the codebase into the protocol implementation (the *Core*) and the remainder (the *Application*). This split allows us to apply powerful semi-automated verification techniques to the security-critical Core, while fully-automatic static analyses scale the verification to the entire codebase by ensuring that the Application cannot invalidate the security properties proved for the Core. The static analyses achieve that by proving *I/O independence*, i.e., that the I/O operations within the Application are independent of the Core's security-relevant data (such as keys), and that the Application meets the Core's requirements. We have proved Diodon sound by first showing that we can safely allow the Application to perform I/O independent of the security protocol, and second that manual verification and static analyses soundly compose. We evaluate Diodon on two case studies: an implementation of the signed Diffie-Hellman key exchange and a large (100k+ LoC) production Go codebase implementing a key exchange protocol for which we obtained secrecy and injective agreement guarantees by verifying a Core of about 1% of the code with the auto-active program verifier Gobra in less than three person months. ",
    "status": "notchecked"
  },
  {
    "id": 27,
    "year": 2026,
    "title": "Toward Inclusive Security and Privacy for Deaf and Hard-of-Hearing People: A Community-Based Interview Study",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00027",
    "abstract": " About 5% of the world’s population experience disabling hearing loss. Nevertheless, deaf and hard-of-hearing (DHH) communities remain an understudied and underserved population in security and privacy (S&P) research. We conducted 24 semi-structured interviews with DHH participants (n=17) and their supporters (n=7) in Germany to explore (1) how DHH people perceive S&P risks in assistive technologies, (2) concerns about disclosing their identity and sharing sign language content online, and (3) sources of advice and common challenges. Our findings highlight participants’ limited awareness of S&P risks in assistive hearing devices and limited interest in sign language video anonymization tools. DHH participants expressed concerns about identity disclosure— whether voluntary, involuntary, or mediated by third parties— and found existing S&P mechanisms and resources largely inaccessible. As a result, they often relied on trusted networks for support. While supporters were generally willing to help, their limited S&P knowledge, social dynamics within the DHH community, and translation challenges between spoken and sign languages hindered effective information sharing. Our research provides implications for researchers, industry practitioners, and policymakers to develop more effective and inclusive S&P tools and resources for DHH communities. ",
    "status": "notchecked"
  },
  {
    "id": 28,
    "year": 2026,
    "title": "VerfCNN, Optimal Complexity zkSNARK for Convolutional Neural Networks",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00028",
    "abstract": " With the widespread deployment of machine learning services, concerns about potential misconduct by service providers have emerged. Providers may deviate from their promised methodologies when delivering their services, undermining customer trust. Zero-knowledge proofs (ZKPs) offer a promising solution for customers to verify service integrity while preserving the intellectual property of the model weights. However, existing ZKP systems for convolutional neural networks (CNNs) impose significant computational overhead on the prover, hindering their practical deployment. To address this challenge and facilitate real-world deployment of ZKPs for CNNs, we introduce VerfCNN, a novel and efficient ZKP system for CNN inference. The core innovation of VerfCNN lies in a specialized protocol for proving multi-channel convolutions, achieving optimal prover complexity that matches the I/O size of the convolution. Our design significantly reduces the prover overhead for verifiable CNN inference. Experiments on VGG-16 demonstrate that our system achieves a prover time of just 12.6 seconds, offering a 6.7× improvement over zkCNN (CCS'21). Remarkably, VerfCNN incurs only a 10× overhead compared to plaintext inference on CPU, whereas general-purpose zkSNARKs typically impose overheads exceeding 1000×. These results underscore VerfCNN's strong potential to enhance the integrity and transparency of real-world ML services. ",
    "status": "notchecked"
  },
  {
    "id": 29,
    "year": 2026,
    "title": "Scalable Accountable Byzantine Agreement and Beyond",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00029",
    "abstract": " No $t$-resilient Byzantine Agreement (or Reliable Broadcast) protocol can guarantee agreement among $n$ correct processes in a non-synchronous network if the actual number of faulty processes $f$ is $\\geq n - 2t$. This limitation highlights the need to augment such fragile protocols with mechanisms that detect safety violations, such as forensic support and accountability. This paper introduces simple and efficient techniques to address this challenge by proposing a new generic transformation, $\\mathcal{ABC}^{++}$. The transformation leverages two key primitives: the \\emph{ratifier} and the \\emph{propagator}. By sequentially composing these primitives with any closed-box Byzantine Agreement (or Reliable Broadcast) protocol, $\\mathcal{ABC}^{++}$ produces a robust counterpart that provides both (adaptively-secure) forensic support and ($1$-delayed adaptively-secure) accountability. The transformation incurs a subquadratic additive communication overhead, with only $1$ round of overhead for decision and forensic support, and $2$ additional rounds for detection in case of a safety violation (or $O\\big(\\log n \\big)$ additional rounds with optimized communication). The generality of $\\mathcal{ABC}^{++}$ offers a compelling general alternative to the subquadratic forensic support solution by Sheng et al. (FC'23) tailored to HotStuff-like protocols, while being more efficient than the (strongly-adaptively-secure) quadratic $\\mathcal{ABC}$ accountable transformation (IPDPS'22, JPDC'23). Moreover, it provides the first subquadratic accountable Byzantine Agreement (or Reliable Broadcast) protocols against a ($1$-delayed) adaptive adversary. Finally, any subquadratic accountable Reliable Broadcast protocol can be integrated into the $\\tau_{scr}$ transformation (ICDCS'22) to produce an improved variant, $\\tau_{scr}^{++}$. This new version compiles any deterministic (and even beyond) protocol into its accountable counterpart with subquadratic multiplicative communication overhead, significantly improving upon the original quadratic overhead in $\\tau_{scr}$. ",
    "status": "notchecked"
  },
  {
    "id": 30,
    "year": 2026,
    "title": "Revelio: Blurred Images Can Still Disclose Your Identity",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00030",
    "abstract": " Gaussian blur is widely used to blur human faces in sensitive photos before the photos are posted on the Internet. However, it is unclear to what extent the blurred faces can be restored and used to re-identify the person, especially under a high-blurring setting. In this paper, we explore this question by developing a deblurring method called Revelio. The key intuition is to leverage a generative model's memorization effect and approximate the inverse function of Gaussian blur for face restoration. Compared with existing methods, we design the deblurring process to be identity-preserving. It uses a conditional Diffusion model for preliminary face restoration and then uses an identity retrieval model to retrieve related images to further enhance fidelity. We evaluate Revelio with large public face image datasets and show that it can effectively restore blurred faces, especially under a high-blurring setting. It has a re-identification accuracy of 95.9%, outperforming existing solutions. The result suggests that Gaussian blur should not be used for face anonymization purposes. We also demonstrate the robustness of this method against mismatched Gaussian kernel sizes and functions, and test preliminary countermeasures and adaptive attacks to inspire future work. ",
    "status": "notchecked"
  },
  {
    "id": 31,
    "year": 2026,
    "title": "RIS-CLA: Reviving CSI-Based Continuous Location Authentication with Reconfigurable Intelligent Surfaces",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00031",
    "abstract": " Continuous Location Authentication (CLA) enables seamless verification of the physical locations of networked devices. While wireless Channel State Information (CSI)-based CLA schemes are attractive due to their passive and infrastructure compatible design, recent studies have exposed critical vulnerabilities to CSI-guessing attacks, limiting their applicability in high-security environments. We propose RIS-CLA, a novel system that leverages Reconfigurable Intelligent Surfaces (RISs) to enable secure and autonomous CSI-based CLA. By dynamically reconfiguring the wireless propagation environment through RIS control codewords, RIS-CLA induces unpredictable, device-specific CSI variations that adversaries cannot easily guess or replicate. The system addresses three key challenges—codeword ambiguity, robustness to channel dynamics, and multi-device scalability—through a suite of techniques including codeword optimization, contrastive learning-based classification, explainable-AI-guided model fine-tuning, and a joint multi-device authentication framework. Extensive prototype-based experiments demonstrate that RIS-CLA effectively mitigates CSI-guessing attacks and achieves robust CLA performance under diverse conditions. ",
    "status": "notchecked"
  },
  {
    "id": 32,
    "year": 2026,
    "title": "Blinding Post-Quantum Hash-and-Sign Signatures",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00032",
    "abstract": " Blind signature schemes are essential for privacy-preserving applications such as electronic voting, digital currencies or anonymous credentials. In this paper, we revisit Fischlin's framework for round-optimal blind signature schemes and its recent efficient lattice-based instantiations. Our proposed framework compiles any post-quantum hash-and-sign signature scheme into a blind signature scheme. The resulting scheme ensures blindness by design and achieves one-more unforgeability, relying solely on the unforgeability of the underlying signature scheme and the random oracle model. To achieve this we introduce the notion of commit-append-and-prove (CAP) systems, which generalizes traditional commit-and-prove system by making their commitments updatable before proving. This building block allows us to unlock the technical challenges encountered when generalizing previous variants of the Fischlin's framework to any hash-and-sign signature scheme. We provide efficient CAP system instantiations based on recent MPC-in-the-Head techniques. We showcase our framework by constructing blind versions of UOV and Wave, thereby introducing the first practical blind signatures based on multivariate cryptography and code-based cryptography. Our blind UOV signatures range from 3.8 KB to 11 KB, significantly outperforming previous post-quantum blind signatures, such as the 22 KB lattice-based blind signatures, which were the most compact until now. ",
    "status": "notchecked"
  },
  {
    "id": 33,
    "year": 2026,
    "title": "Practical Asynchronous Distributed Key Reconfiguration and Its Applications",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00033",
    "abstract": " In this paper, we study practical constructions of asynchronous distributed key reconfiguration (ADKR), which enables an asynchronous fault-tolerant system with an existing threshold cryptosystem to efficiently generate a new threshold cryptosystem for a reconfigured set of participants. While existing asynchronous distributed threshold key generation (ADKG) protocols theoretically solve ADKR, they fail to deliver satisfactory scalability due to cubic communication overhead, even with simplifications to the reconfiguration setting. We introduce an efficient \\textit{share-dispersal-then-agree-and-recast} paradigm for constructing efficient ADKR while preserving adaptive security. Our method reduces the total overhead to $O(\\kappa n^2)$ from $O(n^3)$, where $\\kappa$ is a small constant (typically $\\approx$30 or less). And our further optimizations in PVSS minimize redundant computations across different parties and reduce the dominating PVSS verification cost by about one-third. Our techniques developed for ADKR can also be leveraged to improve the asymptotic efficiency of various other asynchronous protocols: (i) it implies the first (coin-assisted) quadratic-communication ADKG; and (ii) it can be extended to realize the first quadratic-communication asynchronous dynamic proactive secret sharing (APSS) with adaptive security. Experimental evaluations on a global network of 256 AWS servers show up to 40% lower latency compared to the state-of-the-art ADKG protocols that are simplified to the reconfiguration setting, highlighting the practicality of our ADKR in large-scale asynchronous systems. ",
    "status": "notchecked"
  },
  {
    "id": 34,
    "year": 2026,
    "title": "PORTGPT: Towards Automated Backporting Using Large Language Models",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00034",
    "abstract": " Patch backporting, the process of migrating mainline security patches to older branches, is an essential task in maintaining popular open-source projects (e.g., Linux kernel). However, manual backporting can be labor-intensive, while existing automated methods, which heavily rely on predefined syntax or semantic rules, often lack agility for complex patches.Patch backporting, the process of migrating mainline security patches to older branches, is an essential task in maintaining popular open-source projects (e.g., Linux kernel). However, manual backporting can be labor-intensive, while existing automated methods, which heavily rely on predefined syntax or semantic rules, often lack agility for complex patches. In this paper, we introduce PORTGPT, an LLM-agent for end-to-end automation of patch backporting in real-world scenarios. PORTGPT enhances an LLM with tools to access code on-demand, summarize Git history, and revise patches autonomously based on feedback (e.g., from compilers), hence, simulating human-like reasoning and verification. PORTGPT achieved an 89.15% success rate on existing datasets (1815 cases), and 62.33% on our own dataset of 146 complex cases, both outperforms state-of-the-art of backporting tools. We contributed 9 backported patches from PORTGPT to the Linux kernel community and all patches are now merged. ",
    "status": "notchecked"
  },
  {
    "id": 35,
    "year": 2026,
    "title": "AEX-NStep: Probabilistic Interrupt Counting Attacks on Intel SGX",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00035",
    "abstract": " To mitigate interrupt-based stepping attacks (notably using SGX-Step), Intel introduced AEX-Notify, an ISA extension to Intel SGX that aims to prevent deterministic single-stepping. In this work, we introduce AEX-NStep, the first interrupt counting attack on AEX-Notify-enabled Enclaves. We show that deterministic single-stepping is not required for interrupt counting attacks to be practical and that, therefore, AEX-Notify does not entirely prevent such attacks. We specifically show that one of AEX-Notify's security guarantees, obfuscated forward progress, does not hold, and we introduce two new probabilistic interrupt counting attacks. We use these attacks to construct a practical ECDSA key leakage attack on an AEX-Notify-enabled SGX enclave. Our results extend the original security analysis of AEX-Notify and inform the design of future mitigations. ",
    "status": "notchecked"
  },
  {
    "id": 36,
    "year": 2026,
    "title": "Behind the Curtain: How Shared Hosting Providers Respond to Vulnerability Notifications",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00036",
    "abstract": " Large-scale vulnerability notifications (VNs) can help hosting provider organizations (HPOs) identify and remediate security vulnerabilities that attackers can exploit in data breaches or phishing campaigns. Previous VN studies have primarily focused on factors under the control of reporters, such as sender reputation, email formatting, and communication channels. Despite these efforts, remediation rates for vulnerability notifications continue to remain consistently low. This paper presents the first in-depth study of how HPOs process vulnerability notifications internally and what organizational and operational factors influence VN effectiveness. We examine the problem from a different perspective to provide the first detailed understanding of the reasons behind persistently low remediation rates. Instead of manipulating parameters of VN campaigns, we interview hosting providers directly, investigating how they handle vulnerability notifications and what factors may influence VN effectiveness, such as VN awareness and reachability, HPOs’ service models, and perceived security risks. We conducted semi-structured interviews with 24 HPOs across shared hosting and web development services, representing varied company sizes and operator roles. Our findings reveal practical insights on VN processing and abuse workflows. While some providers remain hard to reach due to complex infrastructures, most report routinely handling VNs. However, limited remediation often stems from strict responsibility boundaries, where web application issues are seen as the customer's domain. Low hosting fees and high volumes of daily compromises further discourage both proactive and reactive measures. Our findings show that HPOs blame negligent website owners, and prior works on website owners confirms they often undervalue their sites or lack security know-how. This misalignment raises further concerns about the efficacy of current VN approaches and whether they can reliably prompt remedial action under the existing operational model. ",
    "status": "notchecked"
  },
  {
    "id": 37,
    "year": 2026,
    "title": "LLM Unlearning Should Be Form-Independent",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00037",
    "abstract": " Large Language Model (LLM) unlearning aims to erase or suppress undesirable knowledge within the model, offering promise for controlling harmful or private information to prevent misuse. However, recent studies highlight its limited efficacy in real-world scenarios, hindering practical adoption. In this study, we identify a pervasive issue underlying many downstream failures: the effectiveness of existing unlearning methods heavily depends on the form of training samples and frequently fails to generalize to alternate expressions of the same knowledge. We formally characterize this problem as Form-Dependent Bias and systematically investigate its specific manifestation patterns across various downstream tasks. To quantify its prevalence and support future research, we introduce ORT, a novel benchmark designed to evaluate the robustness of unlearning methods against variations in knowledge expression. Results reveal that Form-Dependent Bias is both widespread and severe among current techniques. We argue that LLM unlearning should be form-independent to address the endless forms of downstream tasks encountered in real-world security-critical scenarios. Towards this goal, we introduce Rank-one Concept Redirection (ROCR), a novel training-free method, as a promising solution path. ROCR performs unlearning by targeting the invariants in downstream tasks, specifically the activated dangerous concepts. It is capable of modifying model parameters within seconds to redirect the model's perception of a specific unlearning target concept to another harmless concept. Extensive experiments demonstrate that ROCR significantly improves unlearning effectiveness compared to traditional methods while generating highly natural outputs. ",
    "status": "notchecked"
  },
  {
    "id": 38,
    "year": 2026,
    "title": "Generate-then-Verify: Reconstructing Data from Limited Published Statistics",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00038",
    "abstract": " We study the problem of reconstructing tabular data from aggregate statistics, in which the attacker aims to identify interesting claims about the sensitive data that can be verified with 100% certainty given the aggregates. Successful attempts in prior work have conducted studies in settings where the set of published statistics is rich enough that entire datasets can be reconstructed with certainty. In our work, we instead focus on the regime where many possible datasets match the published statistics, making it impossible to reconstruct the entire private dataset perfectly (i.e., when approaches in prior work fail). We propose the problem of partial data reconstruction, in which the goal of the adversary is to instead output a subset of rows and/or columns that are guaranteed to be correct. We introduce a novel integer programming approach that first generates a set of claims and then verifies whether each claim holds for all possible datasets consistent with the published aggregates. We evaluate our approach on the housing-level microdata from the U.S. Decennial Census release, demonstrating that privacy violations can still persist even when information published about such data is relatively sparse. ",
    "status": "notchecked"
  },
  {
    "id": 39,
    "year": 2026,
    "title": "MusicShield: Protection for Musicians in the Era of Generative AI",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00039",
    "abstract": " Recent advancements in music-generative AI systems pose a growing threat to professionals in the music production industry. These models learn from large datasets, often scraping publicly available music, and can edit, remix, and replicate an artist's signature style without their consent. In this paper, we introduce MusicShield, a tool that enables musicians to apply \"music shields\" to their work before public release. These shields introduce subtle imperceptible perturbations to the audio signal, preventing generative models from learning or generating new music based on the artist's work. While recent work (e.g., HarmonyCloak) focuses primarily on making music unlearnable to disrupt AI training, MusicShield not only prevents AI from training on music but also thwarts editing and manipulation, with improved scalability, lower computational cost, and better cross-model transferability. To evaluate MusicShield, we conducted user studies with 470 music professionals and enthusiasts to assess its effectiveness, usability, and perceptual tolerability, as well as their views on AI-driven music editing. Additionally, our quantitative evaluations across four state-of-the-art generative models (i.e., MusicLM, MusicGen, Jasco, and Riffusion) demonstrate its robustness and broad applicability. Our analysis shows that MusicShield withstands varied conditions and adaptive countermeasures while remaining lightweight and cost-efficient. User study results, together with quantitative metrics, confirm that MusicShield provides a practical and reliable solution for blocking unauthorized AI learning and editing in the generative AI era. ",
    "status": "notchecked"
  },
  {
    "id": 40,
    "year": 2026,
    "title": "Breaking the Illusion: Automated Reasoning of GDPR Consent Violations",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00040",
    "abstract": " Recent privacy regulations such as the General Data Protection Regulation (GDPR) and the California Consumer Privacy Act (CCPA) have established legal requirements for obtaining user consent regarding the collection, use, and sharing of personal data. These regulations emphasize that consent must be informed, freely given, specific, and unambiguous. However, there are still many violations, which highlight a gap between legal expectations and actual implementation. Consent mechanisms embedded in functional web forms across websites play a critical role in ensuring compliance with data protection regulations such as the GDPR and CCPA, as well as in upholding user autonomy and trust. However, current research has primarily focused on cookie banners and mobile app dialogs. These forms are diverse in structure, vary in legal basis, and are often difficult to locate or evaluate, creating a significant challenge for automated consent compliance auditing. In this work, we present Cosmic, a novel automated framework for detecting consent-related privacy violations in web forms. Cosmic integrates three key innovations: (1) a large language model (LLM)-based framework to extract consent requirements from privacy policies and locate relevant forms using multimodal web agents; (2) a domain-specific language (DSL) to formally describe heterogeneous web form structures, enabling systematic analysis; and (3) machine-interpretable Datalog rules, derived in collaboration with privacy experts, to translate natural-language GDPR requirements into formal logic for automated verification. We evaluate our developed tool for auditing consent compliance in web forms, across 5,823 websites and 3,598 forms. Cosmic detects 3,384 violations on 94.1% of consent forms, covering key GDPR principles such as freely given consent, purpose disclosure, and withdrawal options. It achieves 98.6% and 99.1% TPR for consent and violation detection, respectively, demonstrating high accuracy and real-world applicability. ",
    "status": "notchecked"
  },
  {
    "id": 41,
    "year": 2026,
    "title": "Towards Practical Zero-Knowledge Proof for PSPACE",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00041",
    "abstract": " Efficient zero-knowledge proofs (ZKPs) have been restricted to NP statements so far, whereas they exist for all statements in PSPACE. This work presents the first practical zero-knowledge (ZK) protocols for PSPACE-complete statements by enabling ZK proofs of QBF (Quantified Boolean Formula) evaluation. The core idea is to validate quantified resolution proofs (\\qres) in ZK. We develop an efficient polynomial encoding of Q-RES proofs, enabling proof validation through low-overhead arithmetic checks. We also design a ZK protocol to prove knowledge of a winning strategy related to the QBF, which is often equally important in practice. We implement our protocols and evaluate them on QBFEVAL. The results show that our protocols can verify 72% of QBF evaluations via Q-RES proof and 82% of instances' winning strategies within 100 seconds, for instances where such proofs or strategies can be obtained. ",
    "status": "notchecked"
  },
  {
    "id": 42,
    "year": 2026,
    "title": "Investigating the Impact of Dark Patterns on LLM-Based Web Agents",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00042",
    "abstract": " As users increasingly turn to large language model (LLM) based web agents to automate online tasks, agents may encounter dark patterns: deceptive user interface designs that manipulate users into making unintended decisions. Although dark patterns primarily target human users, their potentially harmful impacts on LLM-based generalist web agents remain unexplored. In this paper, we present the first study that investigates the impact of dark patterns on the decision-making process of LLM-based generalist web agents. To achieve this, we introduce LiteAgent, a lightweight framework that automatically prompts agents to execute tasks while capturing comprehensive logs and screen-recordings of their interactions. We also present TrickyArena, a controlled environment comprising web applications from domains such as e-commerce, streaming services, and news platforms, each containing diverse and realistic dark patterns that can be selectively enabled or disabled. Using LiteAgent and TrickyArena, we conduct multiple experiments to assess the impact of both individual and combined dark patterns on web agent behavior. We evaluate six popular LLM-based generalist web agents across three LLMs and discover that when there is a single dark pattern present, agents are susceptible to it an average of 41% of the time. We also find that modifying dark pattern UI attributes through visual design changes or HTML code adjustments and introducing multiple dark patterns simultaneously can influence agent susceptibility. This study emphasizes the need for holistic defense mechanisms in web agents, encompassing both agent-specific protections and broader web safety measures. ",
    "status": "notchecked"
  },
  {
    "id": 43,
    "year": 2026,
    "title": "Ensemble Conformal Predictor (EnCP): A New Conformal Predictor with Robustness Guarantees against Data Poisoning Attacks",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00043",
    "abstract": " Conformal Prediction (CP) is a popular statistical framework for uncertainty quantification by producing prediction sets with valid coverage guarantees (e.g., ensuring the true label falls within the predicted set with a user-defined confidence level such as 95%). It has recently gained popularity in both classical machine learning (ML) tasks (e.g., image classification) and large language model (LLM) applications (e.g., toxic content classification). However, recent works show CP is vulnerable to adversarial attacks in both the learning and inference phases, affecting its reliability in real-world applications. While several studies investigated defenses against inference-phase attacks, the threat of learning-phase (particularly data poisoning) attacks remains largely under-explored. We take the first step towards developing a provably robust CP framework (called EnCP) against data poisoning attacks, by addressing critical challenges including the sensitivity of the ML model and conformal predictor to poisoned data and the difficulty of maintaining both valid coverage and moderate prediction set size under the attack. Our EnCP is inspired by ensemble learning and can inherently bound the effect of poisoned samples on CP’s coverage and prediction set, enabling us to derive the certified coverage and certified prediction set size. Our results demonstrate strong robustness of EnCP on both image classification benchmarks and LLM for toxicity text classification, showing that EnCP preserves both high coverage and compact prediction sets under data poisoning attacks. Source code is available at: https://github.com/Yuxin104/EnCP. ",
    "status": "notchecked"
  },
  {
    "id": 44,
    "year": 2026,
    "title": "Exploiting Leaderboards for Large-Scale Distribution of Poisoned Models",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00044",
    "abstract": " While poisoning attacks on machine learning models have been extensively studied, the mechanisms by which adversaries can distribute poisoned models at scale remain largely unexplored. We identify model leaderboards---trusted platforms for model discovery and evaluation---as powerful yet vulnerable distribution channels. Through comprehensive analysis, we expose how adversaries can exploit leaderboard mechanisms to artificially inflate rankings of poisoned models, leading to widespread adoption by unsuspecting users. We present TrojanClimb, a general framework that enables stealthy injection of malicious behaviors while maintaining competitive leaderboard performance across four modalities: text-to-speech, text-embedding, text-to-image, and text-generation. Our findings point to the need to redesign leaderboard evaluation mechanisms to detect and filter compromised models, while highlighting broader security implications for the machine learning community regarding the risks of adopting models from unvetted sources. ",
    "status": "notchecked"
  },
  {
    "id": 45,
    "year": 2026,
    "title": "PromoGuardian: Detecting Promotion Abuse Fraud with Multi-Relation Fused Graph Neural Networks",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00045",
    "abstract": " As e-commerce platforms develop, fraudulent activities are increasingly emerging, posing significant threats to the security and stability of these platforms. Promotion abuse is one of the fastest-growing types of fraud in recent years and is characterized by users exploiting promotional activities to gain financial benefits from the platform. To investigate this issue, we conduct the first study on promotion abuse fraud in e-commerce platforms MEITUAN. We find that promotion abuse fraud is a group-based fraudulent activity with two types of fraudulent activities: Stocking Up and Cashback Abuse. Unlike traditional fraudulent activities such as fake reviews, promotion abuse fraud typically involves ordinary customers conducting legitimate transactions and these two types of fraudulent activities are often intertwined. To address this issue, we propose leveraging additional information from the spatial and temporal perspectives to detect promotion abuse fraud. In this paper, we introduce PROMOGUARDIAN, a novel multi-relation fused graph neural network that integrates the spatial and temporal information of transaction data into a homogeneous graph to detect promotion abuse fraud. We conduct extensive experiments on real-world data from MEITUAN, and the results demonstrate that our proposed model outperforms state-of-the-art methods in promotion abuse fraud detection, achieving 93.15% precision, detecting 2.1 to 5.0 times more fraudsters, and preventing 1.5 to 8.8 times more financial losses in production environments. ",
    "status": "notchecked"
  },
  {
    "id": 46,
    "year": 2026,
    "title": "VMSCAPE: Exposing and Exploiting Incomplete Branch Predictor Isolation in Cloud Environments",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00046",
    "abstract": " Virtualization is a cornerstone of modern cloud infrastructures, providing the required isolation to customers. This isolation, however, is threatened by speculative execution attacks which the CPU vendors attempt to mitigate by extending the isolation to the branch predictor state. Our systematic analysis shows that this extension unfortunately is incomplete: while the most obvious case of the guest controlling branch prediction in the host has been addressed by existing hardware mitigations, we discover a number of new Spectre Branch Target Injection (Spectre-BTI) attack primitives on AMD Zen 1-5 and Intel Coffee Lake CPUs that, among others, enable a malicious guest to control indirect branch prediction in the host when it is executing in userspace. Using the aforementioned primitive, we craft VMScape, the first Spectre-BTI attack that enables a malicious KVM guest to leak arbitrary memory from an unmodified QEMU process running on an AMD Zen 5 server system at the speed of 154 B/s, exposing cryptographic keys for disk encryption and decryption. Our analysis of possible mitigation strategies shows that it is possible to mitigate VMScape by selectively flushing the branch predictor with minimal performance impact in common scenarios. ",
    "status": "notchecked"
  },
  {
    "id": 47,
    "year": 2026,
    "title": "GHost in the SHELL: A GPU-to-Host Memory Attack and Its Mitigation",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00047",
    "abstract": " Modern heterogeneous computing platforms increasingly unify CPU and GPU address spaces for improved programmability and performance. To this end, recent Linux kernels and NVIDIA GPU drivers adopt Heterogeneous Memory Management (HMM), which allows GPU kernels to directly access host memory. While this simplifies development, it may introduce a critical security risk. In this paper, we expose a new attack surface introduced by HMM and present GHOST-ATTACK, the first GPU-originated exploitation technique capable of compromising host process memory. By exploiting memory-safety bugs in GPU kernels or executing attacker-supplied kernels, GHOST-ATTACK enables attackers to bypass Address Space Layout Randomization (ASLR) and hijack control flow in widely used applications such as PyTorch and Chrome. To counter this threat, we further propose SHELL (Secure HMM Enforcement with LLVM), a practical defense that restores memory isolation between GPU and host in HMM enabled systems. SHELL statically identifies shared memory regions and enforces fine-grained access control at runtime using the GPU driver’s page-fault mechanism. We implement SHELL by modifying Clang/LLVM and the open-source NVIDIA GPU driver. Our evaluation demonstrates that SHELL effectively blocks all variants of GHOST-ATTACK with negligible performance overhead, preserving the security, compatibility, and performance benefits of HMM. ",
    "status": "notchecked"
  },
  {
    "id": 48,
    "year": 2026,
    "title": "Euston: Efficient and User-Friendly Secure Transfomer Inference with Non-Interactivity",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00048",
    "abstract": " Secure TransFormer Inference (STFI) frameworks have been proposed to address privacy concerns over user inputs and model parameters in Transformer-based LLMs.While most existing solutions rely on interactive protocols that incur substantial user-server communication overhead, non-interactive STFI variants have recently emerged to eliminate such dependencies. Nevertheless, state-of-the-art non-interactive STFI frameworks still suffer from critical limitations. (i) Large ciphertext sizes and multiple rotations alongside heavy user-side overhead in Homomorphic Matrix Multiplication (HMM). (ii) High approximation costs and depth consumptions in Homomorphic Nonlinear Evaluations (HNE). To address these limitations, we present Euston, an efficient and user-friendly STFI with non-interactivity. By combining RNS-CKKS fully homomorphic encryption with optimized methods, Euston achieves unprecedented efficiency in offline-online inference paradigm. The key innovations are twofold. (i) For linear operations, we adopt Singular Value Decomposition (SVD) with our novel batched HMMs to minimize ciphertext size and reduce rotation counts, simultaneously lowering user-side computational, communication and storage overhead. (ii) For nonlinear operations, we employ column(diagonal)-packed ciphertext matrix formats to eliminate costly rotations and depth regulation strategies to reduce depth consumption in non-interactive HNEs, which not only avoids user-server communications but also accelerates inference performance. In comparision with the state-of-the-art approach (NEXUS, NDSS 2025), Euston achieves up to 3100× lower preprocessing costs for the user and 8.8× higher system-wide inference performance, specifically delivering a 90× speedup for HMM and a 165.7× speedup for HNE. Our results demonstrate that Euston establishes new efficiency frontiers for user-friendly STFI deployment across cloud and edge environments. ",
    "status": "notchecked"
  },
  {
    "id": 49,
    "year": 2026,
    "title": "zkFuzz: Foundation and Framework for Effective Fuzzing of Zero-Knowledge Circuits",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00049",
    "abstract": " Zero-knowledge (ZK) circuits enable privacy-preserving computations and are central to many cryptographic protocols. Systems like Circom simplify ZK development by combining witness computation and circuit constraints in one program. However, even small errors can compromise security of ZK programs -- under-constrained circuits may accept invalid witnesses, while over-constrained ones may reject valid ones. Static analyzers are often imprecise with high false positives, and formal tools struggle with real-world circuit scale. Additionally, existing tools overlook several critical behaviors, such as intermediate computations and program aborts, and thus miss many vulnerabilities. Our theoretical contribution is the Trace-Constraint Consistency Test (TCCT), a foundational, language-independent formulation of ZK circuit bugs. TCCT provides a unified semantics that subsumes prior definitions and captures both under- and over-constrained vulnerabilities, exposing the full space of ZK bugs that elude prior tools. Our systems contribution is zkFuzz, a novel program mutation-based fuzzing framework for detecting TCCT violations. zkFuzz systematically mutates the computational logic of Zk programs guided by a novel fitness function, and injects carefully crafted inputs using tailored heuristics to expose bugs. We evaluated zkFuzz on 452 real-world ZK circuits written in Circom, a leading programming system for ZK development. zkFuzz successfully identified 85 bugs, including 59 zero-days-39 of which were confirmed by developers and 14 fixed, including bugs undetectable by prior works due to their fundamentally limited formulations, earning thousands of bug bounties. Our preliminary research on Noir, another emerging DSL for ZK circuit, also demonstrates the feasibility of zkFuzz to support multiple DSLs. ",
    "status": "notchecked"
  },
  {
    "id": 50,
    "year": 2026,
    "title": "No Honor Among Crooks: Non-transferable Anonymous Tokens from Betrayability",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00050",
    "abstract": " In anonymous token protocols, clients obtain access tokens by proving eligibility for the usage of a resource and later get access to the resource by redeeming the token. The server verifying eligibility and providing the resource cannot link the token issuance to its redemption. To prevent ineligible clients from accessing resources, it is crucial to prevent the transfer or sale of tokens. Durak et al. (CCS'24) propose binding tokens to valuable insurance secrets, which must be known to redeem the tokens. The value of the insurance secret deters the vendor from transferring the secret to the token buyer, who cannot redeem the token without the secret. However, the authors do not consider scenarios, where the token vendor assists the buyer during token redemption. Their construction, therefore, falls short to guarantee non-transferability when facing a vendor-aided token redemption. We address this gap by introducing the concept of \\emph{anonymous tokens with betrayability}. Our notion ensures that a token buyer, that is able to redeem a bought token, either knows the insurance secret or is able to betray the vendor in a vendor-aided redemption. The betrayal allows the buyer to steal the insurance secret without being detected. This way, we make the support in the token redemption equivalent to a transfer of the insurance secret and, hence, inherit the transfer deterrence of the insurance secret even when considering a vendor-aided token redemption. We formalize our new security notion, present a protocol for anonymous tokens with betrayability, prove its security, and provide an implementation and experimental evaluation. ",
    "status": "notchecked"
  },
  {
    "id": 51,
    "year": 2026,
    "title": "Setting the Course, but Forgetting to Steer: Analyzing Compliance with GDPR’s Right of Access to Data by Instagram, TikTok, and YouTube",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00051",
    "abstract": " The GDPR’s Right of Access aims to empower users with control over their personal data via Data Download Packages (DDPs). However, their effectiveness is often compromised by inconsistent platform implementations, questionable data reliability, and poor user comprehensibility. This paper conducts a comprehensive audit of DDPs from three social media platforms (TikTok, Instagram, and YouTube) to systematically assess these critical drawbacks. Despite offering similar services, we find that these platforms demonstrate significant inconsistencies in implementing the Right of Access, evident in varying levels of shared data. Critically, the failure to disclose processing purposes, retention periods, and other third-party data recipients serves as a further indicator of non-compliance. Our reliability evaluations, using bots and user-donated data, reveal that while TikTok’s DDPs offer more consistent and complete data, others exhibit notable shortcomings. Similarly, our assessment of comprehensibility, based on surveys with 400 participants, indicates that current DDPs substantially fall short of GDPR’s standards. To improve the comprehensibility, we propose and demonstrate a two-layered approach by: (1) enhancing the data representation itself using stakeholder interpretations; and (2) incorporating a user-friendly extension (Know Your Data) for intuitive data visualization where users can control the level of transparency they prefer. Our findings underscore the need for clearer and non-conflicting regulatory guidance, stricter enforcement, and platform commitment to realize the goal of GDPR’s Right of Access. ",
    "status": "notchecked"
  },
  {
    "id": 52,
    "year": 2026,
    "title": "Battering RAM: Low-Cost Interposer Attacks on Confidential Computing via Dynamic Memory Aliasing",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00052",
    "abstract": " Confidential computing, powered by trusted execution environments (TEEs) like Intel SGX/TDX and AMD SEV-SNP, is now widely available from major cloud providers. At the core of these technologies is hardware-level memory encryption to protect against privileged attackers and physical threats such as bus snooping and cold boot attacks. Recent extensions add access-control checks to defend against software-based ciphertext manipulation and aliasing attacks. In this work, we challenge the protection modern memory encryption technologies offer against physical adversaries by building a low-cost ( ",
    "status": "notchecked"
  },
  {
    "id": 53,
    "year": 2026,
    "title": "Who Taught the Lie? Responsibility Attribution for Poisoned Knowledge in Retrieval-Augmented Generation",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00053",
    "abstract": " Retrieval-Augmented Generation (RAG) integrates external knowledge into large language models to improve response quality. However, recent work has shown that RAG systems are highly vulnerable to poisoning attacks, where malicious texts are inserted into the knowledge database to influence model outputs. While several defenses have been proposed, they are often circumvented by more adaptive or sophisticated attacks. This paper presents RAGOrigin, a black-box responsibility attribution framework designed to identify which texts in the knowledge database are responsible for misleading or incorrect generations. Our method constructs a focused attribution scope tailored to each misgeneration event and assigns a responsibility score to each candidate text by evaluating its retrieval ranking, semantic relevance, and influence on the generated response. The system then isolates poisoned texts using an unsupervised clustering method. We evaluate RAGOrigin across seven datasets and fifteen poisoning attacks, including newly developed adaptive poisoning strategies and multi-attacker scenarios. Our approach outperforms existing baselines in identifying poisoned content and remains robust under dynamic and noisy conditions. These results suggest that RAGOrigin provides a practical and effective solution for tracing the origins of corrupted knowledge in RAG systems. ",
    "status": "notchecked"
  },
  {
    "id": 54,
    "year": 2026,
    "title": "Consistent Estimation of Numerical Distributions under Local Differential Privacy by Wavelet Expansion",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00054",
    "abstract": " Distribution estimation under local differential privacy (LDP) is a fundamental and challenging task. Significant progresses have been made on categorical data. However, due to different evaluation metrics, these methods do not work well when transferred to numerical data. In particular, we need to prevent the probability mass from being misplaced far away. In this paper, we propose a new approach that express the sample distribution using wavelet expansions. The coefficients of wavelet series are estimated under LDP. Our method prioritizes the estimation of low-order coefficients, in order to ensure accurate estimation at macroscopic level. Therefore, the probability mass is prevented from being misplaced too far away from its ground truth. We establish theoretical guarantees for our methods. Experiments show that our wavelet expansion method significantly outperforms existing solutions under Wasserstein and KS distances. ",
    "status": "notchecked"
  },
  {
    "id": 55,
    "year": 2026,
    "title": "The Passkey Promise: A Comparative Usability Study of MFA Methods",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00055",
    "abstract": " Passkeys, the latest evolution of FIDO2 credentials, promise to combine enhanced security with improved usability. While passkeys are widely promoted as the long-awaited replacement for passwords, their real-world usability remains underexplored -- particularly as a passwordless and usernameless Multi-Factor Authentication (MFA) method in complex, heterogeneous environments like universities. Addressing this gap, we conducted a between-groups lab study with 92 university participants, comparing passkeys against security keys and one-time passwords across students, faculty, and staff. Our results show that passkeys are perceived as the most usable and accepted MFA method while enabling faster authentication. However, we also identified critical barriers including personal device requirements, exam scenario conflicts, privacy concerns, and recovery fears. These findings suggest that while passkeys outperform traditional MFA methods, successful deployment in academic settings requires addressing institutional constraints and providing role-specific implementation strategies. ",
    "status": "notchecked"
  },
  {
    "id": 56,
    "year": 2026,
    "title": "SFA-Miner: Mining Path-Sensitive API Usage Patterns via Symbolic Finite Automata",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00056",
    "abstract": " APIs are fundamental to modern software development, enabling integration across components. However, API misuses remain a significant concern, often stemming from an incomplete understanding of requirements and constraints. These misuses can introduce critical security vulnerabilities, impacting software reliability and safety. Avoiding API misuses requires effective detection and prevention mechanisms. In particular, understanding and enforcing correct API usage patterns play a crucial role in mitigating risks and improving API robustness. Recent work has demonstrated the effectiveness of frequent mining techniques in extracting API usage patterns from code. However, state-of-the-art studies focus only on frequently co-occurring operations, overlooking the pre-conditions of the operations. This paper introduces SFA-Miner (Symbolic Finite Automata Miner), a static analysis framework that extracts the frequent usage patterns of each API under different path conditions as symbolic finite automata (SFAs), where states represent abstract program states and transitions correspond to conditions involving APIs and symbolic variables representing their parameters. The key insight is that APIs can have different usage patterns under different path conditions. Violations of the SFA indicate potential API misuses. Leveraging frequent mining techniques, we extract SFAs hidden within code. We implemented SFA-Miner and evaluated it on four widely used open-source projects: Linux kernel, OpenSSL, FFmpeg, and Apache httpd, identifying 181 API misuses. Additionally, we discovered one CVE, demonstrating the tool’s effectiveness in detecting API misuses. ",
    "status": "notchecked"
  },
  {
    "id": 57,
    "year": 2026,
    "title": "Revisiting PQ WireGuard: A Comprehensive Security Analysis With a New Design Using Reinforced KEMs",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00057",
    "abstract": " WireGuard is a VPN based on the Noise protocol, known for its high performance, small code base, and unique security features. Recently, Hülsing et al. (IEEE S&P’21) presented post-quantum (PQ) WireGuard, replacing the Diffie-Hellman (DH) key exchange underlying the Noise protocol with key-encapsulation mechanisms (KEMs). Since WireGuard requires the handshake message to fit in one UDP packet of size roughly 1200 B, they combined Classic McEliece and a modified variant of Saber. However, as Classic McEliece public keys are notoriously large, this comes at the cost of severely increasing the server’s memory requirement. This hinders deployment, especially in environments with constraints on memory (allocation), such as a kernel-level implementations. In this work, we revisit PQ WireGuard and improve it on three fronts: design, (computational) security, and efficiency. As KEMs are semantically but not syntactically the same as DH key exchange, there are many (in hindsight) ad-hoc design choices being made, further amplified by the recent finding on the binding issues with PQ KEMs (Cremers et al., CCS’24). We redesign PQ WireGuard addressing these issues, and prove it secure in a new computational model by fixing and capturing new security features that were not modeled by Hülsing et al. We further propose reinforced KEM as a natural building block for key exchange protocols, enabling a PQ WireGuard construction where the server no longer needs to store Classical McEliece keys, reducing public key memory by 190 to 390×. In essence, we develop a new way to compress two ML-KEM like ciphertexts which may be of an independent interest. ",
    "status": "notchecked"
  },
  {
    "id": 58,
    "year": 2026,
    "title": "CBUE: Conclusion Based Utility Evaluation for Differentially Private Categorical Data",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00058",
    "abstract": " This work provides a method for analyzing the privacy implications of categorical data, with a finite set of elements, for a broad range of human subjects research. The specific target of this work is the field of learning sciences (LS). These researchers need privacy-preserving methods that maintain the accuracy of the conclusions drawn from datasets, conclusions that impact real people through education policies, rules, and funding decisions. Since the concepts of privacy and utility cannot be examined independently of the context, there is a need for an evaluation method that measures the correctness of the conclusions drawn from the dataset. In order to evaluate DP (Differential Privacy) mechanisms, we present Conclusion Based Utility Evaluation (CBUE). In this new evaluation method, it is possible to make a detailed analysis of many scenarios by using a large language model (LLM) to mimic the ability of humans to come to a conclusion. The method includes tokenized conclusions and metrics for evaluating the magnitude of error. We evaluate various DP methods, such as Laplace, Gaussian, and RR (Randomized Response), for reducing privacy risks inherent in databases by building noisy datasets. Experiments are conducted on two different learning sciences datasets to show the flexibility and adaptivity of this method. The results show that CBUE is effective at detecting edge cases, which makes it a more comprehensive utility evaluation method than statistical methods. We observe that CBUE provides a better quantification of the utility-privacy trade-off by providing a more accurate understanding of the utility for different DP mechanisms. ",
    "status": "notchecked"
  },
  {
    "id": 59,
    "year": 2026,
    "title": "Coral: Fast Succinct Non-Interactive Zero-Knowledge CFG Proofs",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00059",
    "abstract": " We introduce Coral, a system for proving in zero- knowledge that a committed byte stream corresponds to a structured object in accordance to a Context Free Grammar. Once a prover establishes the validity of the parsed object with Coral, they can selectively prove facts about the object—such as fields in Web API responses or in JSON Web Tokens—–to third parties or blockchains. Coral reduces the problem of correct parsing to a few simple checks over a left-child right-sibling tree and introduces a novel segmented memory abstraction that unifies and extends prior constructions for RAM in zkSNARKs. Our implementation of Coral runs on a standard laptop, and non-interactively proves the parsing of real Web responses (JSON and HTTP) and files (TOML and C) in seconds. The resulting proofs are small and cheap to verify. ",
    "status": "notchecked"
  },
  {
    "id": 60,
    "year": 2026,
    "title": "deepSURF: Detecting Memory Safety Vulnerabilities in Rust Through Fuzzing LLM-Augmented Harnesses",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00060",
    "abstract": " Although Rust ensures memory safety by default, it also permits the use of unsafe code, which can introduce memory safety vulnerabilities if misused. Unfortunately, existing tools for detecting memory bugs in Rust typically exhibit limited detection capabilities, inadequately handle Rust-specific types, or rely heavily on manual intervention. To address these limitations, we present deepSURF, a tool that integrates static analysis with Large Language Model (LLM)-guided fuzzing harness generation to effectively identify memory safety vulnerabilities in Rust libraries, specifically targeting unsafe code. deepSURF introduces a novel approach for handling generics by substituting them with custom types and generating tailored implementations for the required traits, enabling the fuzzer to simulate user-defined behaviors within the fuzzed library. Additionally, deepSURF employs LLMs to augment fuzzing harnesses dynamically, facilitating exploration of complex API interactions and significantly increasing the likelihood of exposing memory safety vulnerabilities. We evaluated deepSURF on 63 real-world Rust crates, successfully rediscovering 30 known memory safety bugs and uncovering 12 previously-unknown vulnerabilities (out of which 11 have been assigned RustSec IDs and 3 have been patched), demonstrating clear improvements over state-of-the-art tools. ",
    "status": "notchecked"
  },
  {
    "id": 61,
    "year": 2026,
    "title": "InsPIRe: Communication-Efficient PIR with Server-side Preprocessing",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00061",
    "abstract": " We present InsPIRe that is the first private information retrieval (PIR) construction simultaneously obtaining both high-throughput and low query communication while using server-side preprocessing (meaning no offline communication). Prior PIR schemes with both high-throughput and low query communication required substantial offline communication of either downloading a database hint that is 10-100x larger than the communication cost of a single query (such as SimplePIR and DoublePIR [Henzinger et al., USENIX Security 2023]) or streaming the entire database (such as Piano [Zhou et al., S&P 2024]). In contrast, recent works such as YPIR [Menon and Wu, USENIX Security 2024] avoid offline communication at the cost of increasing the query size by 1.8-2x, up to 1-2 MB per query. Our new PIR protocol, InsPIRe, obtains the best of both worlds by obtaining high-throughput and low communication without requiring any offline communication. Compared to YPIR, InsPIRe requires 5x smaller cryptographic keys, requires up to 50% less online query communication while obtaining up to 25% higher throughput. We show that InsPIRe enables improvements across a wide range of applications and database shapes including the InterPlanetary File System and private device enrollment. At the core of InsPIRe, we develop a novel ring packing algorithm, InspiRING, for transforming LWE ciphertexts into RLWE ciphertexts. InspiRING is more amenable to the server-side preprocessing setting that allows moving the majority of the necessary operations to offline preprocessing. InspiRING only requires two key-switching matrices whereas prior approaches needed logarithmic key-switching matrices. We also show that InspiRING has smaller noise growth and faster packing times than prior works in the setting when the total key-switching material sizes must be small. To further reduce communication costs in the PIR protocol, InsPIRe performs the second level of PIR using homomorphic polynomial evaluation, which only requires one additional ciphertext from the client. ",
    "status": "notchecked"
  },
  {
    "id": 62,
    "year": 2026,
    "title": "When AI Meets the Web: Prompt Injection Risks in Third-Party AI Chatbot Plugins",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00062",
    "abstract": " Prompt injection attacks pose a critical threat to large language models (LLMs), with prior work focusing on cutting-edge LLM applications like personal copilots. In contrast, simpler LLM applications, such as customer service chatbots, are widespread on the web, yet their security posture and exposure to such attacks remain poorly understood. These applications often rely on third-party chatbot plugins that act as intermediaries to commercial LLM APIs, offering non-expert website builders intuitive ways to customize chatbot behaviors. To bridge this gap, we present the first large-scale study of 17 third-party chatbot plugins used by over 10,000 public websites, uncovering previously unknown prompt injection risks in practice. First, 8 of these plugins (used by 8,000 websites) fail to enforce the integrity of the conversation history transmitted in network requests between the website visitor and the chatbot. This oversight amplifies the impact of direct prompt injection attacks by allowing adversaries to forge conversation histories (including fake system messages), boosting their ability to elicit unintended behavior (e.g., code generation) by 3–8x. Second, 15 plugins offer tools, such as web-scraping, to enrich the chatbot's context with website-specific content. However, these tools do not distinguish the website's trusted content (e.g., product descriptions) from untrusted, third-party content (e.g., customer reviews), introducing a risk of indirect prompt injection. Notably, we found that ~13% of e-commerce websites have already exposed their chatbots to third-party content. We systematically evaluate both vulnerabilities through controlled experiments grounded in real-world observations, focusing on factors such as system prompt design and the underlying LLM. Our findings show that many plugins adopt insecure practices that undermine the built-in LLM safeguards. ",
    "status": "notchecked"
  },
  {
    "id": 63,
    "year": 2026,
    "title": "Rain: Transiently Leaking Data from Public Clouds Using Old Vulnerabilities",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00063",
    "abstract": " Given their vital importance for governments and enterprises around the world, we need to trust public clouds to provide strong security guarantees even in the face of advanced attacks and hardware vulnerabilities. While transient execution vulnerabilities, such as Spectre, have been in the spotlight since 2018, until now there have been no reports of realistic attacks on real-world clouds, leading to an assumption that such attacks are not practical in noisy real-world settings and without knowledge about the (host or guest) victim. In particular, given that today's clouds have large fleets of older CPUs that lack comprehensive, in-silicon fixes to a variety of transient execution vulnerabilities, the question arises whether sufficient software-based defenses have been deployed to stop realistic attacks---especially those using older, supposedly mitigated vulnerabilities. In this paper, we answer this question in the negative. We show that the practice of mitigating vulnerabilities in isolation, without removing the root cause, leaves systems vulnerable. By combining such ``mitigated'' (and by themselves harmless) vulnerabilities, attackers may still craft an end-to-end attack that is more than the sum of its parts. In particular, we show that attackers can use L1TF, one of the oldest known transient execution vulnerabilities (discovered in January 2018), in combination with a simple speculative out-of-bounds load, to leak data from other guests in a commercial cloud computing platform. Moreover, with an average end-to-end duration of 15 hours to leak the TLS key of an Nginx server in a victim VM under noisy conditions, without detailed knowledge of either host or guest, the attack is realistic even in one of today's biggest and most important commercial clouds. ",
    "status": "notchecked"
  },
  {
    "id": 64,
    "year": 2026,
    "title": "Perceived Privacy Risk and Mitigation Post-Roe",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00064",
    "abstract": " Several years after the overturn of Roe v. Wade, the landscape of reproductive privacy has become increasingly complex and precarious. As a growing portion of the population faces legal risk simply for being pregnant, questions remain about how individuals perceive and respond to these threats and how context-specific factors such as pregnancy risk, miscarriage experience, and state-level restrictions shape privacy behaviors. We surveyed 503 individuals capable of pregnancy who indicated at least some concern with their reproductive health privacy about those concerns and how they have evolved, as well as their awareness of legal risks, and use of protective strategies. While most participants expressed high levels of concern and adopted a broad array of tactics, including VPNs, aliases, and incognito browsing. These behaviors were often deployed without clear threat prioritization, reflecting what we term a “scorched earth” approach. Although context-specific factors (e.g., state restrictiveness, reproductive status) were associated with elevated concern, we observed no consistent link between these factors and the specific strategies adopted, highlighting a disconnect between specific risks and the strategies participants employed, suggesting limited or improvised threat modeling. We argue that heightened threat perception and situational urgency have diminished the explanatory power of traditional demographic predictors, and that context-specific vulnerability offers a more meaningful---if still complex---lens for understanding privacy behavior. In response, we call for a more adaptive and situationally grounded privacy research agenda capable of addressing the shifting legal, social, and technological terrain ",
    "status": "notchecked"
  },
  {
    "id": 65,
    "year": 2026,
    "title": "Shared Spotlight Meridian: Distributed Sparse Pseudorandom Functions for Scalable Federated Learning",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00065",
    "abstract": " Secure federated learning enables multiple clients to train a shared model while keeping raw data private. Minimizing communication is natural in secure multiparty computation, yet cryptographic mechanisms create tension. Consequently, existing secure aggregation protocols are ill-suited to high-dimensional sparse updates, forfeiting sparsification gains and inflating communication by orders of magnitude relative to plaintext aggregation. Seeking efficiency under privacy, we introduce distributed sparse pseudorandom functions. Hidden alignment comes from a secretly shared spotlight index that illuminates only the chosen coordinate, serving as a meridian that anchors aggregations of nonzero entries. Enabled by our cryptographic advances, we present a secure aggregation protocol with near-optimal client communication. Relative to an insecure baseline, each client sends at most one extra bit per nonzero gradient element. Multi-server security holds unless all servers collude. At the client side, computational overhead is small, and server communication is optimal. Near-baseline accuracy is seen in our experiments across computer vision, natural language processing, and recommendation, with plaintext-level bandwidth savings. ",
    "status": "notchecked"
  },
  {
    "id": 66,
    "year": 2026,
    "title": "Transient Architectural Execution: From Weird Gates to Weird Programs",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00066",
    "abstract": " An emerging body of work has explored the construction of weird gates---code segments computing on microarchitectural state not exposed by the instruction set architecture. Weird gates abstract microarchitectural state (e.g., CPU cache residency) as Boolean values and compute logical functions over these values. Researchers have used weird gates in applications like side-channel amplification and malware obfuscation. Indeed, in principle, the computational model of weird gates---a Boolean circuit of bounded size---can perform (bounded) arbitrary computation. In practice, however, this model is less efficient (both asymptotically and concretely) than the standard processor model, which supports conditional execution, indexed memory, and richer data types. In this paper, we show how to build weird computation in the processor model rather than the circuit model. The primitive that makes this possible is transient architectural execution: transiently loading microarchitectural state into registers, computing on it, and storing the results back into microarchitectural state---without exposing any state architecturally. Transient architectural execution, a generalization of prior weird gates and transient execution attacks, allows us to wield the full computational capability of the processor to operate on microarchitectural state. We also show how to use the state of the branch predictor to emulate wide variables of up to 16 bits. As a result, our weird programs are over two orders of magnitude faster than weird gates and can compute functions that are impractical using prior approaches. ",
    "status": "notchecked"
  },
  {
    "id": 67,
    "year": 2026,
    "title": "Cosseter: GitHub Actions Permission Reduction Using Demand-Driven Static Analysis",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00067",
    "abstract": " Security vulnerabilities in GitHub Actions are increasingly leading to software supply chain attacks. In some instances, attackers have modified a project’s source code by crafting a malicious issue title. To mitigate such threats, GitHub introduced a permission system that allows project maintainers to customize the privilege granted to workflows and their jobs. Unfortunately, permission policy specification is a known hard problem across nearly all domains of computing, particularly when it is introduced after an ecosystem has been established. This paper proposes COSSETER, a static analysis tool designed to determine least-privilege permission policies for jobs within GitHub Actions workflow specifications. To achieve this goal, COSSETER overcomes state explosion challenges in static analysis of JavaScript Actions that result from packing and nuances in commonly used npm dependencies. We evaluated COSSETER using a dataset of manual permission annotations of JavaScript Actions used by industry tools and found that it has a comparable precision and recall. We further evaluate COSSETER at scale, studying the permission needs of 1,842 vulnerable workflows identified by prior work and extracting permission summaries for 8,353 JavaScript Actions. We find that COSSETER’s permission policy can reduce 76% of 1,274 high severity code injection vulnerabilities into medium, low, or no severity. In doing so, we demonstrate how COSSETER suggested permissions can provide a valuable defense against software supply chain attacks. ",
    "status": "notchecked"
  },
  {
    "id": 68,
    "year": 2026,
    "title": "SaTor: Exploring Satellite Routing in Tor to Reduce Latency",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00068",
    "abstract": " High latency is a critical limitation within the Tor network that has a negative impact on web application responsiveness. A key factor exacerbating Tor latency is the creation of lengthy circuits that span across geographically distant regions, causing significant transmission delays. A common solution involves modifying Tor's circuit-building process to reduce the likelihood of selecting lengthy circuits. However, this strategy compromises Tor's routing randomness, increasing the risk of deanonymization. Reducing Tor's latency while minimizing security degradation presents a challenge. This paper proposes and investigates SaTor, a satellite-assisted routing scheme to reduce Tor latency. By equipping Tor relays with satellite network access, SaTor could accelerate slow circuits via satellite transmission, without biasing the existing path selection process. Our performance evaluation, using a simulator we developed along with real-world measurements, shows that over the long term, SaTor provides an expected speed-up of 21.8 ms for over 40% of circuits, with only 100 top relays equipped with satellite service. Our research uncovers a viable way to overcome Tor's latency bottleneck, serving as a practical reference for its future enhancement. ",
    "status": "notchecked"
  },
  {
    "id": 69,
    "year": 2026,
    "title": "Understanding and Analyzing Privacy Risks in Mobile Consent-Management Platforms",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00069",
    "abstract": " Today’s mobile applications (apps) increasingly reuse third-party SDKs to provide essential functionalities. However, the integration of these SDKs into an app’s supply chain introduces complexity, making it challenging to manage the SDKs and ensure their collective compliance with privacy regulations. Recently, consent management platforms (CMPs) have emerged, being increasingly adopted by mobile apps as a centralized mechanism and app-global configuration to help manage SDKs, particularly enabling all SDKs in an app to comply with the same user consent status for personal data processing. However, the question of whether the adoption of established CMPs ensures the validity of user consent specifically in mobile apps remains underexplored. This study addresses this gap in knowledge by conducting the first systematic investigation of the problems associated to obtaining user consent with CMP GUIs in realworld mobile apps (across Android and iOS). To achieve this, we developed a novel framework, DIULENS, that efficiently and comprehensively discovers CMP GUIs using a series of LLM-aided GUI analysis techniques tailored to CMPs. The framework analyzes both CMP GUIs and actual SDK usage within the apps to identify violations of privacy-accountable design, implementation, and use of CMPs (CMP DIU risks or DIU risks in short). Our findings reveal various DIU risks, such as failures to properly and consistently disclose thirdparty SDKs, ambiguous consent effects resulting from user interactions with CMP GUIs, and instances where consent is either difficult to withdraw or coerced. Attributing the causes, we found that both app developers’ use (or configuration) of CMPs and flawed CMP implementations, or their combination, could cause DIU risks. We further observed differences in the adoption of CMPs and the DIU risks across the Android and iOS platforms, likely influenced by platform-specific privacy features, such as Apple’s App Tracking Transparency (ATT) framework. This study provides new insights and bridges a critical knowledge gap regarding the assurance of CMPs in obtaining valid user consent in mobile apps. ",
    "status": "notchecked"
  },
  {
    "id": 70,
    "year": 2026,
    "title": "GraphRAG under Fire",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00070",
    "abstract": " GraphRAG advances retrieval-augmented generation (RAG) by structuring external knowledge as multi-scale knowledge graphs, enabling language models to integrate both broad context and granular details in their generation. While GraphRAG has demonstrated success across domains, its security implications remain largely unexplored. To bridge this gap, this work examines GraphRAG's vulnerability to poisoning attacks, uncovering an intriguing security paradox: existing RAG poisoning attacks are less effective under GraphRAG than conventional RAG, due to GraphRAG's graph-based indexing and retrieval; yet, the same features also create new attack surfaces. We present GRAGPOISON, a novel attack that exploits shared relations in the underlying knowledge graph to craft poisoning text capable of compromising multiple queries simultaneously. GRAGPOISON employs three key strategies: i) relation injection to introduce false knowledge, ii) relation enhancement to amplify poisoning influence, and iii) narrative generation to embed malicious content within coherent text. Empirical evaluation across diverse datasets and models shows that GRAGPOISON substantially outperforms existing attacks in terms of effectiveness (up to 98% success rate) and scalability (using less than 68% poisoning text) on multiple variants of GraphRAG. We also explore potential defensive measures and their limitations, identifying promising directions for future research. ",
    "status": "notchecked"
  },
  {
    "id": 71,
    "year": 2026,
    "title": "Descriptors of Exposure: Undermining Tor Anonymity through Exploiting Descriptor Flood",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00071",
    "abstract": " Tor is a widely used network for anonymous communication, employing onion encryption and multi-hop routing to ensure anonymity for its users and service providers. Despite its robust design, Tor has been the target of numerous attacks, such as denial-of-service (DoS) attacks and deanonymization attacks. However, these attacks often rely on resource-intensive methods, such as bandwidth inflation or controlling large-scale nodes. They face limitations due to high costs, limited scalability, and countermeasures that Tor already has in place. In this paper, we identify a new vulnerability, termed the Descriptor Flood, in Tor’s memory management mechanism and service publication protocol. By exploiting Descriptor Flood, attackers can flood Tor nodes with malicious descriptors of onion services, causing severe memory fragmentation, exhaustion, and eventual node crash. Unlike conventional attacks, our method leverages a fundamental design flaw, allowing cost-effective and scalable exploitation without requiring substantial resources. To demonstrate the practical impact of this vulnerability, we propose the Tordos Attack, a three-phase strategy that efficiently disables Tor nodes and executes DoS and deanonymization attacks against onion services via tearing down specific nodes in Tor. The attack addresses key challenges, such as measuring node memory capacity, inducing fragmentation, and disabling critical nodes to maximize disruption. Our extensive experimental results indicate that the attack can disable Tor nodes and onion services within 9.1 minutes and expose the onion service's real identity in 6.1 hours, potentially leading to the collapse of the entire Tor network. ",
    "status": "notchecked"
  },
  {
    "id": 72,
    "year": 2026,
    "title": "EnchTable: Unified Safety Alignment Transfer in Fine-tuned Large Language Models",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00072",
    "abstract": " Nowadays, many machine learning models are fine-tuned from large language models (LLMs) to achieve high performance in specialized domains such as code generation, biomedical analysis, and mathematical problem solving. However, researchers have shown that such fine-tuning process often introduces a critical vulnerability: the systematic degradation of safety alignment, which undermines ethical guidelines and increases the risk of harmful outputs. Addressing this challenge, we introduce ENCHTABLE, a novel and unified framework designed to transfer and maintain safety alignment in downstream LLMs without requiring extensive retraining. ENCHTABLE leverages a Neural Tangent Kernel (NTK)-based safety vector distillation method to decouple safety constraints from task-specific reasoning, ensuring compatibility across diverse model architectures and sizes. Additionally, our interference-aware merging technique effectively balances the trade-offs between safety and utility, minimizing performance compromises across various task domains. We have implemented a fully functional prototype of ENCHTABLE on three different task domains and three distinct LLM architectures, and evaluated its performance through extensive experiments on eleven diverse datasets, assessing both downstream utility and model safety. Our evaluations include assessments of LLMs from different vendors, demonstrating the generalization capability of ENCHTABLE. Furthermore, ENCHTABLE exhibits robust resistance to both static and dynamic jailbreaking attacks, outperforming vendor-released safety models in mitigating adversarially designed prompts. Comparative analyses with six parameter modification methods and two inference-time alignment baselines reveal that ENCHTABLE achieves significantly lower unsafe rate and higher utility score and universal applicability across different task domains. Additionally, we validate that ENCHTABLE can be seamlessly integrated into various deployment pipelines without significant overhead. ",
    "status": "notchecked"
  },
  {
    "id": 73,
    "year": 2026,
    "title": "SeqAss: Using Sequential Associative Caches to Mitigate Conflict-Based Cache Attacks with Reduced Cache Misses and Performance Overhead",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00073",
    "abstract": " Cache randomization has been proposed as an effective defense against conflict-based cache attacks. Mirage and Chameleon are two of the state-of-the-art randomized last-level caches achieving a strong defense. However, they rely on techniques intrusive to the traditional cache structure, such as cache skews, over-provided metadata space, and separated data storage, and prohibit the use of the LRU replacement policy. Mirage incurs 22% extra area and 21% extra power. When running memory heavy applications, Chameleon consumes significant dynamic power due to its high relocation rate. This paper proposes to mitigate conflict-based cache at tacks using sequential associativity. The proposed SeqAss cache retains the set-associative structure and supports LRU. It achieves a defense as strong as Mirage. Instead of raising cache miss rate, SeqAss actually reduces it by 11.4%. Its area and power overhead is 28.8% and 22.1%, respectively, lower than Mirage. When running memory heavy applications, it incurs 50% lower dynamic power overhead compared to Mirage and Chameleon. ",
    "status": "notchecked"
  },
  {
    "id": 74,
    "year": 2026,
    "title": "Convenience at a Cost: The Security Risks of Template-based Development in the App-in-App Ecosystem",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00074",
    "abstract": " Recently, many popular mobile applications, such as WeChat and Alipay, have evolved into super-apps, with numerous merchants tending to develop their own mini-apps to enhance user experience. To overcome the limited development capabilities of individual merchants, super-apps allow third-party service providers to create mini-apps for them using templates, which enable the rapid development of mini-apps for various merchants. However, this template-based development mechanism also introduces significant security concerns, as many mini-apps created using templates exhibit malicious behaviors. In this work, we present the first systematic study focused on assessing the malicious behaviors associated with mini-app templates. We design and implement a novel tool, MateMiner, which adopts a three-stage clustering analysis and differential analysis to extract mini-app templates from a large dataset of mini-apps. Furthermore, we propose a pattern-based method to detect malicious behaviors. Finally, we apply MateMiner to 2,282,096 mini-apps and identify malicious behaviors in 79,758 mini-apps and 4,642 mini-app templates. Our results reveal that the templates have been abused to facilitate the development of malicious mini-apps, with most malicious behaviors targeting user privacy. This study highlights the security risks associated with template-based development and provides a foundation for detecting and mitigating such threats. Furthermore, we have reported all our findings to the super-app platform. ",
    "status": "notchecked"
  },
  {
    "id": 75,
    "year": 2026,
    "title": "LatORAM: ORAMs from Lateral Stashes and Delayed Shuffling",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00075",
    "abstract": " We study the design of oblivious RAMs (ORAMs) that allow a client to access memory outsourced to a remote, untrusted server without revealing the client's data access pattern. We are interested in concretely efficient constructions and prior works have yielded different ORAM frameworks with various trade-offs. Tree-based constructions such as Ring ORAM [Ren et al., USENIX'15] obtain low communication overhead, but require client storage of linear position maps and two roundtrip queries. Hierarchical schemes such as FutORAMa [Asharov et al., CCS'23] further reduce communication at the cost of more roundtrips during queries. Finally, SQRT-ORAM [Zahur et al., S&P'16] enables fast queries of one roundtrip and one block of communication at the cost of larger amortized communication costs. We present two new constructions, LatORAM and LAT2ORAM, that simultaneously obtains the positive traits of all three types of ORAM constructions. Online queries are blazing fast with one roundtrip and a single block of communication like SQRT-ORAM. Fixing the client memory sizes for comparison, the online communication cost of our constructions are 3-6x smaller than Ring ORAM and 5-10x smaller than FutORAMa even though both Ring ORAM and FutORAMa require multiple roundtrips per online query. Furthermore, our total amortized communication is also up to 50% smaller. To obtain our constructions, we present a new lazy approach of lateral stash growth that delays large shuffles. Of independent interest, we present improved oblivious merging schemes for specific settings important for our ORAMs. Our constructions solely rely on symmetric Cryptography. ",
    "status": "notchecked"
  },
  {
    "id": 76,
    "year": 2026,
    "title": "SoK: Evaluating Jailbreak Guardrails for Large Language Models",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00076",
    "abstract": " Large Language Models (LLMs) have achieved remarkable progress, but their deployment has exposed critical vulnerabilities, particularly to jailbreak attacks that circumvent safety alignments. Guardrails—external defense mechanisms that monitor and control LLM interactions—have emerged as a promising solution. However, the current landscape of LLM guardrails is fragmented, lacking a unified taxonomy and comprehensive evaluation framework. In this Systematization of Knowledge (SoK) paper, we present the first holistic analysis of jailbreak guardrails for LLMs. We propose a novel, multi-dimensional taxonomy that categorizes guardrails along six key dimensions, and introduce a Security-Efficiency-Utility evaluation framework to assess their practical effectiveness. Through extensive analysis and experiments, we identify the strengths and limitations of existing guardrail approaches, provide insights into optimizing their defense mechanisms, and explore their universality across attack types. Our work offers a structured foundation for future research and development, aiming to guide the principled advancement and deployment of robust LLM guardrails. ",
    "status": "notchecked"
  },
  {
    "id": 77,
    "year": 2026,
    "title": "Breaking the Barrier for Asynchronous MPC with a Friend",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00077",
    "abstract": " Multiparty computation (MPC) is a topic of growing interest for privacy-preserving computation tasks. A few MPC libraries have been developed, and newer protocols are regularly proposed to reduce the latency overhead, improve scalability, and achieve strong termination guarantees. However, most current MPC protocols are designed and implemented assuming network synchrony: in theory, they assume that all messages are delivered within a known time bound, while for experimental analysis, most assume all nodes to be honest, such that the time bounds are never deployed. While deploying MPC systems in the wild and trying to minimize the latency, network synchrony is indeed a strong assumption to make: natural adverse network conditions can break the safety and/or liveness of the protocol due to simply delayed messages. Asynchronous MPC (AMPC) protocols can overcome the challenge as they do not assume fixed time bounds for message delivery delays; however, AMPC faces a natural threshold barrier of 2/3rd honest majority and introduces significant computation and/or communication overheads. This work aims to achieve the best-of-both network models by designing a practical AMPC protocol that has stronger resilience guarantees matching those for synchronous MPC. We achieve this by adopting the emerging helper-aided model, and designing protocols that achieve fairness not only in the simple honest majority setting but also in the dishonest majority setting. Our protocols follow the standard preprocessing-online paradigm, enabling a lightweight and fast input-dependent online phase. In the honest majority setting, our protocol relies solely on lightweight cryptographic operations. In the dishonest majority setting, the protocol requires oblivious transfer (OT) during preprocessing, which we prove is necessary in this setting. We implement our constructions and provide a thorough performance comparison with state-of-the-art MPC protocols in the helper-aided model. Our experiments demonstrate that our protocols substantially outperform the state-of-the-art helper-aided MPC scheme, while being significantly more resilient to network delays. ",
    "status": "notchecked"
  },
  {
    "id": 78,
    "year": 2026,
    "title": "Demystifying and Exploiting ASLR on NVIDIA GPUs",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00078",
    "abstract": " GPUs are foundational to modern AI workloads, powering deep learning training and inference. As their deployment becomes increasingly widespread, GPUs have also emerged as attractive targets for attackers. To strengthen their defenses, security measures, such as Address Space Layout Randomization (ASLR), are deployed. However, in contrast to the extensive research on CPU ASLR, in-depth studies of GPU ASLR are still missing. This paper presents the first comprehensive examination of ASLR on NVIDIA GPUs. We propose two novel techniques to thoroughly inspect memory mappings and collect randomized GPU addresses at scale. Leveraging these techniques, we construct a fine-grained GPU memory map and introduce entropy-based metrics to quantify the strength of randomization. Our study uncovers multiple previously unknown weaknesses of ASLR on NVIDIA GPUs, including an unrandomized GPU heap and correlated ASLR offsets between GPU and CPU regions, which undermines the security of both GPU and CPU ASLR. These findings have been confirmed by NVIDIA. Furthermore, we conduct a practical case study demonstrating how these weaknesses can be exploited to infer CPU ASLR offsets from the GPU. Finally, we give mitigations to enhance GPU ASLR security. ",
    "status": "notchecked"
  },
  {
    "id": 79,
    "year": 2026,
    "title": "Dory: Streaming PCG with Small Memory",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00079",
    "abstract": " Pseudorandom correlation generators (PCGs) have been popular in generating a huge amount of correlated randomness, a critical resource in secure computation. However, existing PCGs are memory-consuming and not friendly to resource-constrained devices. Even for moderate devices, the need for large memory can also be a disadvantage in applications like zero-knowledge proofs or large-scale secure computation. In this paper, we propose a malicious streaming PCG (sPCG), which generates a bounded number of tuples of subfield vector oblivious linear evaluation (sVOLE) on-the-fly, each with sublinear memory and computation. (1) We propose an efficient protocol that replaces the relaxed distributed comparison function in the best pseudorandom correlation function (PCF) for sVOLE (CRYPTO'22), which has the same streaming features for any polynomial number of tuples. With this protocol, our sPCG is doubly efficient in memory and the computation per sVOLE. Moreover, we augment the black-box distributed setup to malicious security and yield 4x communication improvement. Our sPCG can be extended to a more efficient sVOLE PCF with the same improvements in memory and computation, and a 2x faster malicious non-black-box distributed setup. (2) We present a practical attack on the Learning Parity with Noise (LPN) assumption for expand-accumulate codes with regular noise, revealing that some previous parameters provide around 14~22 bits of security over binary noises, far below the target 128 bits. To address this, we introduce a low-Hamming-weight noise distribution to withstand the attack. We then derive some updated LPN parameters with the new noise distribution, restoring 128-bit security and reducing the noise-related computation and communication. (3) We provide an implementation of our sPCG for the special case of correlated oblivious transfer (COT). In addition to the improvements over the best PCF, our sPCG can have a comparable end-to-end performance to Ferret (CCS'20) and the PCG from expand-convolute codes (CRYPTO'23), two state-of-the-art PCGs, with the advantage of being able to produce 10 million COTs on-the-fly and reducing the memory from 337 MB and 624 MB to 20 MB, respectively. ",
    "status": "notchecked"
  },
  {
    "id": 80,
    "year": 2026,
    "title": "Designing Transport-Level Encryption for Datacenter Networks",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00080",
    "abstract": " Cloud applications need network data encryption to isolate from other tenants and protect their data from potential eavesdroppers in the network infrastructure. This paper presents SMT, a protocol design for emerging datacenter transport protocols, such as NDP and Homa, to integrate data encryption. SMT integrates TLS-based encryption with a message-based transport protocol that supports efficient Remote Procedure Calls (RPCs), a common workload in datacenters. This architecture enables the use of per-message record sequence number spaces in a secure session, while ensuring unique message identities to prevent replay attacks. It also enables the use of existing NIC offloads designed for TLS over TCP, while being a native transport protocol alongside TCP and UDP. We implement SMT in the Linux kernel by extending Homa/Linux and improve RPC throughput by up to 41 % and latency by up to 35 % in comparison to TLS/TCP. ",
    "status": "notchecked"
  },
  {
    "id": 81,
    "year": 2026,
    "title": "MAYA: Addressing Inconsistencies in Generative Password Guessing through a Unified Benchmark",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00081",
    "abstract": " Recent advances in generative models have led to their application in password guessing, with the aim of replicating the complexity, structure, and patterns of human-created passwords. Despite their potential, inconsistencies and inadequate evaluation methodologies in prior research have hindered meaningful comparisons and a comprehensive, unbiased understanding of their capabilities. This paper introduces MAYA, a unified, customizable, plug-and-play benchmarking framework designed to facilitate the systematic characterization and benchmarking of deep generative password-guessing models in the context of trawling attacks. Using MAYA, we conduct a comprehensive assessment of six state-of-the-art DL-based models, which we re-implemented and adapted to ensure standardization, and two traditional ML-based approaches. Our evaluation spans eight real-world password datasets and covers an exhaustive set of advanced testing scenarios, totaling over 15,000 compute hours. Our findings indicate that these models effectively capture different aspects of human password distribution and exhibit strong generalization capabilities. However, their effectiveness varies significantly with long and complex passwords. Through our evaluation, DL-based autoregressive models consistently outperform other deep learning approaches, demonstrating unique capabilities in generating accurate and complex guesses; meanwhile, ML-based approaches remain surprisingly highly competitive in many scenarios. Moreover, the diverse password distributions learned by the models enable a multi-model attack that outperforms the best individual model by an average of ∼7 percentage points. By releasing MAYA, we aim to foster further research, providing the community with a new tool to consistently and reliably benchmark generative password-guessing models. Our framework is publicly available at https://github.com/williamcorrias/MAYA-Password-Benchmarking.git. ",
    "status": "notchecked"
  },
  {
    "id": 82,
    "year": 2026,
    "title": "URLcoat: Exploiting Web Search Capability to Jailbreak Large Language Models",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00082",
    "abstract": " Large language models (LLMs) achieve remarkable advances in understanding and reasoning with human language, which are widely applied in software development, content creation, healthcare, etc. However, their vulnerabilities to security threats, especially jailbreak attacks, remain a significant issue. Existing research on jailbreak mainly focuses on the security risks of LLMs' inherent thinking and reasoning, overlooking the new attack surface introduced by web search capability. Attackers can exploit this by guiding LLMs to retrieve information from external URLs, which is then used to implicitly reconstruct harmful instructions and circumvent safety mechanisms, leading to the generation of harmful content. In this paper, we propose a novel jailbreak attack, named URLcoat. The core idea is to exploit the web search capabilities of LLMs to circumvent their security safeguards. URLcoat incorporates three core strategies: obfuscating the feature of sensitive words to evade input detection, reconstructing harmful instructions via implicit associations with external URLs, and contextual narrative guidance to bypass output filtering. The experimental results reveal that URLcoat attains 100% attack success rates in mainstream LLMs, including GPT-5, GPT-4o, Gemini 2.0 Flash Thinking, DeepSeek R1, Kimi 1.5, ChatGLM-4, Grok 3, Gemini 2.5 Pro, Gemini 2.5 Flash, and Gemini 2.0 Flash, exceeding the performance of state-of-the-art jailbreak techniques. This study examines the security vulnerabilities arising from LLMs' web search capability, which facilitates the LLMs to produce harmful output. ",
    "status": "notchecked"
  },
  {
    "id": 83,
    "year": 2026,
    "title": "Phoenix: Rowhammer Attacks on DDR5 with Self-Correcting Synchronization",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00083",
    "abstract": " DDR5 has shown an increased resistance to Rowhammer attacks in production settings. Surprisingly, DDR5 achieves this without additional refresh management commands, pointing to the deployment of more sophisticated in-DRAM Target Row Refresh (TRR) mechanisms. This paper reverse engineers such advanced TRR schemes in DDR5 devices for the first time. Our findings show that compared to older mitigations deployed in DDR4, these new schemes have considerably fewer blind spots spread over many refresh intervals. This means that an effective DDR5 Rowhammer pattern must precisely track thousands of refresh operations, which we show is not possible with existing techniques. To address this challenge, our new DDR5 Rowhammer attack, called Phoenix, self-corrects the pattern whenever it detects a missed refresh operation during the attack. Our evaluation shows that Phoenix triggers bit flips on 15 out of 15 DDR5 devices in our test pool. Using these bit flips, we build the first Rowhammer privilege escalation exploit that obtains root on a commodity DDR5 system with default settings in as little as 109 seconds. These results provide further evidence that a principled Rowhammer mitigation, such as per-row activation counters, is mandatory for a secure operation of future devices. ",
    "status": "notchecked"
  },
  {
    "id": 84,
    "year": 2026,
    "title": "Practical Anonymous Two-Party Gradient Boosting Decision Tree",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00084",
    "abstract": " Structured data is well handled by gradient-boosted decision trees (GBDT), which are usually trained on vertically partitioned features across mutually distrustful parties. High speed and interpretability make GBDTs popular in finance and healthcare, where neural networks may fall short. Enabling secure computation for GBDTs poses unique challenges, requiring secure record alignment for comparison. Relying on private set intersection (PSI) is a de facto approach. Mistaking PSI for a safety measure actually exposes which record identifiers (IDs) are shared between the datasets. Although circuit-PSI could help, it is costly for generic uses. New ideas are needed to efficiently train in a \"dark forest\". Aiming to hide the IDs, we initiate the study of anonymous GBDT training on split data held by two parties. Dual circuit-PSI in our design lets the parties alternate as receiver to run pick-then-sum over local features. Via oblivious programmable pseudorandom functions, we propagate circuit-PSI outputs as shared state across runs. Avoiding universal alignment, we resolve the neglected dilemma that ID hiding incurs a cost that scales with domain size. Next, we halve the cost of ciphertext packing used to convert single-instruction multiple-data homomorphic encryption from (ring) learning with errors in prior secure GBDT (Usenix Security ’23) and related secure machine-learning computations. Comparative experiments show our protocol remains competitive with leaky approaches in efficiency. Enabling ID-hiding aggregation, our techniques can extend to other vertically partitioned analytics. ",
    "status": "notchecked"
  },
  {
    "id": 85,
    "year": 2026,
    "title": "QuickSafe: Targeted Hardening Against Memory Corruption",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00085",
    "abstract": " Despite decades of research, memory safety solutions see limited adoption, as they often incur high overheads, are complex to deploy, or cover only a narrow scope of bugs. In this paper, we present QuickSafe --- a targeted approach to harden programs against exploitation of known but unresolved memory errors with minimal overhead. QuickSafe yields a stopgap patch that is immediately available, while the bug awaits eventual resolution. Where most existing automatic patch generators rely on inserting runtime constraint checks in the code to stop exploits, QuickSafe instead isolates memory objects associated with a known bug from the rest of the program. Object isolation can be implemented in different ways, depending on hardware support and desired security guarantees. To assess the viability, we present two such implementations. On traditional architectures, we allocate vulnerable objects on dedicated pages flanked by inaccessible guard pages. On platforms that support Memory Tagging Extensions (MTE), we offer stronger guarantees by enforcing disjoint tag domains. To reliably identify the objects associated with a given memory error, we introduce TagASan --- an extension of AddressSanitizer (ASan) that uses tagged pointers to trace faulting accesses back to their originating allocation sites. As an additional contribution, we present a new dataset of 223 real-world memory errors across ten prominent projects to measure the performance of automatic patch generators. We evaluate QuickSafe on (1) this new benchmark suite, (2) the Juliet Test Suite, and (3) buggy benchmarks from SPEC CPU2006/2017. Using the guard-page-based isolation backend, QuickSafe protects against the exploitation of all evaluated bugs, incurring a geomean memory overhead of 2.46% and a geomean runtime overhead of 2.67% --- with the vast majority of applications slowing down by only around 1%. We apply the MTE-based isolation strategy to a representative subset of the dataset, confirming its effectiveness and showing negligible runtime overhead of ~0.12%. ",
    "status": "notchecked"
  },
  {
    "id": 86,
    "year": 2026,
    "title": "VIA: Communication-Efficient Single-Server Private Information Retrieval",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00086",
    "abstract": " Private Information Retrieval (PIR) is a crucial component in many privacy-preserving systems, with Offline/Online PIR attracting significant attention. Recent works have focused on eliminating offline communication overhead. However, existing constructions incur high online communication costs as a trade-off. To address this, we propose VIA, a single-server PIR scheme that eliminates offline communication while achieving $O{_\\lambda}(\\log N)$ online communication complexity. Experimental evaluations demonstrate that for a 32 GB database, VIA requires only 690 KB of online communication---a $3.7\\times$ reduction compared to state-of-the-art schemes without offline communication---while attaining a throughput of 3.11 GB/s. Furthermore, we introduce VIA-C, a variant of VIA that allows offline communication. Compared to previous communication-efficient schemes, VIA-C achieves a $24.5\\times$ reduction in online communication, requiring only 2.1 KB for a 32 GB database (with 14.8 MB offline communication). Moreover, VIA-C can naturally extend to VIA-B that supports batch queries. Compared to previous communication-efficient batch PIR schemes, VIA-B achieves a $3.5\\times$ reduction in query size and a $127\\times$ reduction in response size for a 1 GB database of 1-byte records. The designs of our schemes rely on a novel DMux-CMux structure and LWE-to-RLWE conversion techniques. ",
    "status": "notchecked"
  },
  {
    "id": 87,
    "year": 2026,
    "title": "2FiA: Towards WiFi Sensing-Based Authentication with Unique Biometrics",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00087",
    "abstract": " The emerging IEEE 802.11bf standard positions WiFi sensing as a key enabler of human biometric sensing for authentication. However, existing WiFi sensing-based authentication systems primarily depend on voluntary or semi-voluntary biometric traits, such as body motions or respiration. While effective, these traits lack strong uniqueness and are susceptible to imitation, making WiFi sensing systems vulnerable to behavioral mimicry attacks. In this paper, we introduce 2FiA the first dual-biometrics WiFi sensing-based authentication system integrating semi-voluntary respiration and involuntary heartbeat. Respiration serves as the primary factor, offering efficient and continuous identity verification, while heartbeat reinforces system robustness through its highly unique and hard-to-imitate nature. For the first time, we propose a novel WiFi sensing pipeline to extract weak heartbeat signals by statistically localizing the thoracic region, effectively suppressing non-thoracic interference, and separating co-located respiration to refine the heartbeat signals. Furthermore, we leverage Respiratory Sinus Arrhythmia (RSA) as a physiological constraint to validate and enhance the extracted heartbeat signals by exploiting the intrinsic coupling between respiration and heartbeat. We then build the authentication model by integrating features from both respiration and heartbeat signals in a unified framework. Through extensive experiments involving dozens of participants across diverse environments, we demonstrate that 2FiA delivers reliable authentication performance, particularly in multi-user and impersonation attack scenarios. ",
    "status": "notchecked"
  },
  {
    "id": 88,
    "year": 2026,
    "title": "AI Wrote My Paper and All I Got Was This False Negative:* Measuring the Efficacy of Commercial AI Text Detectors",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00088",
    "abstract": " Academic institutions and publishers are increasingly relying on commercial AI-generated-text (AIGT) detectors to combat plagiarism and verify authorship in the era of large language models (LLMs). As the number of submissions to academic security conferences increases at an exponential rate, the temptation to deploy detectors to protect academic integrity commensurately increases. Unfortunately, even when benchmarks are disclosed, these detectors lack appropriate performance characterizations for use in evaluating academic security writing. In this paper, we conduct a comprehensive empirical evaluation of leading AIGT detector performance on academic security writing. We collect a dataset of all papers (N=6,295) from Tier-1 conferences (IEEE S\\&P, CCS, NDSS, and USENIX) prior to the public release of ChatGPT. We then create an AIGT version of each of these papers and use this combined dataset to evaluate the top five most popular AIGT detectors, based on Tranco-list rankings. Our evaluation not only finds that performance varies wildly across AIGT detectors (e.g., FPRs between 0.05\\% and 68.6\\% and FNRs ranging between 0.3\\% and 99.6\\%). Even more critically, these detectors are trivially circumvented by a simple adaptive adversary (e.g., a TPR reduction from 94.2\\% to 2.5\\%). Ultimately, the limitations of current detector-based approaches create an adversarial environment in which achieving authorship verification remains out of reach. ",
    "status": "notchecked"
  },
  {
    "id": 89,
    "year": 2026,
    "title": "Cavern: Efficient Honest-Majority Maliciously Secure $(2+1)$ -PC for $\\mathbb{Z}_{2^n}$ via DPFs",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00089",
    "abstract": " We introduce \\textsc{Cavern}, a new maliciously secure $(2+1)$ -PC protocol for efficient piecewise polynomial (i.e., spline) evaluation on additively secret shared inputs over the ring $\\mathbb{Z}_{2^n}$ in the preprocessing model, where parties obtain input-independent correlated randomness in an offline phase, which they then use to run an efficient protocol in the input-dependent online phase. This $(2+1)$ party structure can alternatively be instantiated between two parties with the aid of a (possibly untrusted) dealer. At the technical level, we introduce a new primitive called verifiable incremental distributed point function (VIDPF) and build on a novel combination of the VIDPF and authenticated secret sharing, providing an efficient method to detect the malicious behavior of the dealer or one of the parties. We implement and benchmark our protocol against the state-of-the-art semi-honest protocol \\textsc{Grotto} (CCS 2023), and the trusted-dealer-based maliciously secure 2PC protocol \\textsc{Shark} (S\\&P 2025). The results indicate that \\textsc{Cavern} only imposes a constant factor overhead on the top of \\textsc{Grotto} and \\textsc{Shark}, while providing stronger security guarantees. ",
    "status": "notchecked"
  },
  {
    "id": 90,
    "year": 2026,
    "title": "Chypnosis: Undervolting-based Static Side-channel Attacks",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00090",
    "abstract": " Static side-channel analysis attacks, which rely on a stopped clock to extract sensitive information, pose a growing threat to embedded systems’ security. To protect against such attacks, several proposed defenses aim to detect unexpected variations in the clock signal and clear sensitive states. In this work, we present Chypnosis, an undervolting attack technique that indirectly stops the target circuit clock, while retaining stored data. Crucially, Chypnosis also blocks the state clearing stage of prior defenses, allowing recovery of secret information even in their presence. However, basic undervolting is not sufficient in the presence of voltage sensors designed to handle fault injection via voltage tampering. To overcome such defenses, we observe that rapidly dropping the supply voltage can disable the response mechanism of voltage sensor systems. We implement Chypnosis on various FPGAs, demonstrating the successful bypass of their sensors, both in the form of soft and hard intellectual property (IP) cores. To highlight the real-world applicability of Chypnosis, we show that the alert handler of the OpenTitan root-of-trust, responsible for invoking hardware responses to threats, can be bypassed. Furthermore, we demonstrate that by combining Chypnosis with static side-channel analysis techniques, namely laser logic state imaging (LLSI) and impedance analysis (IA), we can extract sensitive information from a side-channel protected cryptographic module used in OpenTitan, even in the presence of established clock and voltage sensors. Finally, we propose and implement an improvement to an established FPGA-compatible clock detection countermeasure, and we validate its resilience against Chypnosis. ",
    "status": "notchecked"
  },
  {
    "id": 91,
    "year": 2026,
    "title": "Fizzle: A Framework for Deterministic and Reproducible Network Fuzzing",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00091",
    "abstract": " Networked systems regularly receive untrusted inputs. When improperly handled, adversaries thus have the ability to remotely crash or compromise such systems. While many techniques have been proposed to detect these vulnerabilities, their ability to handle asynchronous and nondeterministic behavior significantly limit their coverage of real systems. In this paper we present Fizzle, a high-performance deterministic simulation testing framework for fuzzing network applications. Fizzle interposes system library calls to enforce sequential execution for multi-threading, simulate multi-modal network connections, and control system randomization in a manner that is transparent to the target application. By tracking synchronization and I/O primitives, Fizzle deterministically identifies when an application has finished processing input, thereby dramatically expanding the suite of protocols that it can accurately fuzz relative to other approaches. We show that Fizzle maintains 100% stability across ProFuzzBench targets and highly concurrent applications including Unbound, Redis and Open5GS. This resultantly leads to improved coverage and newly discovered/disclosed CVEs for projects that have already been subject to fuzzing. Surprisingly, Fizzle significantly outperforms existing network fuzzers despite carrying out substantial bookkeeping of external state and enforcing sequential execution of threads, achieving up to 20x more executions per second. Fizzle is designed to be highly configurable to a variety of network inputs and integrates with both AFL++ and LibAFL; we release it as an open-source extensible framework for future network protocol research to be carried out in a deterministic and reproducible manner. ",
    "status": "notchecked"
  },
  {
    "id": 92,
    "year": 2026,
    "title": "Sealing the Window: Efficient Tamper Protection for Provenance Logs",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00092",
    "abstract": " Today's advanced cyber attacks routinely circumvent existing protection measures. Analysts must rely on after-the-fact detection, based on provenance logs, to understand and recover from these intrusions. Since attackers prize the ability to stay hidden, they take every measure to remove all signs of attacks from these logs. In this research, we begin with a study of previous work on protecting provenance logs from such tampering. Through a motivating experimental study, we show that audit logging systems deployed today are highly susceptible to tampering. Moreover, existing tamper detection measures either require specialized hardware and custom OS modifications, or they incur excessive performance costs. To overcome these challenges, we first analyze previous research to identify their key bottlenecks. We then present new techniques and algorithms that avoid these bottlenecks, while also providing several additional benefits. Our techniques have been implemented into a system WinSeal that achieves well over a 10x reduction in overhead as compared to previous tamper detection techniques. On the protection front as well, WinSeal improves a key metric, namely, tamper window duration, by an order of magnitude as compared to previous techniques compatible with stock hardware and software. Our software is being open-sourced along with this paper. ",
    "status": "notchecked"
  },
  {
    "id": 93,
    "year": 2026,
    "title": "STIR/SHAKEN: A Cocktail of Cryptographic Clumsiness",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00093",
    "abstract": " Scams and fraudulent robocalls are rampant in the telephone system. Fraudsters often employ call spoofing to impersonate a known caller to the victim, making it difficult to detect and block the fraudster’s calls. In an effort to combat call spoofing, the U.S. government mandated the use of a new suite of protocols called STIR/SHAKEN in 2019. STIR/SHAKEN is, at its core, a system that uses cryptography for abuse prevention. Providers include a cryptographically-signed assertion about the caller’s identity and other metadata in call headers. This serves both to authentically convey this metadata between providers during call routing and to provide reportable, verifiable evidence of bad behavior by providers that originate fraudulent calls. The purpose of this paper is to investigate the security and privacy of STIR/SHAKEN and to assess its impact on the security and privacy of the telephone system. We find that STIR/SHAKEN is deeply harmful to user privacy and has severe security issues both in its design and implementation. We identify two main issues in the design of STIR/SHAKEN. First, signing call metadata renders it crypto- graphically non-repudiable. Second, STIR/SHAKEN has led to widespread new leakage of sensitive call metadata to off-path third parties. We also identify a number of issues in specific parts of STIR/SHAKEN, such as the PKI. We investigated STIR/SHAKEN implementations using several different techniques. We survey 29 providers about their STIR/SHAKEN experiences, did large-scale traffic measurements, including STIR/SHAKEN certificates, at a real telephone provider, and manually tested several STIR/SHAKEN implementations. Among our findings are that severely malformed certificates are common, and that some STIR/SHAKEN implementations completely break the federally-mandated *67 caller-privacy mechanism. Finally, we propose solutions to many of the issues we identified. We design a backwards-compatible key discovery mechanism that uses SIP error messages. We also design the first blind signing protocol for the asymmetric message franking (AMF) construction of Tyagi et al., and introduced new security definitions to capture novel security requirements we identify for the setting, such as verifier-hiding blindness. To our knowledge, in this effort we have initiated the formal study of blind signing for designated-verifier signatures. ",
    "status": "notchecked"
  },
  {
    "id": 94,
    "year": 2026,
    "title": "International Students and Scams: At Risk Abroad",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00094",
    "abstract": " International students (IntlS) in the US refer to foreign students who acquire student visas to study in the US, primarily in higher education. As IntlS arrive in the US, they face several challenges, such as adjusting to a new country and culture, securing housing remotely, and arranging finances for tuition and personal expenses. These experiences, coupled with recent events such as visa revocations and the cessation of new visas, compound IntlS’ risk of being targeted by and falling victim to online scams. While prior work has investigated IntlS’ security and privacy, as well as general end users’ reactions to online scams, research on how IntlS are uniquely impacted by scams remains largely absent. To address this gap, we conduct a two-phase user study comprising surveys (n=48) and semi-structured interviews (n=9). We investigate IntlS’ exposure and interactions with scams, post-exposure actions such as reporting, and their perceptions of the usefulness of existing prevention resources and the barriers to following prevention advice. We find that IntlS are often targeted by scams (e.g., attackers impersonating government officials) and fear legal implications or deportation, which directly impacts their interactions with scams (e.g., they may prolong engagement with a scammer due to a sense of urgency). Interestingly, we also find that IntlS may lack awareness of – or access to – reliable resources that inform them about scams or guide them in reporting incidents to authorities. In fact, they may also face unique barriers in enacting scam prevention advice, such as avoiding reporting financial losses, since IntlS are required to demonstrate financial ability to stay in the US. The findings produced by our study help synthesize guidelines for stakeholders to better aid IntlS in reacting to scams. ",
    "status": "notchecked"
  },
  {
    "id": 95,
    "year": 2026,
    "title": "MetaBreak: Jailbreaking Online LLM Services via Special Token Manipulation",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00095",
    "abstract": " Unlike regular tokens derived from existing text corpora, special tokens are artificially created to annotate structured conversations during the fine-tuning process of Large Language Models (LLMs). Serving as metadata of training data, these tokens play a crucial role in instructing LLMs to generate coherent and context-aware responses. We demonstrate that special tokens can be exploited to construct four attack primitives, with which malicious users can reliably bypass the internal safety alignment of online LLM services and circumvent state-of-the-art (SOTA) external content moderation systems simultaneously. Moreover, we found that addressing this threat is challenging, as aggressive defense mechanisms-such as input sanitization by removing special tokens entirely, as suggested in academia-are less effective than anticipated. This is because such defense can be evaded when the special tokens are replaced by regular ones with high semantic similarity within the tokenizer's embedding space. We systemically evaluated our method, named MetaBreak, on both lab environment and commercial LLM platforms. Our approach achieves jailbreak rates comparable to SOTA prompt-engineering-based solutions when no content moderation is deployed. However, when there is content moderation, MetaBreak outperforms SOTA solutions PAP and GPTFuzzer by 11.6% and 34.8%, respectively. Finally, since MetaBreak employs a fundamentally different strategy from prompt engineering, the two approaches can work synergistically. Notably, empowering MetaBreak on PAP and GPTFuzzer boosts jailbreak rates by 24.3% and 20.2%, respectively. ",
    "status": "notchecked"
  },
  {
    "id": 96,
    "year": 2026,
    "title": "State of Browser Process-Isolation: The Same-Site Weakness",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00096",
    "abstract": " Web browsers are among the most sophisticated and essential software tools we use in everyday life. Due to their complexity, however, their attack surface is large and encompasses a broad class of vulnerabilities. To protect against a large class of advanced exploitation techniques, browsers have adopted site isolation, which protects users by isolating websites and their sensitive information into separate processes out of reach for an attacker. However, due to initial compatibility issues, subdomains are not isolated from each other. This creates a serious security risk, as attackers frequently hijack subdomains and exploit them to launch malicious campaigns. In this paper, we study the risks of current renderer process isolation policies and show that attackers can exfiltrate sensitive data across all major browsers. First, we analyze the design of process isolation across browsers and evaluate how the assignment of web origins to processes is influenced by existing mitigation headers. Through this analysis, we uncover several flaws in the implementation of these mitigations and introduce novel techniques to force domains in the same process. Next, we evaluate which type of in-process attacks pose viable threats by presenting exploitation case studies on the Blink, Gecko, and WebKit browser engines and measuring their performance. Our case studies demonstrate that, because only small amounts of data need to be leaked, even Spectre v1 can be employed, highlighting that nearly all modern machines are at risk. We assess the adoption of mitigation headers by scanning websites from the top 25,000 entries in the Tranco ranking as well as subdomains of academic institutions. Our analysis reveals that only 6% of Tranco-ranked domains and fewer than 2% of university websites enable any relevant mitigation. To evaluate the performance of stricter process isolation policies, we benchmark Chrome’s prototypes implementing origin isolation using Speedometer 3.0 and conduct a case study on the top 12 reachable websites from the Tranco ranking. Overall, we conclude that in-process attacks still pose a significant threat; however, browsers can enforce stricter policies with low overhead and no compatibility issues for most websites. ",
    "status": "notchecked"
  },
  {
    "id": 97,
    "year": 2026,
    "title": "Your Compiler is Backdooring Your Model: Understanding and Exploiting Compilation Inconsistency Vulnerabilities in Deep Learning Compilers",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00097",
    "abstract": " Deep learning (DL) compilers serve as essential infrastructure in modern DL systems. In this work, we uncover a fundamental security vulnerability inherent in the design principles of DL compilers. Specifically, we ask: Can an official, unmodified DL compiler change a DL model's semantics during compilation, and can such changes introduce hidden backdoors? To answer this question, we consider both adversarial and natural in-the-wild settings. In the adversarial setting, we propose an attack that generates a benign DL model where the backdoor trigger has no effect on the model's behavior. However, after compilation, this benign model is transformed into a backdoored version, allowing the trigger to influence its decisions successfully. We evaluate our approach on six DL models, three commercial compilers, and two hardware platforms. Pre-compilation models show no trigger effects and remain undetected by four state-of-the-art backdoor detectors. In contrast, post-compilation models achieve a 100% attack success rate on triggered inputs while preserving normal behavior on clean inputs, with a 100% prediction consistency rate with the pre-compilation model. Our attack generalizes across different compiler-hardware combinations and floating-point settings. Beyond the intentional adversarial setting, we further conduct an in-the-wild analysis of the top 100 most-downloaded models on HuggingFace-including one with over 220 million downloads—and uncover natural triggers in 31 models using a gradient-guided method. These findings suggest that DL compilers may unintentionally introduce security risks, even in the absence of explicit attacks. Our results uncover an overlooked threat in the ML stack: unmodified DL compilers can silently change the model semantics during compilation. To our knowledge, our work is the first work to demonstrate the inherent security risks of DL compiler design, highlighting a new frontier for secure and trustworthy machine learning. ",
    "status": "notchecked"
  },
  {
    "id": 98,
    "year": 2026,
    "title": "CenRL: A Framework for Performing Intelligent Censorship Measurements",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00098",
    "abstract": " Active Internet measurements are crucial for exposing the increasing frequency and severity of global Internet censorship. However, current measurement efforts are constrained by limited resources and time, and reacting to new censorship events remains a largely manual process reliant on rapid signals. As a result, creating a comprehensive and real-time picture of Internet censorship remains a key challenge. In this work, we introduce CenRL, an intelligent censorship measurement framework that leverages reinforcement learning to optimize and automate censorship measurements. We model the censorship measurement process as a multi-armed bandit problem and design CenRL agents to address two key tasks: maximizing the detection of blocked websites within a network and automatically responding to blocking changes in dynamic censorship environments. We demonstrate CenRL's effectiveness through realistic simulated experiments in three highly censored regions (China, Russia, and Kazakhstan) and real-world censorship measurements across vantage points in 15 countries with diverse censorship policies. Our controlled experiments demonstrate that CenRL significantly outperforms the state of the art measurement processes, finding 75% of blocked websites in less than half the number of measurements while identifying censorship changes up to seven times faster. Our real-world experiments confirm this advantage across multiple censorship environments, showing that CenRL can find 2.5 times more blocked websites on average compared to existing measurement strategies. Our study demonstrates the potential of using reinforcement learning to provide deeper insights into restrictions on online freedom. ",
    "status": "notchecked"
  },
  {
    "id": 99,
    "year": 2026,
    "title": "Nebula: Proving machine executions via folding schemes",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00099",
    "abstract": " A major bottleneck for these protocols is the prover’s space complexity, which grows linearly with the number of program steps and makes it impractical to produce proofs for long-running computations. To overcome this, we propose generating these proofs incrementally, using folding schemes. However, realizing this requires new tools in the folding setting: (1) an efficient read-write memory argument for proving the correctness of memory operations; and (2) a method to eliminate the overheads incurred by unused machine instructions when incrementally proving a program execution step. We address these with new techniques. First, we introduce commitment-carrying IVC, where a proof carries an incremental commitment to the prover’s non-deterministic advice provided at different steps. Second, we show how this unlocks efficient read-write memory arguments (which implies indexed lookups arguments), with a cost profile identical to that of memory arguments in the context of non-recursive arguments. Third, we provide a new universal “switchboard” circuit construction that combines circuits of different instructions such that one can “turn off” uninvoked circuit elements and constraints, offering a new way to achieve pay-per-use prover costs. We design an IVC scheme, which we refer to as Nebula, that incorporates these techniques. We implement a prototype of a Nebula-based zkVM for the Ethereum Virtual Machine (EVM). We find that our techniques qualitatively provide a 30× smaller constraint system to represent the EVM over standard memory-checking techniques, and lead to over 260× faster proof generation for the standard ERC-20 token transfer transaction when compared to our baseline Nova (CRYPTO’22) with existing arithmetization methods. ",
    "status": "notchecked"
  },
  {
    "id": 100,
    "year": 2026,
    "title": "New Constructions of Functional Adaptor Signatures: Broader Functions and Improved Efficiency",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00100",
    "abstract": " Functional adaptor signatures (FAS) are a novel cryptographic primitive introduced at CCS'24 that enable privacy-preserving, fine-grained data-payment exchanges between a seller and a buyer in a trustless and atomic manner. In this setup, the seller holds sensitive data (x) (e.g., patient records, climate data), and the buyer specifies a function (f) (e.g., aggregate, sum). FAS guarantees that the buyer learns (f(x)) (and nothing beyond) if and only if the seller receives payment in blockchain-based tokens. Unlike generic smart contracts, FAS-powered solutions excel in privacy, efficiency, and compatibility with diverse blockchain systems. However, prior FAS constructions were limited to linear functions (where f was linear in $x$), restricting their applicability to more complex and prevalent applications including data analytics and ML model evaluations. In this work, we extend the capabilities of FAS to support higher-degree functions (( \\textit{deg} \\geq 2 )), significantly broadening its range of applications. Our core contribution is a novel FAS design leveraging \\emph{homomorphic encryption}, which simultaneously achieves enhanced efficiency and compatibility for general functions. This approach diverges fundamentally from the restricted design in CCS'24 which relied on connections to functional encryption. We implement our homomorphic encryption-based FAS for functions arising in applications such as data analytics and machine learning inference. Remarkably, even for linear functions, our new design achieves an order-of-magnitude improvement in performance compared to CCS'24 constructions. Furthermore, our solutions seamlessly integrate with prominent blockchain systems, requiring only a basic signature verification script on standard transactions, thus ensuring practical deployability. As a conceptual contribution, we introduce the general paradigm of a blockchain-based \\emph{functional fair exchange} (FFE) protocol, rigorously define buyer- and seller-fairness, and show that FAS imply the general goal of FFE. ",
    "status": "notchecked"
  },
  {
    "id": 101,
    "year": 2026,
    "title": "TEE.fail: Breaking Trusted Execution Environments via DDR5 Memory Bus Interposition",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00101",
    "abstract": " Trusted execution environments (TEEs) aim to offer strong privacy and integrity guarantees even in the presence of root level attackers capable of arbitrarily modifying the system’s software. Recently however, there has been a pivotal shift in TEE deployment, moving TEEs from enclaves running on PC-oriented hardware to confidential virtual machines executing on server-grade CPUs. Under the hood, this change has also resulted in significant modifications to the underlying memory encryption engine, removing integrity guarantees and protections against replay attacks. While Intel's and AMD's change in TEE implementation is clearly significant and substantial, most TEE deployments appear to fail to acknowledge the difference in security guarantees, assuming a stronger security model than truly afforded by the implementation. Thus, in this work we investigate the true protection offered by Intel's and AMD's newest TEE offerings against entry-level physical side-channel attacks. We show that, contrary to popular belief, bus interposition attacks on DDR5 server memory can be constructed cheaply by hobbyists, using parts easily obtained on e-commerce websites. Next, combining our ability to monitor DDR5 bus transactions with deterministic memory encryption used by Intel’s SGX and TDX as well as AMD's SEV-SNP, we are able to extract secret key material (such as attestation keys in some cases) from machines in fully trusted status. Finally, we demonstrate the implications of our attacks on multiple real world TEE deployments. ",
    "status": "notchecked"
  },
  {
    "id": 102,
    "year": 2026,
    "title": "Fast Deterministically Safe Proof-of-Work Consensus",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00102",
    "abstract": " Permissionless blockchains achieve consensus while allowing unknown nodes to join and leave the system at any time. They typically come in two flavors: proof of work (PoW) and proof of stake (PoS), and both are vulnerable to attacks. PoS protocols suffer from long-range attacks, wherein attackers alter execution history at little cost, and PoW protocols are vulnerable to attackers with enough computational power to subvert execution history. PoS protocols respond by relying on external mechanisms like social consensus; PoW protocols either fall back to probabilistic guarantees, or are slow. We present Sieve-MMR, the first fully-permissionless protocol with deterministic security and constant expected latency that does not rely on external mechanisms. We obtain Sieve-MMR by porting a PoS protocol (MMR) to the PoW setting. From MMR we inherit constant expected latency and deterministic security, and proof-of-work gives us resilience against long-range attacks. The main challenge to porting MMR to the PoW setting is what we call time-travel attacks, where attackers use PoWs generated in the distant past to increase their perceived PoW power in the present. We respond by proposing Sieve, a novel algorithm that implements a new broadcast primitive we dub time-travel-resilient broadcast (TTRB). Sieve relies on black-box, deterministic PoW primitive to implement TTRB, which we use as the messaging layer for MMR. ",
    "status": "notchecked"
  },
  {
    "id": 103,
    "year": 2026,
    "title": "Credential Extraction Attacks Against Compromised Credential Checking Services of Password Managers",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00103",
    "abstract": " Password managers (PMs) are highly recommended by security standards and experts to assist users in managing their login credentials. In response to the increasingly serious threat of credential leakages, more and more leading PMs start to leverage third-party compromised credential checking (C3) services, aiming to help users check whether their credentials in the vault have been leaked. C3 services (e.g., Have I Been Pwned) generally maintain extensive datasets of leaked credentials and provide APIs for compromised credential checking. Queries to C3 services comply with k-anonymity security properties, designed to limit information leakage about credentials. However, these queries are deterministic, indicating that identical credentials consistently generate the same query. We find that PMs exhibit identifiable query patterns, such as automatically checking all credentials associated with a single user, and periodically checking users' credentials. We, for the first time, demonstrate that the query patterns of PMs can be effectively exploited by an honest-but-curious C3 server to identify PM users and extract credentials. We propose a novel credential extraction attack framework based on query pattern leakage to C3 services, and implement attack algorithms targeting PMs' query patterns. Our empirical attacks successfully identify 83.04%~87.59% of PM users. Furthermore, this query pattern leakage enables attackers to significantly increase the password guessing success rates by 15.42%$\\sim$30.43% with one guess, compared to attacks without leveraging this leakage. We evaluate 14 leading PMs, and find that 10 are vulnerable to our attacks. We have disclosed our findings along with recommendations to affected vendors for being aware of (and mitigating) these vulnerabilities. ",
    "status": "notchecked"
  },
  {
    "id": 104,
    "year": 2026,
    "title": "Consumer Beware! Exploring Data Brokers’ CCPA Compliance",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00104",
    "abstract": " Data brokers collect and sell the personal information of millions of individuals, often without their knowledge or consent. The California Consumer Privacy Act (CCPA) grants consumers the legal right to request access to, or deletion of, their data. To facilitate these requests, California maintains an official registry of data brokers. However, the extent to which these entities comply with the law is unclear. This paper presents the first large-scale, systematic study of CCPA compliance of all 543 officially registered data brokers. Data access requests were manually submitted to each broker, followed by in-depth analyses of their responses (or lack thereof). Above 40% failed to respond at all, in an apparent violation of the CCPA. Data brokers that responded requested personal information as part of their identity verification process, including details they had not previously collected. Paradoxically, this means that exercising one's privacy rights under CCPA introduces new privacy risks. Our findings reveal rampant non-compliance and lack of standardization of the data access request process. These issues highlight an urgent need for stronger enforcement, clearer guidelines, and standardized, periodic compliance checks to enhance consumers' privacy protections and improve data broker accountability. ",
    "status": "notchecked"
  },
  {
    "id": 105,
    "year": 2026,
    "title": "PromptLocate: Localizing Prompt Injection Attacks",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00105",
    "abstract": " Prompt injection attacks deceive a large language model into completing an attacker-specified task instead of its intended task by contaminating its input data with an injected prompt, which consists of injected instruction(s) and data. Localizing the injected prompt within contaminated data is crucial for post-attack forensic analysis and data recovery. Despite its growing importance, prompt injection localization remains largely unexplored. In this work, we bridge this gap by proposing PromptLocate, the first method for localizing injected prompts. PromptLocate comprises three steps: (1) splitting the contaminated data into semantically coherent segments, (2) identifying segments contaminated by injected instructions, and (3) pinpointing segments contaminated by injected data. We show PromptLocate accurately localizes injected prompts across eight existing and eight adaptive attacks. Our code and data are available at: https://github.com/liu00222/Open-Prompt-Injection. ",
    "status": "notchecked"
  },
  {
    "id": 106,
    "year": 2026,
    "title": "KeyTAR: Practical Keystroke Timing Attacks and Input Reconstruction",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00106",
    "abstract": " Keystroke timing attacks have long been recognized as a serious security concern. Researchers have conjectured that an attacker who learns the amount of time that elapses between keystrokes on a computer keyboard can reconstruct the keys pressed by a victim typist. Given the severe implications of a successful keystroke timing attack, numerous published side-channel works have utilized keystroke timing extraction as a case study to illustrate the impact of various types of side-channel attacks. However, despite an abundance of works demonstrating extraction of inter-keystroke timings, it remains to be proven that input recovery is actually possible. This paper bridges this long-standing gap in the literature and performs a comprehensive study on the feasibility of reconstructing typed input from inter-keystroke timings. We model input reconstruction as a machine translation task and fine-tune open-source Large Language Models (LLMs) with a curriculum learning strategy, leveraging their ability to utilize contextual information and incorporate semantic understanding into the reconstruction process. With this approach, we reconstruct typed input with a high degree of fidelity. Using the best reconstruction among the Top-5 predictions and a normalized edit distance threshold of 0.1 as the criterion for successful reconstruction, we achieve a success rate of 34.9%. We also demonstrate input reconstruction under practical, real-world circumstances, where additional noise is introduced to the inter-keystroke timing traces. We conduct end-to-end cache attacks, both from native environments and from the Chrome browser, and quantify how the additional noise inherent to cache attacks affects the input recovery process. To obtain a sufficiently large dataset for training and fine-tuning the LLM for noisy traces extracted via cache-attacks, we replayed over 1.5 million typing samples from real human typists while performing cache attacks. We release and open-source this dataset, along with our code and checkpoint for reconstructing input, so that future works on keystroke-timing attacks can rigorously and empirically evaluate their effectiveness. ",
    "status": "notchecked"
  },
  {
    "id": 107,
    "year": 2026,
    "title": "SoK: Robustness in Large Language Models against Jailbreak Attacks",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00107",
    "abstract": " Large Language Models (LLMs) have achieved remarkable success but remain highly susceptible to jailbreak attacks, where adversarial prompts that coerce models into generating harmful, unethical, or policy-violating outputs. Such attacks pose real-world risks, eroding safety, trust, and regulatory compliance in high-stakes applications. Although a variety of attack and defense methods have been proposed, existing evaluation practices are inadequate, often relying on narrow metrics like attack success rate that fail to capture the multidimensional nature of LLM security. In this paper, we present a systematic taxonomy of jailbreak attacks and defenses and introduce Security Cube, a unified, multi-dimensional framework for comprehensive evaluation of these techniques. We provide detailed comparison tables of existing attacks and defenses, highlighting key insights and open challenges across the literature. Leveraging Security Cube, we conduct benchmark studies on 13 representative attacks and 5 defenses, establishing a clear view of the current landscape encompassing jailbreak attacks, defenses, automated judges, and LLM vulnerabilities. Based on these evaluations, we distill critical findings, identify unresolved problems, and outline promising research directions for enhancing LLM robustness against jailbreak attacks. Our analysis aims to pave the way towards more robust, interpretable, and trustworthy LLM systems. Our code is available at Code. ",
    "status": "notchecked"
  },
  {
    "id": 108,
    "year": 2026,
    "title": "The First Large-Scale Systematic Study of Python Class Pollution Vulnerability",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00108",
    "abstract": " Class pollution is a recently discovered, yet underexplored Python vulnerability that allows attackers to pollute unintended runtime objects by exploiting the class-based inheritance model and reflection mechanism. Before this paper, only two real-world vulnerabilities related to class pollution---including one reported to the Common Vulnerabilities and Exposures (CVE) database---were discovered. Furthermore, there was no existing tool capable of detecting such vulnerabilities, let alone a systematic study of vulnerable code patterns, exploitation techniques, and real-world prevalence. In this paper, we design and implement Pyrl, the first framework for detecting class pollution vulnerabilities in real-world applications via a novel, static operational taint analysis. Our key insight is that class pollution consists of two types of vulnerable code primitives---gets and sets---for fetching and setting items and attributes. Different combinations of these primitives (two types of gets and three sets) further lead to six unique vulnerability types according to our first taxonomy of class pollution. Pyrl's operational taint analysis tracks attacker-controlled inputs on these primitives and their combinations using fine-grained, operational taint labels that are initiated, transformed, propagated, and merged according to the analysis context. We applied Pyrl to over half a million real-world Python programs from GitHub and PyPI, resulting in the detection of 47 zero-day, exploitable class pollutions. Our findings include critical vulnerabilities in widely used applications, such as Azure CLI by Microsoft and Mesop by Google, both of which have been acknowledged and patched. We have responsibly reported all identified vulnerabilities to the corresponding developers---who fixed five of them---and CVE Numbering Authorities (CNAs)---who assigned seven CVE identifiers. ",
    "status": "notchecked"
  },
  {
    "id": 109,
    "year": 2026,
    "title": "Jigsaw: Doubly Private Smart Contracts",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00109",
    "abstract": " Privacy is a growing concern for smart contracts on public ledgers. In recent years, we have seen several practical systems for privacy-preserving smart contracts, but they only target privacy of on-chain data, and rely on trusted off-chain parties with user data -- for instance, a decentralized finance application (e.g. exchange) relies on an off-chain matching engine to process client orders that get settled on-chain, where privacy only applies to the on-chain data. Privacy conscious users demand stronger notions of privacy, for their identity and their data, from all other parties in the ecosystem. We propose a novel framework for smart contracts that ensures {\\em doubly private} execution, addressing {both on-chain and off-chain privacy} requirements. In our framework, clients submit their requests in a privacy-preserving manner to a group of (potentially mutually untrusting) servers. These servers collaboratively match client requests without learning any information about the data or identities of the clients. We then present {\\em Jigsaw}, an efficient cryptographic realization of our proposed framework. {\\em Jigsaw} builds on the ZEXE architecture (Bowe et al., S\\&P 2020), which leverages zkSNARKs, and extends Collaborative zkSNARKs (Ozdemir and Boneh, USENIX 2022) to enable proof generation by a group of servers. In Jigsaw, we introduce a novel collaborative zkSNARK construction that achieves low latency and reduced proving time, and showcase these advantages over sample applications ranging from trading in a decentralized exchange to auctions and voting. Our experiments demonstrate that {\\em Jigsaw} is roughly $40-50$x faster in proof generation and uses orders-of-magnitude less bandwidth than the naive approach of using off-the-shelf Collaborative zkSNARKs. ",
    "status": "notchecked"
  },
  {
    "id": 110,
    "year": 2026,
    "title": "Cottontail: Large Language Model-Driven Concolic Execution for Highly Structured Test Input Generation",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00110",
    "abstract": " How can we perform concolic execution to generate highly structured test inputs for systematically testing parsing programs? Existing concolic execution engines are significantly restricted by (1) input structure-agnostic path constraint selection, leading to the waste of testing effort or missing coverage; (2) limited constraint-solving capability, yielding many syntactically invalid test inputs; (3) reliance on manual acquisition of highly structured seed inputs, resulting in non-continuous testing. This paper proposes Cottontail, a new Large Language Model (LLM)-driven concolic execution engine, to mitigate the above limitations. A more complete program path representation, named Expressive Coverage Tree (ECT), is first constructed to help select structure-aware path constraints. Later, an LLM-driven constraint solver based on a Solve-Complete paradigm is designed to solve the path constraints smartly to get test inputs that are not only satisfiable to the constraints but also valid to the input syntax. Finally, a history-guided seed acquisition is employed to obtain new highly structured test inputs either before testing starts or after testing is saturated. We implemented Cottontail on top of SymCC and evaluated eight extensively tested open-source libraries across four different formats (XML, SQL, JavaScript, and JSON). The experimental result is promising: Cottontail significantly outperforms baseline approaches by 30.73% and 41.32% on average in terms of line and branch coverage. Besides, Cottontail found six previously unknown vulnerabilities (six CVEs assigned). We have reported these issues to developers, and four out of them have been fixed so far. ",
    "status": "notchecked"
  },
  {
    "id": 111,
    "year": 2026,
    "title": "LLMs in the SOC: An Empirical Study of Human-AI Collaboration in Security Operations Centres",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00111",
    "abstract": " The integration of Large Language Models (LLMs) into Security Operations Centres (SOCs) presents a transformative, yet still evolving, opportunity to reduce analyst workload through human-AI collaboration. However, their real-world application in SOCs remains underexplored. To address this gap, we present a longitudinal study of 3,090 analyst queries from 45 SOC analysts over 10 months. Our analysis reveals that analysts use LLMs as on-demand aids for sensemaking and context-building, rather than for making high-stakes determinations, preserving analyst decision authority. The majority of queries are related to interpreting low-level telemetry (e.g., commands) and refining technical communication through short (1-3 turn) interactions. Notably, 93% of queries align with established cybersecurity competencies (NICE Framework), underscoring the relevance of LLM use for SOC-related tasks. Despite variations in tasks and engagement, usage trends indicate a shift from occasional exploration to routine integration, with growing adoption and sustained use among analysts. We find that LLMs function as flexible, on-demand cognitive aids that augment, rather than replace, SOC expertise. Our study provides actionable guidance for designing context-aware, human-centred AI assistance in security operations, highlighting the need for further in-the-wild research on real-world analyst-LLM collaboration, challenges, and impacts. ",
    "status": "notchecked"
  },
  {
    "id": 112,
    "year": 2026,
    "title": "DREAM: Scalable Red Teaming for Text-to-Image Generative Systems via Distribution Modeling",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00112",
    "abstract": " Despite the integration of safety alignment and external filters, text-to-image (T2I) generative systems are still susceptible to producing harmful content, such as sexual or violent imagery. This raises serious concerns about unintended exposure and potential misuse. Red teaming, which aims to proactively identify diverse prompts that can elicit unsafe outputs from the T2I system, is increasingly recognized as an essential method for assessing and improving safety before real-world deployment. However, existing automated red teaming approaches often treat prompt discovery as an isolated, prompt-level optimization task, which limits their scalability, diversity, and overall effectiveness. To bridge this gap, in this paper, we propose DREAM, a scalable red teaming framework to automatically uncover diverse problematic prompts from a given T2I system. Unlike prior work that optimizes prompts individually, DREAM directly models the probabilistic distribution of the target system's problematic prompts, which enables explicit optimization over both effectiveness and diversity, and allows efficient large-scale sampling after training. To achieve this without direct access to representative training samples, we draw inspiration from energy-based models and reformulate the objective into a simple and tractable form. We further introduce GC-SPSA, an efficient optimization algorithm that provides stable gradient estimates through the long and potentially non-differentiable T2I pipeline. During inference, we also propose a diversity-aware sampling strategy to enhance prompt variety. The effectiveness of DREAM is validated through extensive experiments, demonstrating state-of-the-art performance across a wide range of T2I models and safety filters in terms of both prompt success rate and diversity. Our code is available at https://github.com/AntigoneRandy/DREAM ",
    "status": "notchecked"
  },
  {
    "id": 113,
    "year": 2026,
    "title": "Sort, Sweep, Mirror: Batch Private Interval Lookup with Logarithmic Cost",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00113",
    "abstract": " Secure multiparty computation often requires table lookups and piecewise polynomial evaluation for efficiency. Hiding both the table and the accessed entries is essential. Existing work on private lookup table (LUT) protocols either incurs $\\Omega(mL)$ computation and communication (Eurocrypt '24) or is optimized for small tables (NDSS '25), where $m$ is the output bitwidth and $L = 2^{\\ell}$ for input bitwidth $\\ell$. Realizing $\\mathcal{O}(\\ell \\log L)$ communication and $\\mathcal{O}((\\ell + m) \\log L)$ computation per query for the first time, we propose a batch private LUT protocol that overcomes these limitations by processing $K$ lookups with $\\mathcal{O}(K \\log L)$ secure comparisons. More generally, our approach extends to private interval LUT (ILUT), enabling efficient interval-based lookups in batches. Applications include private machine learning over a large input range, which small LUTs cannot approximate accurately. Notably, it supports inverse-square-root approximation and secure multiplication common in quantized neural networks, where outputs are dependent on the private model weights. Systematic experiments demonstrate that our protocol reduces communication by $10.56$- to $1984$-fold over the state of the art for private LUTs with tables ranging from $2^{16}$ to $2^{24}$ entries. Moreover, it supports ${>}2^{11}$ lookups per second for a $2^{24}$-entry table in a local-area network and ${>}2^{9}$ in a wide-area network. ",
    "status": "notchecked"
  },
  {
    "id": 114,
    "year": 2026,
    "title": "SoK: Systematizing a Decade of Architectural RowHammer Defenses Through the Lens of Streaming Algorithms",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00114",
    "abstract": " A decade after its academic introduction, RowHammer (RH) remains a moving target that continues to challenge both the industry and academia. With its potential to serve as a critical attack vector, the ever-decreasing RH threshold now threatens DRAM process technology scaling, with a superlinearly increasing cost of RH protection solutions. Due to their generality and relatively lower performance costs, architectural RH solutions are the first line of defense against RH. However, the field is fragmented with varying views of the problem, terminologies, and even threat models. In this paper, we systematize architectural RH defenses from the last decade through the lens of streaming algorithms. We provide a taxonomy that encompasses 48 different works. We map multiple architectural RH defenses to the classical streaming algorithms, which extends to multiple proposals that did not identify this link. We also provide two practitioner guides. The first guide analyzes which algorithm best fits a given RHTH, location, process technology, storage type, and mitigative action. The second guide encourages future research to consult existing algorithms when architecting RH defenses. We illustrate this by demonstrating how Reservoir-Sampling can improve related RH defenses, and also introduce Sticky-Sampling that can provide mathematical security that related studies do not guarantee. ",
    "status": "notchecked"
  },
  {
    "id": 115,
    "year": 2026,
    "title": "Best of Both Worlds: Effective Foreign Bridge Identification in V8 Embedders for Security Analysis",
    "category": "top-tier",
    "publication": "IEEE S&P",
    "paper": "https://doi.ieeecomputersociety.org/10.1109/SP63933.2026.00115",
    "abstract": " Modern JavaScript applications increasingly rely on native extensions and WebAssembly modules for performance-critical functionality. This multi-language architecture, however, introduces attack surfaces in native code that may be exploitable via JavaScript interfaces. Effective cross-language security analysis depends on accurately identifying bridges, i.e., connection points where JavaScript functions delegate to native or WebAssembly code. Yet, existing approaches often struggle to cover all such bridges or produce false positives, due to the diversity of foreign function interfaces in JavaScript. We present GASKET, a novel dynamic analysis tool that effectively identifies bridges between JavaScript and low-level code. The key insight behind GASKET is that regardless of the binding framework or runtime used, all function objects are ultimately represented as uniform internal structures within the JavaScript engine (e.g., V8). By analyzing the memory layout of these structures, GASKET effortlessly identifies the native or WebAssembly functions bound to JavaScript high-level constructs, even across diverse binding frameworks and execution environments. Our evaluation demonstrates that GASKET achieves perfect recall while incurring no false positives. When integrated with existing security tools across 1,266 npm packages, GASKET enables the detection of 54 additional vulnerable flows in 23 packages that were missed by prior approaches due to incomplete bridge identification. Among these flows, 19 are confirmed to be exploitable vulnerabilities. Beyond discovering new vulnerabilities, GASKET also benefits software supply chain analysis: in a systematic study of ∼2K dependent packages, we find that although many depend on vulnerable native extensions, only a small fraction actually invoke vulnerable functions. This allows for reduced alert fatigue and actionable security insights. ",
    "status": "notchecked"
  }
]