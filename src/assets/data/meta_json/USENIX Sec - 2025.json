[
  {
    "id": 3575,
    "year": 2025,
    "title": "Analyzing the AI Nudification Application Ecosystem",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/gibson",
    "abstract": "Given a source image of a clothed person (an image subject), AI-based nudification applications can produce nude (undressed) images of that person. Moreover, not only do such applications exist, but there is ample evidence of the use of such applications in the real world and without the consent of an image subject. Still, despite the growing awareness of the existence of such applications and their potential to violate the rights of image subjects and cause downstream harms, there has been no systematic study of the nudification application ecosystem across multiple applications. We conduct such a study here, focusing on 20 popular and easy-to-find nudification websites. We study the positioning of these web applications (e.g., finding that most sites explicitly target the nudification of women, not all people), the features that they advertise (e.g., ranging from undressing-in-place to the rendering of image subjects in sexual positions, as well as differing user-privacy options), and their underlying monetization infrastructure (e.g., credit cards and cryptocurrencies). We believe this work will empower future, data-informed conversations—within the scientific, technical, and policy communities—on how to better protect individuals' rights and minimize harm in the face of modern (and future) AI-based nudification applications.\nredContent warning: This paper includes descriptions of web applications that can be used to create synthetic non-consensual explicit AI-created imagery (SNEACI). This paper also includes an artistic rendering of a user interface for such an application."
  },
  {
    "id": 3576,
    "year": 2025,
    "title": "Easy As Child's Play: An Empirical Study on Age Verification of Adult-Oriented Android Apps",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/yao-yifan",
    "abstract": "The rapid growth of mobile apps has provided convenience and entertainment, including adult-oriented apps for users 18 and older. Despite various strategies to prevent minors from accessing such content, the effectiveness of these measures remains uncertain. This paper investigates these mechanisms and proposes a novel detection solution: GUARD (Guarding Underage Access Restriction Detection). GUARD determines relevant components (e.g., those that can accept the user's age or birthdate) based on the spatial relationships of the components in a layout and tracks the data flows through taint analysis. Recognizing static analysis limitations, GUARD also dynamically interacts with apps to identify age-related input components, which are then used for precise taint analysis. Our analysis of 31,750 adult-only apps (out of 693,334 apps on Google Play) reveals that only 1,165 (3.67%) implement age verification, with the majority relying on the weakest method, the age gate (which simply asks users if they are over 18). Even apps with stronger age verification (e.g., document uploads, online ID verification) can be bypassed using simple methods like false IDs or fake documents. They can also be circumvented through accounts from services without age checks (e.g., OAuth abuse) or by exploiting regional differences via VPNs. This paper also proposes countermeasures to enhance the effectiveness of age verification methods, which received positive feedback from Google through our email exchanges."
  },
  {
    "id": 3577,
    "year": 2025,
    "title": "Abusability of Automation Apps in Intimate Partner Violence",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/zhang-shirley",
    "abstract": "Automation apps such as iOS Shortcuts and Android Tasker enable users to \"program\" new functionalities, also called recipes, on their smartphones. For example, users can create recipes to set the phone to silent mode once they arrive at their office or save a note when an email is received from a particular sender. These automation apps provide convenience and can help improve productivity. However, these automation apps can also provide new avenues for abuse, particularly in the context of intimate partner violence (IPV). This paper systematically explores the potential of automation apps to be used for surveillance and harassment in IPV scenarios. We analyze four popular automation apps—iOS Shortcuts, Samsung Modes & Routines, Tasker, and IFTTT—evaluating their capabilities to facilitate surveillance and harassment. Our study reveals that these tools can be exploited by abusers today to monitor, impersonate, overload, and control their victims. The current notification and logging mechanisms implemented in these automation apps are insufficient to warn the victim about the abuse or to help them identify the root cause and stop it. We therefore built a detection mechanism to identify potentially malicious Shortcuts recipes and tested it on 12,962 publicly available Shortcuts recipes. We found 1,014 recipes that can be used to surveil and harass others. We then discuss how users and platforms mitigate such abuse potential of automation apps."
  },
  {
    "id": 3578,
    "year": 2025,
    "title": "Malicious LLM-Based Conversational AI Makes Users Reveal Personal Information",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/zhan",
    "abstract": "LLM-based Conversational AIs (CAIs), also known as GenAI chatbots, like ChatGPT, are increasingly used across various domains, but they pose privacy risks, as users may disclose personal information during their conversations with  CAIs. Recent research has demonstrated that LLM-based CAIs could be used for malicious purposes. However, a novel and particularly concerning type of malicious LLM application remains unexplored: an LLM-based CAI that is deliberately designed to extract personal information from users. In this paper, we report on the malicious LLM-based CAIs that we created based on system prompts that used different strategies to encourage disclosures of personal information from users. We systematically investigate CAIs' ability to extract personal information from users during conversations by conducting a randomized-controlled trial with 502 participants. We assess the effectiveness of different malicious and benign CAIs to extract personal information from participants, and we analyze participants' perceptions after their interactions with the CAIs. Our findings reveal that malicious CAIs extract significantly more personal information than benign CAIs, with strategies based on the social nature of privacy being the most effective while minimizing perceived risks. This study underscores the privacy threats posed by this novel type of malicious LLM-based CAIs and provides actionable recommendations to guide future research and practice."
  },
  {
    "id": 3579,
    "year": 2025,
    "title": "An Industry Interview Study of Software Signing for Supply Chain Security",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/kalu",
    "abstract": "Many software products are composed of components integrated from other teams or external parties. Each additional link in a software product's supply chain increases the risk of the injection of malicious behavior. To improve supply chain provenance, many cybersecurity frameworks, standards, and regulations recommend the use of software signing. However, recent surveys and measurement studies have found that the adoption rate and quality of software signatures are low. We lack in-depth industry perspectives on the challenges and practices of software signing. \nTo understand software signing in practice, we interviewed 18 experienced security practitioners across 13 organizations. We study the challenges that affect the effective implementation of software signing in practice. We also provide possible impacts of experienced software supply chain failures, security standards, and regulations on software signing adoption. To summarize our findings: (1) We present a refined model of the software supply chain factory model highlighting practitioner's signing practices; (2) We highlight the different challenges–technical, organizational, and human–that hamper software signing implementation; (3) We report that experts disagree on the importance of signing; and (4) We describe how internal and external events affect the adoption of software signing. Our work describes the considerations for adopting software signing as one aspect of the broader goal of improved software supply chain security."
  },
  {
    "id": 3580,
    "year": 2025,
    "title": "Voluntary Investment, Mandatory Minimums, or Cyber Insurance: What Minimizes Losses?",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/hastings",
    "abstract": "In recent years there has been significant interest from policymakers in addressing ransomware through policy and regulations, yet this process remains far more of an art than a science. This paper introduces a novel method for quantitatively evaluating policy proposals: we create a simulated game theoretic agent-based economic model of security and use it as a testbed for several policy interventions, including a hands-off approach, mandatory minimum investments, and mandatory cyber insurance. Notably, we find that the bottleneck for better security outcomes lies not in better defender decision-making but in improved coordination between defenders: using our model, we find that a policy requiring defenders to invest at least 2% of resources into security each round produces better overall outcomes than leaving security investment decisions to defenders even when the defenders are \"perfect play\" utility maximizers. This provides evidence that security is a weakest-link game and makes the case for mandatory security minimums. Using our model, we also find that cyber insurance does little to improve overall outcomes. To make our tool accessible to others, we have made the code open source and released it as an online web application."
  },
  {
    "id": 3581,
    "year": 2025,
    "title": "A First Look at Governments' Enterprise Security Guidance",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/ruth",
    "abstract": "To combat the deluge of enterprise breaches, government agencies have developed and published a wealth of cybersecurity guidance for organizations. However, little research has studied this advice. In this paper, we conduct the first systematic analysis of government guidance for enterprise security. We curate a corpus of prominent guidance documents from 41 countries and analyze the availability of advice, the coverage provided by the advice, and the consistency of advice across countries. To facilitate detailed analysis and comparisons, we develop a tree-based taxonomy and quantitative comparison metric, and then apply these tools to analyze \"essential\" enterprise best practice documents from ten countries. Our results highlight a lack of consensus among the governments' frameworks we analyzed—even among close allies—about what security measures to recommend and how to present guidance."
  },
  {
    "id": 3582,
    "year": 2025,
    "title": "SoK: Can Synthetic Images Replace Real Data? A Survey of Utility and Privacy of Synthetic Image Generation",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/chung-yunsung",
    "abstract": "Advances in generative models have transformed the field of synthetic image generation for privacy-preserving data synthesis (PPDS). However, the field lacks a comprehensive survey and comparison of synthetic image generation methods across diverse settings. In particular, when we generate synthetic images for the purpose of training a classifier, there is a pipeline of generation-sampling-classification which takes private training as input and and outputs the final classifier of interest. In this survey, we systematically categorize existing image synthesis methods, privacy attacks, and mitigations along this generation-sampling-classification pipeline. To empirically compare diverse synthesis approaches, we provide a benchmark with representative generative methods and use model-agnostic membership inference attacks (MIAs) as a measure of privacy risk. Through this study, we seek to answer critical questions in PPDS: Can synthetic data effectively replace real data? Which release strategy balances utility and privacy? Do mitigations improve the utility-privacy tradeoff? Which generative models perform best across different scenarios? With a systematic evaluation of diverse methods, our study provides actionable insights into the utilty-privacy tradeoffs of synthetic data generation methods and guides the decision on optimal data releasing strategies for real-world applications."
  },
  {
    "id": 3583,
    "year": 2025,
    "title": "Characterizing and Detecting Propaganda-Spreading Accounts on Telegram",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/kireev",
    "abstract": "Information-based attacks on social media, such as disinformation campaigns and propaganda, are emerging cybersecurity threats. The security community has focused on countering these threats on social media platforms like X and Reddit. However, they also appear in instant-messaging social media platforms such as WhatsApp, Telegram, and Signal. In these platforms, information-based attacks primarily happen in groups and channels, requiring manual moderation efforts by channel administrators. We collect, label, and analyze a large dataset of more than 17 million Telegram comments and messages. Our analysis uncovers two independent, coordinated networks that spread pro-Russian and pro-Ukrainian propaganda, garnering replies from real users. We propose a novel mechanism for detecting propaganda that capitalizes on the relationship between legitimate user messages and propaganda replies and is tailored to the information that Telegram makes available to moderators. Our method is faster, cheaper, and has a detection rate (97.6%) 11.6 percentage points higher than human moderators after seeing only one message from an account. It remains effective despite evolving propaganda."
  },
  {
    "id": 3584,
    "year": 2025,
    "title": "GradEscape: A Gradient-Based Evader Against AI-Generated Text Detectors",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/meng",
    "abstract": "In this paper, we introduce GradEscape, the first gradient-based evader designed to attack AI-generated text (AIGT) detectors. GradEscape overcomes the undifferentiable computation problem, caused by the discrete nature of text, by introducing a novel approach to construct weighted embeddings for the detector input. It then updates the evader model parameters using feedback from victim detectors, achieving high attack success with minimal text modification. To address the issue of tokenizer mismatch between the evader and the detector, we introduce a warm-started evader method, enabling GradEscape to adapt to detectors across any language model architecture. Moreover, we employ novel tokenizer inference and model extraction techniques, facilitating effective evasion even in query-only access.\nWe evaluate GradEscape on four datasets and three widely-used language models, benchmarking it against four state-of-the-art AIGT evaders. Experimental results demonstrate that GradEscape  outperforms existing evaders in various scenarios, including with an 11B paraphrase model, while utilizing only 139M parameters. We have successfully applied GradEscape to two real-world commercial AIGT detectors. Our analysis reveals that the primary vulnerability stems from disparity in text expression styles within the training data. We also propose a potential defense strategy to mitigate the threat of AIGT evaders. We open-source our GradEscape for developing more robust AIGT detectors."
  },
  {
    "id": 3585,
    "year": 2025,
    "title": "Provably Robust Multi-bit Watermarking for AI-generated Text",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/qu-watermarking",
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities of generating texts resembling human language. However, they can be misused by criminals to create deceptive content, such as fake news and phishing emails, which raises ethical concerns. Watermarking is a key technique to address these concerns, which embeds a message (e.g., a bit string) into a text generated by an LLM. By embedding the user ID (represented as a bit string) into generated texts, we can trace generated texts to the user, known as content source tracing. The major limitation of existing watermarking techniques is that they achieve sub-optimal performance for content source tracing in real-world scenarios. The reason is that they cannot accurately or efficiently extract a long message from a generated text. We aim to address the limitations.\nIn this work, we introduce a new watermarking method for LLM-generated text grounded in pseudo-random segment assignment. We also propose multiple techniques to further enhance the robustness of our watermarking algorithm. We conduct extensive experiments to evaluate our method. Our experimental results show that our method achieves a much better tradeoff between extraction accuracy and time complexity, compared with existing baselines. For instance, when embedding a message of length 20 into a 200-token generated text, our method achieves a match rate of 97.6%, while the state-of-the-art work Yoo et al. only achieves 49.2%. Additionally, we prove that our watermark can tolerate edits within an edit distance of 17 on average for each paragraph under the same setting."
  },
  {
    "id": 3586,
    "year": 2025,
    "title": "HateBench: Benchmarking Hate Speech Detectors on LLM-Generated Content and Hate Campaigns",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/shen",
    "abstract": "Large Language Models (LLMs) have raised increasing concerns about their misuse in generating hate speech. Among all the efforts to address this issue, hate speech detectors play a crucial role. However, the effectiveness of different detectors against LLM-generated hate speech remains largely unknown. In this paper, we propose HateBench, a framework for benchmarking hate speech detectors on LLM-generated hate speech. We first construct a hate speech dataset of 7,838 samples generated by six widely-used LLMs covering 34 identity groups, with meticulous annotations by three labelers. We then assess the effectiveness of eight representative hate speech detectors on the LLM-generated dataset. Our results show that while detectors are generally effective in identifying LLM-generated hate speech, their performance degrades with newer versions of LLMs. We also reveal the potential of LLM-driven hate campaigns, a new threat that LLMs bring to the field of hate speech detection. By leveraging advanced techniques like adversarial attacks and model stealing attacks, the adversary can intentionally evade the detector and automate hate campaigns online. The most potent adversarial attack achieves an attack success rate of 0.966, and its attack efficiency can be further improved by 13-21x through model stealing attacks with acceptable attack performance. We hope our study can serve as a call to action for the research community and platform moderators to fortify defenses against these emerging threats."
  },
  {
    "id": 3587,
    "year": 2025,
    "title": "EmbedX: Embedding-Based Cross-Trigger Backdoor Attack Against Large Language Models",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/yan-nan",
    "abstract": "Large language models (LLMs) nowadays have attracted an affluent user base due to the superior performance across various downstream tasks. Yet, recent works reveal that LLMs are vulnerable to backdoor attacks, where an attacker can inject a specific token trigger to manipulate the model's behaviors during inference. Existing efforts have largely focused on single-trigger attacks while ignoring the variations in different users' responses to the same trigger, thus often resulting in undermined attack effectiveness. In this work, we propose EmbedX, an effective and efficient cross-trigger backdoor attack against LLMs. Specifically, EmbedX exploits the continuous embedding vector as the soft trigger for backdooring LLMs, which enables trigger optimization in the semantic space. By mapping multiple tokens into the same soft trigger, EmbedX establishes a backdoor pathway that links these tokens to the attacker's target output. To ensure the stealthiness of EmbedX, we devise a latent adversarial backdoor mechanism with dual constraints in frequency and gradient domains, which effectively crafts the poisoned samples close to the target samples. Through extensive experiments on four popular LLMs across both classification and generation tasks, we show that EmbedX achieves the attack goal effectively, efficiently, and stealthily while also preserving model utility."
  },
  {
    "id": 3588,
    "year": 2025,
    "title": "Mind the Inconspicuous: Revealing the Hidden Weakness in Aligned LLMs' Refusal Boundaries",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/yu-jiahao",
    "abstract": "Recent advances in Large Language Models (LLMs) have led to impressive alignment—where models learn to distinguish harmful from harmless queries through supervised fine-tuning (SFT) and reinforcement learning from human feedback (RLHF). In this paper, we reveal a subtle yet impactful weakness in these aligned models. We find that simply appending multiple end-of-sequence (eos) tokens can cause a phenomenon we call \"context segmentation\", which effectively shifts both \"harmful\" and \"benign\" inputs closer to the refusal boundary in the hidden space. \nBuilding on this observation, we propose a straightforward method to BOOST jailbreak attacks by appending eos tokens. Our systematic evaluation shows that this strategy significantly increases the attack success rate across 8 representative jailbreak techniques and 16 open-source LLMs, ranging from 2B to 72B parameters. Moreover, we develop a novel probing mechanism for commercial APIs and discover that major providers—such as OpenAI, Anthropic, and Qwen—do not filter eos tokens, making them similarly vulnerable. These findings highlight a hidden yet critical blind spot in existing alignment and content filtering approaches.\nWe call for heightened attention to eos tokens' unintended influence on model behaviors, particularly in production systems. Our work not only calls for an input-filtering based defense, but also points to new defenses that make refusal boundaries more robust and generalizable, as well as fundamental alignment techniques that can defend against context segmentation attacks."
  },
  {
    "id": 3589,
    "year": 2025,
    "title": "Game of Arrows: On the (In-)Security of Weight Obfuscation for On-Device TEE-Shielded LLM Partition Algorithms",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/wang-pengli",
    "abstract": "Utilizing Trusted Execution Environments (TEEs) to protect Large Language Models (LLMs) on users' devices is a practical solution for model owners. To alleviate the computation burden on TEEs, researchers have proposed TEE-Shielded LLM Partition (TSLP) to offload heavy computation layers to co-operating untrusted GPUs, while lightweight layers are shielded in TEE. TSLP utilizes various lightweight obfuscation schemes to protect offloaded weights from various attacks meanwhile not introducing large computation overhead. However, existing lightweight obfuscation algorithms have one vital vulnerability in common: the direction similarity of obfuscated vectors. In this paper, we propose a novel attack, ArrowMatch, that utilizes direction similarity to recover obfuscated private weights. To achieve this, ArrowMatch compares direction distances between obfuscated model weights and public pre-trained model weights. To mitigate this vulnerability, we propose a novel obfuscation scheme, ArrowCloak, which leverages lightweight matrix-vector multiplication to protect vector directions and private weights. We evaluate ArrowMatch and ArrowCloak on four representative LLMs, using seven datasets, along with five obfuscation schemes. The results show that ArrowMatch can break the protection of all existing lightweight obfuscation schemes with high accuracy (similar to no protection) and effectively recover the private weights (with over 98% accuracy). In addition, ArrowCloak can effectively defend against ArrowMatch (6.5X better than state of the art) and protect direction information by increasing the direction distance over 900X. We also evaluate the performance of ArrowCloak on a real-world Intel SGX device and show that ArrowCloak can reduce total overhead by 2.83X compared to shield-the-whole baseline."
  },
  {
    "id": 3590,
    "year": 2025,
    "title": "LLMmap: Fingerprinting for Large Language Models",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/pasquini",
    "abstract": "We introduce LLMmap, a first-generation fingerprinting technique targeted at LLM-integrated applications. LLMmap employs an active fingerprinting approach, sending carefully crafted queries to the application and analyzing the responses to identify the specific LLM version in use. Our query selection is informed by domain expertise on how LLMs generate uniquely identifiable responses to thematically varied prompts. With as few as 8 interactions, LLMmap can accurately identify 42 different LLM versions with over 95% accuracy. More importantly, LLMmap is designed to be robust across different application layers, allowing it to identify LLM versions —whether open-source or proprietary— from various vendors, operating under various unknown system prompts, stochastic sampling hyperparameters, and even complex generation frameworks such as RAG or Chain-of-Thought. We discuss potential mitigations and demonstrate that, against resourceful adversaries, effective countermeasures may be challenging or even unrealizable."
  },
  {
    "id": 3591,
    "year": 2025,
    "title": "Refusal Is Not an Option: Unlearning Safety Alignment of Large Language Models",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/song-minkyoo",
    "abstract": "Safety alignment has become an indispensable procedure to ensure the safety of large language models (LLMs), as they are reported to generate harmful, privacy-sensitive, and copy-righted content when prompted with adversarial instructions. Machine unlearning is a representative approach to establishing the safety of LLMs, enabling them to forget problematic training instances and thereby minimize their influence. However, no prior study has investigated the feasibility of adversarial unlearning—using seemingly legitimate unlearning requests to compromise the safety of a target LLM.\nIn this paper, we introduce novel attack methods designed to break LLM safety alignment through unlearning. The key idea lies in crafting unlearning instances that cause the LLM to forget its mechanisms for rejecting harmful instructions. Specifically, we propose two attack methods. The first involves explicitly extracting rejection responses from the target LLM and feeding them back for unlearning. The second attack exploits LLM agents to obscure rejection responses by merging them with legitimate-looking unlearning requests, increasing their chances of bypassing internal filtering systems. Our evaluations show that these attacks significantly compromise the safety of two open-source LLMs: LLaMA and Phi. LLaMA's harmfulness scores increase by an average factor of 11 across four representative unlearning methods, while Phi exhibits a 61.8× surge in the rate of unsafe responses. Furthermore, we demonstrate that our unlearning attack is also effective against OpenAI's fine-tuning service, increasing GPT-4o's harmfulness score by 2.21×. Our work identifies a critical vulnerability in unlearning and represents an important first step toward developing safe and responsible unlearning practices while honoring users' unlearning requests. Our code is available at https://doi.org/10.5281/zenodo.15628860."
  },
  {
    "id": 3592,
    "year": 2025,
    "title": "Activation Approximations Can Incur Safety Vulnerabilities in Aligned LLMs: Comprehensive Analysis and Defense",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/zhang-jiawen",
    "abstract": "Large Language Models (LLMs) have showcased remarkable capabilities across various domains.  Accompanying the evolving capabilities and expanding deployment scenarios of LLMs, their deployment challenges escalate due to their sheer scale and the advanced yet complex activation designs prevalent in notable model series, such as Llama, Gemma, Mistral. These challenges have become particularly pronounced in resource-constrained deployment scenarios, where mitigating inference bottlenecks is imperative. Among various recent efforts, activation approximation has emerged as a promising avenue for pursuing inference efficiency, sometimes considered indispensable in applications such as private inference. Despite achieving substantial speedups with minimal impact on utility, even appearing sound and practical for real-world deployment, the safety implications of activation approximations remain unclear.\nIn this work, we fill this critical gap in LLM safety by conducting the first systematic safety evaluation of activation approximations. Our safety vetting spans seven state-of-the-art techniques across three popular categories (activation polynomialization, activation sparsification, and activation quantization), revealing consistent safety degradation across ten safety-aligned LLMs. To overcome the hurdle of devising a unified defense accounting for diverse activation approximation methods, we perform an in-depth analysis of their shared error patterns and uncover three key findings. We propose QuadA, a novel safety enhancement method tailored to mitigate the safety compromises introduced by activation approximations. Extensive experiments and ablation studies corroborate QuadA's effectiveness in enhancing the safety capabilities of LLMs after activation approximations."
  },
  {
    "id": 3593,
    "year": 2025,
    "title": "Narrowbeer: A Practical Replay Attack Against the Widevine DRM",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/roudot",
    "abstract": "Streaming services like Netflix, Prime Video, and HBO Max rely on DRM solutions to ward off piracy. By enabling the distribution of encrypted content, DRM systems prevent subscribed users from downloading the streamed content, as well as unauthorized users from having access to it.\nGoogle Widevine, one of the most deployed DRMs, provides a fully software-based solution on desktop platforms to ensure portability. In this paper, we empirically investigate the security protections implemented by Widevine to counter an attacker tampering with its interactions within its environment, namely with the operating system and the hosting browser. Focusing on randomness and time, we uncover new flaws in the Widevine license acquisition process, particularly targeting the freshness and expiration of the licenses. To demonstrate the effectiveness of our findings, we develop Narrowbeer, a practical replay attack allowing legitimate users to generate never-expiring licenses, and enabling unauthorized users to reuse these licenses to access premium content without subscription. Finally, we validate our attack against real-world streaming services by succeeding in repeatedly playing the same license on different desktop devices."
  },
  {
    "id": 3594,
    "year": 2025,
    "title": "Lancet: A Formalization Framework for Crash and Exploit Pathology",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/dai",
    "abstract": "Vulnerability and exploit analysis are at the heart of soft- ware security research and practice. However, a formalization framework for dissecting the cause, development, and impact of common software errors has been missing. To address this gap, we introduce Lancet, a formalization framework that reliably tracks three distinct types of ownership within its operational semantics that can be used to identify and differ- entiate between various types of vulnerabilities and exploit primitives even in the presence of memory corruption. Addi- tionally, we developed two downstream tools, FCS and EPF, to demonstrate how security analysts can use Lancet for de- tailed crash and exploit analysis. FCS serves as a fast crash triaging tool, aiding patch synthesis in our winning system in the DARPA AIxCC semi-final, while EPF fingerprints the transition of exploitation primitives to facilitate exploit analy- sis. Experiment results show that both tools are efficient and effective."
  },
  {
    "id": 3595,
    "year": 2025,
    "title": "Synthesis of Code-Reuse Attacks from p-code Programs",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/denhoed",
    "abstract": "We present a new method for automatically synthesizing code-reuse attacks—for example, using Return Oriented Programming—based on mechanized formal logic. Our method reasons about machine code via abstraction to the p-code intermediate language of Ghidra, a well-established software reverse-engineering framework. This allows it to be applied to binaries of essentially any architecture, and provides certain technical advantages. We define a formal model of a fragment of p-code in propositional logic, enabling analysis by automated reasoning algorithms. We then synthesize code-reuse attacks by identifying selections of gadgets that can emulate a given p-code reference program. This enables our method to scale well, in both reference program and gadget library size, and facilitates integration with external tools. Our method matches or exceeds the success rate of state-of-the-art ROP chain synthesis methods while providing improved runtime performance."
  },
  {
    "id": 3596,
    "year": 2025,
    "title": "Sound and Efficient Generation of Data-Oriented Exploits via Programming Language Synthesis",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/ling",
    "abstract": "Data-oriented programming (DOP) is a methodology for embedding malicious programs into fixed executable vulnerable binaries. DOP is effective for implementing code reuse attacks that exploit memory corruptions without violating many defence techniques, such as non-execute, address space layer randomisation, control flow and code point integrity. Existing approaches for automated exploit generation for DOP follow the program synthesis approach: given a description of an attack phrased as a program, they perform extensive constraint-based search to identify the required payload for the corrupted memory. The program synthesis-inspired approaches come with three major shortcomings regarding (a) efficiency: attack generation often takes prohibitively large amount of time, (b) soundness: they provide no formal guarantees whatsoever that a particular user-described attack is feasible in a particular vulnerable program with suitable payloads, and (c) capability visibility: they do not make clear to users what attack capabilities are admitted by the vulnerable program.\nIn this work, we propose a novel approach to synthesise code reuse attacks via DOP by casting this task as an instance of the previously unexplored programming language synthesis idea. Given a vulnerable program and an exploit (e.g., buffer overflow), our approach derives a grammar of a programming language for describing the available attacks. Our approach addresses the issue (a) by shifting the cost of synthesising individual attacks to synthesising the entire attack language: once the grammar is generated, the compilation of each attack takes negligible time. The issues (b) and (c) are addressed by establishing correctness of our grammar synthesis algorithm: any attack expressible in terms of a generated grammar is realisable. We implement our approach in a tool called DOPPLER—an end-to-end compiler for DOP-based attacks. We evaluate DOPPLER against available state-of-the art techniques on a set of 17 case studies, including three recent CVEs, demonstrating its improved effectiveness (it generates more attacks) and efficiency (it does so much faster)."
  },
  {
    "id": 3597,
    "year": 2025,
    "title": "My ZIP isn't your ZIP: Identifying and Exploiting Semantic Gaps Between ZIP Parsers",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/you",
    "abstract": "ZIP is one of the most popular archive formats. It is used not only as archive files, but also as the container for other file formats, including office documents, Android applications, Java archives, and many more. Despite its ubiquity, the ZIP file format specification is imprecisely specified, posing the risk of semantic gaps between implementations that can be exploited by attackers. While prior research has reported individual such vulnerabilities, there is a lack of systematic studies for ZIP parsing ambiguities.\nIn this paper, we developed a differential fuzzer ZipDiff and systematically identified parsing inconsistencies between 50 ZIP parsers across 19 programming languages. The evaluation results show that almost all pairs of parsers are vulnerable to certain parsing ambiguities. We summarize our findings as 14 distinct parsing ambiguity types in three categories with detailed analysis, systematizing current knowledge and uncovering 10 types of new parsing ambiguities. We demonstrate five real-world scenarios where these parsing ambiguities can be exploited, including bypassing secure email gateways, spoofing office document content, impersonating VS Code extensions, and tampering with signed nested JAR files while still passing Spring Boot's signature verification. We further propose seven mitigation strategies to address these ambiguities. We responsibly reported the vulnerabilities to the affected vendors and received positive feedback, including bounty rewards from Gmail, Coremail, and Zoho, and three CVEs from Go, LibreOffice, and Spring Boot."
  },
  {
    "id": 3598,
    "year": 2025,
    "title": "Tady: A Neural Disassembler without Structural Constraint Violations",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/qin",
    "abstract": "Disassembly is a crucial yet challenging step in binary analysis. While emerging neural disassemblers show promise for efficiency and accuracy, they frequently generate outputs violating fundamental structural constraints, which significantly compromise their practical usability. To address this critical problem, we regularize the disassembly solution space by formalizing and applying key structural constraints based on post-dominance relations. This approach systematically detects widespread errors in existing neural disassemblers' outputs. These errors often originate from models' limited context modeling and instruction-level decoding that neglect global structural integrity. We introduce Tady, a novel neural disassembler featuring an improved model architecture and a dedicated post-processing algorithm, specifically engineered to address these deficiencies. Comprehensive evaluations on diverse binaries demonstrate that Tady effectively eliminates structural constraint violations and functions with high efficiency, while maintaining instruction-level accuracy."
  },
  {
    "id": 3599,
    "year": 2025,
    "title": "SoK: Towards a Unified Approach to Applied Replicability for Computer Security",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/olszewski",
    "abstract": "Reproducibility has been an increasingly important focus within the Security Community over the past decade. While showing great promise for increasing the quantity and quality of available artifacts, reproducibility alone only addresses some of the challenges to establishing experimental validity in scientific research and is not enough to move forward our discipline. Instead, replicability is required to test the bounds of a hypothesis and ultimately show consistent evidence to a scientific theory. Although there are clear benefits to replicability, it remains imprecisely defined, and a formal framework to reason about and conduct replicability experiments is lacking. In this work, we systematize over 30 years of research and recommendations on the topics of reproducibility, replicability, and validity, and argue that their definitions have had limited practical application within Computer Security. We address these issues by providing a framework for reasoning about replicability, known as the Tree of Validity (ToV). We evaluate an attack and a defense to demonstrate how the ToV can be applied to threat modeling and experimental environments. Further, we show two papers with Distinguished Artifact Awards and demonstrate that true reproducibility is often unattainable; however, meaningful comparisons are still attainable by replicability. We expand our analysis of two recent SoK papers, themselves replicability studies, and demonstrate how these papers recreate multiple paths through their respective ToVs. In so doing, we are the first to provide a practical framework of replicability with broad applications for, and beyond, the Security research community."
  },
  {
    "id": 3600,
    "year": 2025,
    "title": "LLMxCPG: Context-Aware Vulnerability Detection Through Code Property Graph-Guided Large Language Models",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/lekssays",
    "abstract": "Software vulnerabilities present a persistent security challenge, with over 25,000 new vulnerabilities reported in the Common Vulnerabilities and Exposures (CVE) database in 2024 alone. While deep learning approaches show promise for vulnerability detection, recent comprehensive evaluations reveal critical limitations: accuracy drops by up to 45% on rigorously verified datasets, and performance degrades significantly under simple code modifications. This paper presents LLMxCPG, a novel framework integrating Code Property Graphs (CPG) with Large Language Models (LLM) for robust vulnerability detection. Our CPG-based slice construction technique reduces code size by 67.84-90.93% while preserving vulnerability-relevant context. Empirical evaluation demonstrates LLMxCPG's effectiveness across both traditional and verified datasets, achieving 15-40% improvements in F1-score over state-of-the-art baselines. Unlike existing approaches, LLMxCPG maintains consistent performance across function-level and multi-function codebases while exhibiting robust detection efficacy under various syntactic modifications."
  },
  {
    "id": 3601,
    "year": 2025,
    "title": "X.509DoS: Exploiting and Detecting Denial-of-Service Vulnerabilities in Cryptographic Libraries using Crafted X.509 Certificates",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/shi-bing",
    "abstract": "Existing studies predominantly focus on cryptographic vulnerabilities affecting confidentiality or integrity, with limited attention to those impacting availability. To fill this gap, we conduct a comprehensive study targeting implementations vulnerable to DoS (Denial-of-Service) attacks within cryptographic libraries. Notably, we observed that these vulnerable implementations are frequently associated, directly or indirectly, with X.509 certificates. Consequently, we facilitate the launch of DoS attacks by using crafted X.509 certificates as attack vectors, which we termed X.509DoS in this work.\nLeveraging the tool we developed for rapid generation of crafted certificates and detection of DoS vulnerabilities, we successfully discovered 18 new vulnerabilities and identified 12 previously known CVEs across seven mainstream cryptographic libraries. Our findings demonstrate the effectiveness of exploiting and detecting DoS vulnerabilities via X.509 certificates, revealing that X.509DoS is a widespread threat that has not been well-studied previously. Our work also shows that strict adherence to textbooks or standards does not guarantee security, highlighting the need for cryptographic library developers to pay more attention to real-world considerations."
  },
  {
    "id": 3602,
    "year": 2025,
    "title": "Cyber-Physical Deception Through Coordinated IoT Honeypots",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/guan",
    "abstract": "As Internet of Things (IoT) devices become widely deployed, they face numerous threats due to the inherent vulnerabilities and interconnected nature of these devices. One effective approach to enhancing IoT security is the deployment of honeypot systems, which can attract, engage, and deceive potential attackers, thereby exposing their attack methodologies and strategies. However, traditional honeypots often fail to effectively deceive attackers due to their inability to emulate the physical and network dependencies present in real-world IoT environments. Consequently, attackers can easily detect inconsistencies among the honeypots after launching attacks from multiple sources, spanning both cyber and physical domains, to verify device status. To address this challenge, we propose a Cyber-Physical Deception System (CPDS) capable of mimicking the intricate cyber-physical connections among IoT devices by coordinating various IoT honeypots. Specifically, we model the vulnerabilities of individual IoT devices by collecting and analyzing attack traces. We analyze the physical and network dependencies among IoT devices and formulate them as Prolog rules. Then, we coordinate the honeypots based on the attacker's actions and the dependency rules, ensuring cross-layer consistency among the honeypots. We implemented our deception system by leveraging software-defined networking, enhancing existing IoT honeypots, and configuring them to work in concert. Through online deployment, human evaluation on real attack scenario and extensive simulation experiments, we have demonstrated the effectiveness of CPDS in terms of fidelity and scalability."
  },
  {
    "id": 3603,
    "year": 2025,
    "title": "AutoLabel: Automated Fine-Grained Log Labeling for Cyber Attack Dataset Generation",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/peng-yihao",
    "abstract": "High-quality labeled log datasets are essential for log-based cyber-security research, such as anomaly detection and forensic analysis. However, such datasets are scarce and generally not publicly accessible. Existing methods for generating labeled log datasets have several limitations: they are labor-intensive, require specialized expertise, provide inadequate support for multi-source logs, and produce coarse-grained labels.\nThis paper presents AutoLabel, which automates fine-grained log labeling by reducing the labeling problem to obtaining an accurate attack subgraph in a provenance graph. It modifies the environment, applications, and attack tools to generate auxiliary information during attacks. Then, from the resulting audit logs, it builds a provenance graph and leverages the auxiliary information to correlate application and traffic logs with audit logs, identify key attack-related edges, refine the graph to mitigate dependency explosion, and ultimately extract an attack subgraph for precise labeling.\nExperiments in 29 scenarios, including 25 real CVE vulnerabilities across 12 widely-used applications (spanning 5 programming languages) plus a Sandworm threat simulation by MITRE CTID, show that AutoLabel achieves 100% labeling accuracy, substantially reduces manual log-analysis effort, and produces labeled datasets in no more than 96 minutes per scenario. AutoLabel has generated over 580 datasets that could be served as benchmarks."
  },
  {
    "id": 3604,
    "year": 2025,
    "title": "CoVault: Secure, Scalable Analytics of Personal Data",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/de-viti",
    "abstract": "There is growing awareness that the analysis of personal data, such as individuals' mobility, financial, and health data, can provide significant benefits to society. However, liberal societies have so far refrained from such analytics, arguably due to the lack of secure analytics platforms that scale to billions of records while operating in a very strong threat model. We contend that one fundamental gap here is the lack of an architecture that can scale (actively-)secure multi-party computation (MPC) horizontally without weakening security. To bridge this gap, we present CoVault, an analytics platform that leverages server-aided MPC and trusted execution environments (TEEs) to colocate the MPC parties in a single datacenter without reducing security, and scales MPC horizontally to the datacenter's available resources. CoVault scales well empirically. For example, CoVault can scale the DualEx 2PC protocol to perform epidemic analytics for a country of 80M people (about 11.85B data records/day) on a continuous basis using one core pair for every 30,000 people."
  },
  {
    "id": 3605,
    "year": 2025,
    "title": "EvilEDR: Repurposing EDR as an Offensive Tool",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/alachkar",
    "abstract": "Endpoint Detection and Response (EDR) systems provide continuous monitoring, threat detection, and response capabilities. This has driven their widespread adoption in enterprises, making them a key part of an enterprise's security architecture. However, EDR systems are a double-edged sword, and in this study, we demonstrate how this class of systems can be employed for offensive use. Unlike prior studies that focused on evasion and tampering, we introduce the new concept of EDR repurposing, which we call EvilEDR. Our analysis shows that EvilEDR can be used to execute arbitrary commands via the response console, transfer tools, exfiltrate data, and passively collect system information to facilitate further exploitation and lateral movement. EvilEDR operates covertly, masquerading as a legitimate process and communicating seamlessly with trusted domains. Additionally, we show that EvilEDR can impair defenses by registering its own EPP as the default. It can also isolate the host from the network, severing telemetry and response channels essential for enterprise defense mechanisms. Fortunately, EvilEDR can be effectively detected and mitigated, and in this paper, we propose concrete and actionable defense strategies to achieve this."
  },
  {
    "id": 3606,
    "year": 2025,
    "title": "TAPAS: An Efficient Online APT Detection with Task-guided Process Provenance Graph Segmentation and Analysis",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/zhang-bo-tapas",
    "abstract": "Advanced Persistent Threats (APTs) pose critical security challenges to institutions and enterprises through sophisticated, long-duration attack campaigns. While recent APT detection methods primarily leverage provenance graphs constructed from kernel-level audit logs to reveal attack patterns, they face severe scalability limitations in production environments. The provenance graphs grow rapidly (several GB per day) and require long-term maintenance to capture APT campaigns that span months, creating prohibitive storage and computational overhead for real-time detection.\nTo address these challenges, we propose TAPAS, an efficient online APT detection framework that reduces graph dimensionality in both spatial and temporal spaces. For spatial dimensionality, TAPAS focuses on the backbone of the provenance graph, which is often large-scale but sparse. Specifically, TAPAS constructs stacked LSTM-GRU models that iteratively update the representations of the backbone nodes based on relevant redundant nodes, replacing direct storage and computation of these redundancies. For temporal dimensionality, TAPAS designs a task-guided backbone graph segmentation algorithm that identifies active subgraphs as objects to be detected in real-time, reducing structural redundancy in the temporal space.\nEvaluation in widely used benchmark datasets, DARPA TC and OpTC, demonstrates TAPAS's effectiveness in providing fast, low-overhead online detection while maintaining similar detection accuracy to state-of-the-art methods. Our results show that TAPAS reduces storage requirements by up to 1806× and achieves 99.99% accuracy with an average detection time of 12.78 seconds per GB of audit data, validating its practicality for enterprise deployment with throughputs well above the enterprise requirement of 10^4KB/s."
  },
  {
    "id": 3607,
    "year": 2025,
    "title": "Nothing is Unreachable: Automated Synthesis of Robust Code-Reuse Gadget Chains for Arbitrary Exploitation Primitives",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/bailluet",
    "abstract": "Automating gadget chaining is a challenge that has attracted significant attention since the introduction of code-reuse attacks. Influenced by the primitives offered by stack-overflow vulnerabilities, several approaches were proposed that required the attacker to control the stack. Since then, most proposed approaches have had strong requirements on the capabilities of the attacker. However, during the last decade, a plethora of new attack primitives have emerged – e.g. use-after-free, heap-overflow – often breaking the requirements of existing approaches – e.g. controlling the stack. This paper presents a new approach to synthesizing code-reuse gadget chains that supports arbitrary exploitation primitives and layouts. We thoroughly compare the performance of our approach to the state-of-the-art. We show its ability to outperform its competitors by supporting intricate exploitation primitives and layouts that other approaches cannot. Especially, we demonstrate its real-world applicability by synthesizing gadget chains for ten real-world vulnerabilities with diverse exploitation primitives that competing tools struggle with. Among them is our case study: CVE-2022-46152 – which targets a widely used trusted execution environment."
  },
  {
    "id": 3608,
    "year": 2025,
    "title": "BlueGuard: Accelerated Host and Guest Introspection Using DPUs",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/orenbach",
    "abstract": "Virtual Machine Introspection (VMI) is an essential technique for monitoring the runtime state of a virtual machine. VMI systems are widely used by major cloud providers as they enable a range of applications, such as malware detection. Unfortunately, existing VMI systems suffer from several shortcomings: they either compete with the introspected VMs for shared CPU resources or report poor performance. Further, they cannot introspect hypervisors or bare metal machines.\nWe propose BlueGuard, a system that leverages the physically isolated Data Processing Unit (DPU) commonly found on data center servers to efficiently run full system introspection by both host and guest introspection (HGI).\nBlueGuard facilitates the creation of hardware-accelerated HGI applications and frees the CPU while providing performance isolation. As a beneficial side effect, BlueGuard is capable of introspecting even bare metal servers that are usually out of scope for VMI systems. Furthermore, BlueGuard abstracts the DPU accelerators and provides kernel bypassing, non-blocking memory access, and user-level threading to achieve µs-scale introspection latency. Finally, we introduce delta introspection to accelerate the detection of state changes with BlueGuard and demonstrate the ability to isolate infected machines on a network layer.\nWe implement and extensively evaluate BlueGuard on an NVIDIA BlueField-2 DPU. Our system achieves a 4.3x detection speedup compared to prior work and is capable of monitoring tens of VMs concurrently without hindering the host performance."
  },
  {
    "id": 3609,
    "year": 2025,
    "title": "RollingEvidence: Autoregressive Video Evidence via Rolling Shutter Effect",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/qian",
    "abstract": "Today, cameras are everywhere, generating vast video evidence essential for justice, security, and legal matters. However, advanced video manipulation and creation techniques threaten their authenticity, casting doubt on their reliability. Existing defensive measures, including data-driven models and digital watermarks, remain susceptible to adversarial and injection attacks. To address these challenges, we introduce RollingEvidence, an active system that utilizes the rolling shutter effect in CMOS cameras to embed real-time probes at the physical layer during recording, appearing as stripe patterns in video images, thus enhancing the integrity of probes and evidentiary content. RollingEvidence employs an autoregressive encoding scheme to produce compact, high-dimensional probes for later frames, incorporating previous frames and device-specific cryptographic keys. During verification, we design deep networks to decode probes from video and then locate tampered frames using exponential-min implication. Our theoretical analysis, along with a prototype and comprehensive experiments, demonstrate the efficiency of RollingEvidence in producing and verifying authentic videos."
  },
  {
    "id": 3610,
    "year": 2025,
    "title": "From Constraints to Cracks: Constraint Semantic Inconsistencies as Vulnerability Beacons for Embedded Systems",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/zhao",
    "abstract": "Embedded systems have a profound impact on our daily lives and work by powering IoT devices and network devices. Ensuring their security is therefore critical. To enhance security and robustness, embedded systems often utilize constraints to validate user inputs. Through an empirical study, we identified that these constraints can be categorized into distinct types and may exhibit semantic inconsistencies across different components. Notably, over 86% of embedded system vulnerabilities originate from such inconsistencies. However, existing static analysis techniques struggle to systematically and accurately identify these inconsistencies, resulting in high false positive rates and an inability to detect certain vulnerabilities effectively.\nThis paper introduces NÜWA, a novel static analysis technique that leverages constraint semantic inconsistencies to detect vulnerabilities in embedded systems. NÜWA achieves scalable and precise vulnerability discovery by addressing the challenges of identifying constraint semantics across diverse implementations and accurately extracting them. We implemented NÜWA and evaluated it using known vulnerability datasets, including 31 vulnerabilities from 13 vendors, and compared its performance to five state-of-the-art (SOTA) tools. NÜWA identified 18, 22, 6, 17, and 19 more vulnerabilities than the respective SOTA tools. Further analysis demonstrates that NÜWA effectively extracts constraints with minimal false positives. To date, NÜWA has uncovered 152 previously unknown vulnerabilities which are all confirmed by the developers, and 88 were assigned with CVE IDs."
  },
  {
    "id": 3611,
    "year": 2025,
    "title": "IRBlock: A Large-Scale Measurement Study of the Great Firewall of Iran",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/tai",
    "abstract": "The Great Firewall of Iran (GFI) has evolved significantly over the past decade, constantly adding sophisticated blocking techniques. Prior research into Iran's Internet censorship, however, has primarily been one-off studies, leaving significant gaps in understanding the breadth and evolution of its filtering strategies. Exploiting the bidirectional blocking behaviors of the GFI and its own injection mechanisms as a side-channel to determine traffic disruption, we developed IRBlock, a novel large-scale, multi-protocol measurement system designed to measure DNS, HTTP, and UDP-based censorship across Iran, enabling continuous monitoring and in-depth exploration of the GFI's blocking behavior.\nOver a period of 2.5 months, IRBlock has periodically measured the entire Iran's IP address space and tested the blocking status of over 500M apex domains, uncovering new insights into the GFI's censorship practices of different core network protocols. Notably, IRBlock identified 6.8M IPs subjected to DNS poisoning and HTTP blockpage injection, and 5.4M IPs subjected to UDP-based traffic disruption. We also analyzed the censored domains found by IRBlock and discovered over censored 6M FQDNs and 3.3M apex domains. Via reverse engineering of the GFI's blocking rules, we found many domains are inadvertently overblocked due to blanket blocking policies of entire TLDs (e.g., .il), resulting in large collateral damage to innocuous websites. We also find that the GFI's blocking strategies show many similarities to those observed for the Great Firewall of China.\nOur study represents the most comprehensive view of Iran's Internet censorship to date. Leveraging IRBlock's data, we shed light on the GFI's evolving filtering strategies and the challenges faced by circumvention tools. We discuss the implications of our findings on existing censorship measurement and circumvention efforts. We hope that the insights gained from our study can inform not only the research community but also policymakers and activists working to promote digital freedom in Iran and beyond. All data collected by IRBlock will be made publicly available to facilitate further research on nation-state censorship and Internet freedom advocacy."
  },
  {
    "id": 3612,
    "year": 2025,
    "title": "Email Spoofing with SMTP Smuggling: How the Shared Email Infrastructures Magnify this Vulnerability",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/wang-chuhan",
    "abstract": "Email spoofing is a critical technique used in phishing attacks to impersonate a trusted sender. SMTP smuggling is a new vulnerability that allows adversaries to perform email spoofing while bypassing existing authentication protocols such as SPF and DMARC. While SMTP smuggling has been publicly disclosed since 2023, its impact has not been comprehensively evaluated and the effectiveness of the community's mitigation strategies is yet unknown. In this paper, we present an in-depth study of SMTP smuggling vulnerabilities, supported by empirical measurements of public email services, open-source email software, and email security gateways. More importantly, for the first time, we explored how to perform measurements on private email services ethically, with new methodologies combining user studies, a DKIM side channel, and a non-intrusive testing method. Collectively, we found that 19 public email services, 1,577 private email services, five open-source email software, and one email gateway were still vulnerable to SMTP smuggling (and/or our new variants). In addition, our results showed that the centralization of email infrastructures (e.g., shared SFP records, commonly used email software/gateways) has amplified the impact of SMTP smuggling. Adversaries can spoof highly reputable domains through free-to-register email accounts while bypassing sender authentication. We provided suggestions on short-term and long-term solutions to mitigate this threat. To further aid email administrators, we developed an online service to help self-diagnosis of SMTP smuggling vulnerabilities."
  },
  {
    "id": 3613,
    "year": 2025,
    "title": "The Silent Danger in HTTP: Identifying HTTP Desync Vulnerabilities with Gray-box Testing",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/mu",
    "abstract": "HTTP Desync is a high-risk threat in today's decentralized Internet, stemming from discrepancies among HTTP implementations. Current automatic detection tools, primarily dictionary-based scanners and black-box fuzzers, lack insights into internal states of implementations, leading to ineffective testing. Moreover, they focus on the request-side Desync, overlooking vulnerabilities in HTTP responses.\nIn this paper, we present HDHunter, a novel automatic HTTP discrepancy detection framework using the gray-box coverage-directed differential testing technique. HDHunter can discover discrepancies in not only HTTP requests but also HTTP responses and CGI responses. We evaluated our HDHunter prototype against 19 state-of-the-art HTTP implementations and identified 17 new HTTP Desync vulnerabilities. We have disclosed all identified vulnerabilities to corresponding vendors and received acknowledgments and bug bounty rewards, including 9 CVEs from well-known HTTP software, including Apache, Tomcat, Squid, etc."
  },
  {
    "id": 3614,
    "year": 2025,
    "title": "Censorship Evasion with Unidentified Protocol Generation",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/wails",
    "abstract": "We present the design and implementation of a novel approach to internet censorship evasion called Unidentified Protocol Generation (UPGen). UPGen automatically generates novel protocols for encrypted communication that are not easily recognizable as being UPGen protocols, but instead as some benign encrypted protocol unknown to the adversary. UPGen protocols are to be used to relay traffic to censored destinations via proxies, where each proxy can run a different UPGen-generated protocol. An adversary attempting to block at the protocol level but unable to identify UPGen protocols could cause significant collateral damage if it attempted to block all unidentified protocols. We conduct a security evaluation of UPGen employing state-of-the-art machine learning classifiers and find that it is infeasible to block UPGen protocols without also blocking existing encrypted protocols. We conduct small- and large-scale performance evaluations and find that UPGen protocols meet or exceed the performance of other common censorship evasion protocols."
  },
  {
    "id": 3615,
    "year": 2025,
    "title": "Exposing and Circumventing SNI-based QUIC Censorship of the Great Firewall of China",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/zohaib",
    "abstract": "Despite QUIC handshake packets being encrypted, the Great Firewall of China (GFW) has begun blocking QUIC connections to specific domains since April 7, 2024. In this work, we measure and characterize the GFW's censorship of QUIC to understand how and what it blocks. Our measurements reveal that the GFW decrypts QUIC Initial packets at scale, applies heuristic filtering rules, and uses a blocklist distinct from its other censorship mechanisms. We expose a critical flaw in this new system: the computational overhead of decryption reduces its effectiveness under moderate traffic loads. We also demonstrate that this censorship mechanism can be weaponized to block UDP traffic between arbitrary hosts in China and the rest of the world. We collaborate with various open-source communities to integrate circumvention strategies into Mozilla Firefox, the quic-go library, and all major QUIC-based circumvention tools."
  },
  {
    "id": 3616,
    "year": 2025,
    "title": "Ares: Comprehensive Path Hijacking Detection via Routing Tree",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/tao",
    "abstract": "Since Border Gateway Protocol (BGP) lacks a strong security mechanism, prefix hijacking attacks are becoming increasingly rampant, which has drawn a lot of attention from both academia and industry. Recently, prefix hijacking has evolved from origin hijacking to more stealthy hijacking, i.e., path hijacking, to bypass existing hijacking detection systems. The attacker will manipulate the AS path attributes while announcing the prefix of the victim AS. However, existing systems only target origin hijacking or only address part of the path hijacking, which allows attackers to exploit vulnerabilities to hijack. In this paper, our observation shows that path hijacking triggers the creation of a new observed prefix's routing tree (OPRT) within an AS and we advocate for a radical new approach to comprehensively address all types of path hijacking. We propose a first-of-its-kind system, called Ares, to detect path hijacking in an effective, accurate, and fast way. At the core of Ares is weighted edit distance to quantify the differences between routing trees, combined with a clustering mechanism to accelerate anomaly detection and heuristic rules to further increase the detection accuracy. We validate Ares with historical hijacking events and large-scale simulations, For each of the 12 real-world events, Ares was able to detect the hijacking within 5 minutes of its occurrence. Additionally, simulations show that Ares detects an average of 97.2% and 99.3% of stealthy exact and sub-prefix path hijackings targeting Tier-1 and content ASes with only 1.06% of false positive rate, outperforming state-of-the-art methods. In addition, it generates only 2.31 suspicious alerts per hour across the entire Internet, a manageable volume for operators to investigate and respond effectively."
  },
  {
    "id": 3617,
    "year": 2025,
    "title": "Trust but Verify: An Assessment of Vulnerability Tagging Services",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/huang-szu-chun",
    "abstract": "Internet-wide scanning services are widely used for attack surface discovery across organizations and the Internet. Enterprises, government agencies, and researchers rely on these tools to assess risks to Internet-facing infrastructure. However, their reliability and trustworthiness remain largely unexamined. This paper addresses this gap by comparing results from three commercial scanners – Shodan, ONYPHE, and LeakIX – with findings from our independent experiments using verified Nuclei templates, designed to identify specific vulnerabilities through crafted benign requests. We found that the payload-based detections of Shodan are mostly confirmed. Yet, Nuclei finds many more vulnerable endpoints, so defenders might face massive underreporting. For Shodan's banner-based detections, the opposite issue arises: a significant overreporting of false positives. This indicates that banner-based detections are unreliable. Moreover, three commercial services and Nuclei scans exhibit significant discrepancies. Our work has implications for industry users, policymakers, and the many academic researchers who rely on the results provided by these attack surface management services. By highlighting their shortcomings in vulnerability monitoring, this work serves as a call for action to advance and standardize such services to enhance their trustworthiness."
  },
  {
    "id": 3618,
    "year": 2025,
    "title": "Watch Out Your TV Box: Reversing and Blocking a P2P-based Illegal Streaming Ecosystem",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/ahn",
    "abstract": "Recent developments have led to the emergence of illegal streaming services that are difficult to detect because they are offered only to those who have purchased specific set-top boxes. Even when such infringements are identified, the hardware-based nature of the service makes tracking extremely challenging. This paper focuses on analyzing the services provided through one such device, EVPAD. Upon installation, as of January 19, 2025, EVPAD allows users to watch real-time broadcasts of 1,260 channels from 18 countries and access 24,934 VoD contents, including Netflix and Disney Plus, as well as locally produced broadcasts. Through reverse engineering and detailed analysis, we identified 131,175 unique users and 78 servers dedicated to providing illegal streaming services over the course of two months. Beyond copyright infringement, EVPAD devices distributed worldwide could be misused by operators for cyberattacks. This paper proposes two blocking strategies based on EVPAD's service characteristics to curb copyright infringement and track key service nodes to dismantle illegal services and prevent potential cyber threats."
  },
  {
    "id": 3619,
    "year": 2025,
    "title": "Catch-22: Uncovering Compromised Hosts using SSH Public Keys",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/munteanu",
    "abstract": "Attackers regularly use SSH (Secure SHell) to compromise systems, e.g., via brute-force attacks, establishing persistence by deploying SSH public keys. This ranges from IoT botnets like Mirai, over loader and dropper systems, to the back-ends of malicious operations. Identifying compromised systems at the Internet scale would be a major break-through for combatting malicious activity by enabling targeted clean-up efforts.\nIn this paper, we present a method to identify compromised SSH servers at scale. For this, we use SSH's behavior to only send a challenge during public key authentication, to check if the key is present on the system. Our technique neither allows us to access compromised systems (unlike, e.g., testing known attacker passwords), nor does it require access for auditing.\nWith our methodology used at an Internet-wide scan, we identify more than 21,700 unique systems (1,649 ASes, 144 countries) where attackers installed at least one of 52 verified malicious keys provided by a threat intelligence company, including critical Internet infrastructure. Furthermore, we find new context on the activities of malicious campaigns like, e.g., the 'fritzfrog' IoT botnet, malicious actors like 'teamtnt', and even the presence of state-actor associated keys within sensitive ASes. Comparing to honeypot data, we find these to under-/over-represent attackers' activity, even underestimating some APTs' activities. Finally, we collaborate with a national CSIRT and the Shadowserver Foundation to notify and remediate compromised systems. We run our measurements continuously and automatically share notifications."
  },
  {
    "id": 3620,
    "year": 2025,
    "title": "USD: NSFW Content Detection for Text-to-Image Models via Scene Graph",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/zhang-yuyang",
    "abstract": "In recent years, Text-to-Image (T2I) techniques have achieved remarkable success in synthesizing high-quality visual content. However, this advancement has raised significant societal concerns regarding the potential security risks, particularly the generation of unsafe images, such as those containing sexual or violent content. Previous research has primarily focused on classifying unsafe concepts based on overall image features. However, extracting abstract harmful concepts directly from concrete image content has proven to be challenging, limiting the effectiveness of existing methods. Our observations reveal that harmful concepts are often embedded in entities and their relationships, particularly in the actions involving these entities. In this work, we propose \\Name, a novel approach for identifying unsafe scenes. For the first time, we leverage scene graph generation and classification to detect harmful attributes and relationships within images. Our method focuses on defining and detecting unsafe scenes, providing insight into how unsafe images are generated by Text-to-Image models. In three meta-scenarios, our method achieved F1 scores that were, on average, 95.52% higher than baseline approaches. Additionally, Name effectively localized unsafe portions of the image, removing 95% of harmful content while preserving 76.34% of image consistency. This pioneering study highlights the importance of investigating the intent and purpose of unsafe images to enhance the security of T2I models and ensure safer applications of this technology."
  },
  {
    "id": 3621,
    "year": 2025,
    "title": "Exposing the Guardrails: Reverse-Engineering and Jailbreaking Safety Filters in DALL·E Text-to-Image Pipelines",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/villa",
    "abstract": "We investigate the specific design and implementation of safety guardrails in black-box text-to-image (T2I) models, such as DALL·E, which are implemented to prevent potential misuse from generating harmful image content. Specifically, we introduce a novel timing-based side-channel analysis approach to reverse engineer the safety mechanisms of DALL·E models. By measuring and analyzing the differential response times of these systems, we reverse-engineer the architecture of previously unknown cascading safety filters at various stages of the T2I pipeline. Our analysis reveals key takeaways by contrasting safety mechanisms in DALL·E 2 and DALL·E 3: DALL·E 2 uses blocklist-based filtering, whereas DALL·E 3 employs an LLM-based prompt revision stage to improve image quality and filter harmful content. We find discrepancies between the LLM's language understanding and the CLIP embedding used for image generation, which we exploit to develop a negation-based jailbreaking attack. We further uncover gaps in the multilingual coverage of safety measures, which render DALL·E 3 vulnerable to a new class of low-resource language attacks for T2I systems. Lastly, we outline six distinct countermeasures techniques and research directions to address our findings. This work emphasizes the challenges of aligning the diverse components of these systems and underscores the need to improve the consistency and robustness of guardrails across the entire T2I pipeline."
  },
  {
    "id": 3622,
    "year": 2025,
    "title": "On the Proactive Generation of Unsafe Images From Text-To-Image Models Using Benign Prompts",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/wu-yixin-generation",
    "abstract": "Malicious or manipulated prompts are known to exploit text-to-image models to generate unsafe images. Existing studies, however, focus on the passive exploitation of such harmful capabilities. In this paper, we investigate the proactive generation of unsafe images from benign prompts (e.g., a photo of a cat) through maliciously modified text-to-image models. Our preliminary investigation demonstrates that poisoning attacks are a viable method to achieve this goal but uncovers significant side effects, where unintended spread to non-targeted prompts compromises attack stealthiness. Root cause analysis identifies conceptual similarity as an important contributing factor to these side effects. To address this, we propose a stealthy poisoning attack method that balances covertness and performance. Our findings highlight the potential risks of adopting text-to-image models in real-world scenarios, thereby calling for future research and safety measures in this space."
  },
  {
    "id": 3623,
    "year": 2025,
    "title": "Neural Invisibility Cloak: Concealing Adversary in Images via Compromised AI-driven Image Signal Processing",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/zhu-wenjun",
    "abstract": "Image Signal Processing (ISP) is crucial for image production in cameras, and recent AI-driven ISP algorithms (AISP) are increasingly used in cameras to produce enhanced images. However, their vulnerabilities are not well understood. This paper presents Neural Invisibility Cloak (NIC), which can trigger a compromised AISP to remove a person with an \"invisibility cloak\" from the image. Essentially NIC is a neural backdoor that none of the traditional ones can accomplish, as it requires replacing each pixel in the cloaked area with background information, yet the final image should be free of any suspicious elements in terms of both humans and AI algorithms. To address the challenges, we propose a data-poisoning method combined with a generative training strategy to embed malicious behaviors in the AISP models, thereby manipulating the output images and videos from cameras, without impairing AISP performance. Our validation in two mainstream AISP modules and four representative AISP tasks in real-world experiments shows the effectiveness of NIC on deceiving downstream image recognition algorithms and human observers. In particular, we show that NIC can remove the human from the images completely, as he walks across the camera views, wearing a real cloak, appearing invisible to the video surveillance system. Moreover, we extend NIC to a patch-based variant (NIP), which can be applied to more general scenarios. Finally, we discuss potential defenses against NIC-like attacks to safeguard AISP models."
  },
  {
    "id": 3624,
    "year": 2025,
    "title": "Bridging the Gap in Vision Language Models in Identifying Unsafe Concepts Across Modalities",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/qu-yiting",
    "abstract": "Vision-language models (VLMs) are increasingly applied to identify unsafe or inappropriate images due to their internal ethical standards and powerful reasoning abilities. However, it is still unclear whether they can recognize various unsafe concepts when presented in different modalities, such as text and images. To address this, we first compile the UnsafeConcepts dataset, featuring 75 unsafe concepts, i.e., \"Swastika,\" \"Sexual Harassment,\" and \"Assaults,\" along with associated 1.5K images. We then conduct a systematic evaluation of VLMs' perception (concept recognition) and alignment (ethical reasoning) capabilities. We assess eight popular VLMs and find that, although most VLMs accurately perceive unsafe concepts, they sometimes mistakenly classify these concepts as safe. We also identify a consistent modality gap among open-source VLMs in distinguishing between visual and textual unsafe concepts. To bridge this gap, we introduce a simplified reinforcement learning (RL)-based approach using proximal policy optimization (PPO) to strengthen the ability to identify unsafe concepts from images. Our approach uses reward scores based directly on VLM responses, bypassing the need for collecting human-annotated preference data to train a new reward model. Experimental results show that our approach effectively enhances VLM alignment on images while preserving general capabilities. It outperforms baselines such as supervised fine-tuning (SFT) and direct preference optimization (DPO). We hope our dataset, evaluation findings, and proposed alignment solution contribute to the community's efforts in advancing safe VLMs."
  },
  {
    "id": 3625,
    "year": 2025,
    "title": "Backdooring Bias (B^2) into Stable Diffusion Models",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/naseh",
    "abstract": "Recent advances in large text-conditional diffusion models have revolutionized image generation by enabling users to create realistic, high-quality images from textual prompts, significantly enhancing artistic creation and visual communication. However, these advancements also introduce an underexplored attack opportunity: the possibility of inducing biases by an adversary into the generated images for malicious intentions, e.g., to influence public opinion and spread propaganda. In this paper, we study an attack vector that allows an adversary to inject arbitrary bias into a target model. The attack leverages low-cost backdooring techniques using a targeted set of natural textual triggers embedded within a small number of malicious data samples produced with public generative models. An adversary could pick common sequences of words that can then be inadvertently activated by benign users during inference. We investigate the feasibility and challenges of such attacks, demonstrating how modern generative models have made this adversarial process both easier and more adaptable. On the other hand, we explore various aspects of the detectability of such attacks and demonstrate that the model's utility remains intact in the absence of the triggers. Our extensive experiments using over 200,000 generated images and against hundreds of fine-tuned models demonstrate the feasibility of the presented backdoor attack. We illustrate how these biases maintain strong text-image alignment, highlighting the challenges in detecting biased images without knowing that bias in advance. Our cost analysis confirms the low financial barrier ($10-$15) to executing such attacks, underscoring the need for robust defensive strategies against such vulnerabilities in diffusion models."
  },
  {
    "id": 3626,
    "year": 2025,
    "title": "Watch the Watchers! On the Security Risks of Robustness-Enhancing Diffusion Models",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/li-changjiang",
    "abstract": "Thanks to their remarkable denoising capabilities, diffusion models are increasingly being employed as defensive tools to reinforce the robustness of other models, notably in purifying adversarial examples and certifying adversarial robustness. However, the potential risks of these practices remain largely unexplored, which is highly concerning. To bridge this gap, this work investigates the vulnerability of robustness-enhancing diffusion models.\nSpecifically, we demonstrate that these models are highly susceptible to DIFF2, a simple yet effective attack, which substantially diminishes their robustness assurance. Essentially, DIFF2 integrates a malicious diffusion-sampling process into the diffusion model, guiding inputs embedded with specific triggers toward an adversary-defined distribution while preserving the normal functionality for clean inputs. Our case studies on adversarial purification and robustness certification show that DIFF2 can significantly reduce both post-purification and certified accuracy across benchmark datasets and models, highlighting the potential risks of relying on pre-trained diffusion models as defensive tools. We further explore possible countermeasures, suggesting promising avenues for future research."
  },
  {
    "id": 3627,
    "year": 2025,
    "title": "Pretender: Universal Active Defense against Diffusion Finetuning Attacks",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/sun-zekun",
    "abstract": "The proliferation of Diffusion Models (DMs) has marked a significant advancement in AI-generated image creation. However, this success has also spawned a new form of infringement threat termed the Diffusion Finetuning Attack (DFA), where malicious attackers can finetune pre-trained DMs using minimal resources to illicitly synthesize copyrightinfringing images by 'stealing' information from personal photographic data or artwork, raising critical concerns about privacy and intellectual property rights. Recognizing the limitations of current defense strategies, which exhibit inadequate generalizability and suboptimal mechanism efficacy, we introduce an universal and effective active defense mechanism that applies subtle protective noise to images, guarding against information theft from DFAs. Our work innovatively conceptualizes active defense as a bi-level optimization problem, focusing on attackers' common behaviors to enhance the generalization of defense. Guided by this optimization framework, we have developed a novel algorithm named Pretender, where we adversarially trained a surrogate model to facilitate the generation of more effective protective noise. In addition, a Simultaneous Gradient Back-Propagation (SGBP) technique is introduced to significantly enhance computational efficiency. Extensive experiments including real-world evaluations have demonstrated the effectiveness of Pretender. By applying minimal perturbations (p = 0.03), Pretender successfully disrupted the quality and semantics of images synthesized by diverse DFAs, achieving a comprehensive and prominent improvement in various automated evaluation metrics by 22.27% and in human assessment scores by 94.28%."
  },
  {
    "id": 3628,
    "year": 2025,
    "title": "Self-interpreting Adversarial Images",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/zhang-tingwei",
    "abstract": "We introduce a new type of indirect, cross-modal injection attacks against visual language models that enable creation of self-interpreting images. These images contain hidden \"meta-instructions\" that control how models answer users' questions about the image and steer their outputs to express an adversary-chosen style, sentiment, or point of view.\nSelf-interpreting images act as soft prompts, conditioning the model to satisfy the adversary's (meta-)objective while still producing answers based on the image's visual content. Meta-instructions are thus a stronger form of prompt injection. Adversarial images look natural and the model's answers are coherent and plausible—yet they also follow the adversary-chosen interpretation, e.g., political spin, or even objectives that are not achievable with explicit text instructions.\nWe evaluate the efficacy of self-interpreting images for a variety of models, interpretations, and user prompts. We describe how these attacks could cause harm by enabling creation of self-interpreting content that carries spam, misinformation, or spin. Finally, we discuss defenses."
  },
  {
    "id": 3629,
    "year": 2025,
    "title": "TORCHLIGHT: Shedding LIGHT on Real-World Attacks on Cloudless IoT Devices Concealed within the Tor Network",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/pan-yumingzhi",
    "abstract": "The rapidly expanding Internet of Things (IoT) landscape is shifting toward cloudless architectures, removing reliance on centralized cloud services but exposing devices directly to the internet and increasing their vulnerability to cyberattacks. Our research revealed an unexpected pattern of substantial Tor network traffic targeting cloudless IoT devices, suggesting that attackers are using Tor to anonymously exploit undisclosed vulnerabilities (possibly obtained from underground markets). To delve deeper into this phenomenon, we developed TORCHLIGHT, a tool designed to detect both known and unknown threats targeting cloudless IoT devices by analyzing Tor traffic. TORCHLIGHT filters traffic via specific IP patterns, strategically deploys virtual private server (VPS) nodes for cost-effective detection, and uses a chain-ofthought (CoT) process with large language models (LLMs) for accurate threat identification.\nOur results are significant: for the first time, we have demonstrated that attackers are indeed using Tor to conceal their identities while targeting cloudless IoT devices. Over a period of 12 months, TORCHLIGHT analyzed 26 TB of traffic, revealing 45 vulnerabilities, including 29 zero-day exploits with 25 CVE-IDs assigned (5 CRITICAL, 3 HIGH, 16 MEDIUM, and 1 LOW) and an estimated value of approximately $312,000. These vulnerabilities affect around 12.71 million devices across 148 countries, exposing them to severe risks such as information disclosure, authentication bypass, and arbitrary command execution. The findings have attracted significant attention, sparking widespread discussion in cybersecurity circles, reaching the top 25 on Hacker News, and generating over 190,000 views."
  },
  {
    "id": 3630,
    "year": 2025,
    "title": "CloudFlow: Identifying Security-sensitive Data Flows in Serverless Applications",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/raffa",
    "abstract": "The serverless computing paradigm has significantly changed how modern cloud applications are developed. This model allows developers to focus on application business logic while outsourcing to the cloud provider infrastructure details such as machine provisioning. However, the serverless model also presents new security challenges. Among these, static analysis of application security, a fundamental part of the secure software development lifecycle, becomes more complex due to the presence of event-triggered code and the black-box nature of cloud services.\nIn this paper, we present CloudFlow, a novel framework to statically detect security-sensitive data flows in serverless applications. To achieve this, CloudFlow leverages the infrastructure definition provided by the developer to identify the events, permissions and entry points of an application. Using this information and custom models for events and cloud API calls, it instruments the application code, which can then be analysed with general-purpose methods for static analysis. We evaluate our framework against a new suite of 40 microbenchmarks, CloudBench. Furthermore, we analyse 104 real-world applications selected from a recent dataset. To the best of our knowledge, this is the largest security-focused analysis of serverless applications to date. Our results show that CloudFlow passes all microbenchmarks, apart from three, and detects 11 code injection and information leakage vulnerabilities in real-world applications. Both CloudFlow and CloudBench are open-source to support future research."
  },
  {
    "id": 3631,
    "year": 2025,
    "title": "Serverless Functions Made Confidential and Efficient with Split Containers",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/shi-jiacheng",
    "abstract": "The increasing adoption of serverless computing in security-critical fields (e.g., finance and healthcare) motivates confidential serverless. This paper explores confidential virtual machines (CVMs), a promising hardware security feature offered by various CPU architectures, for securing serverless functions. However, our analysis reveals a mismatch between current CVM implementations and function needs, resulting in performance bottlenecks, resource inefficiency, and an expanded trusted computing base (TCB).\nWe present split container, a design that separates security and management to create confidential containers with a minimal TCB. Our observation is that real-world serverless functions often require a limited set of OS functionalities. Thus, our design deploys a function-oriented OS (microkernel + library OS) within the CVM for secure execution of multiple functions while reusing an untrusted commodity OS like Linux outside for container management. Based on the split container design, we have implemented CoFunc, a system prototype that works on both AMD SEV and Intel TDX. With FunctionBench and ServerlessBench, CoFunc demonstrates significant performance improvements (up to 60× on SEV and 215× on TDX) compared to the only known CVM-based confidential container (Kata-CVM with optimizations), while incurring <14% performance overhead on average compared to a state-of-the-art non-confidential container system (lean container)."
  },
  {
    "id": 3632,
    "year": 2025,
    "title": "Exploring and Exploiting the Resource Isolation Attack Surface of WebAssembly Containers",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/yu-zhaofeng",
    "abstract": "Recently, the WebAssembly (or Wasm) technology has been rapidly evolving, with many runtimes actively under development, providing cross-platform secure sandboxes for Wasm modules to run as portable containers. Compared with Docker, which isolates applications at the operating system level, Wasm runtimes provide more security mechanisms, such as linear memory, type checking, and protected call stacks. Although Wasm is designed with security in mind and considered to be a more secure container runtime, various security challenges have arisen, and researchers have focused on the security of Wasm runtimes, such as discovering vulnerabilities or proposing new security mechanisms to achieve robust isolation. However, we have observed that the resource isolation is not well protected by the current Wasm runtimes, and attackers can exhaust the host's resources to interfere with the execution of other container instances by exploiting the WASI/WASIX interfaces. And the attack surface has not been well explored and measured. In this paper, we explore the resource isolation attack surface of Wasm runtimes systematically by proposing several static Wasm runtime analysis approaches. Based on the analysis results, we propose several exploitation strategies to break the resource isolation of Wasm runtimes. The experimental results show that malicious Wasm instances can not only consume large amounts of system resources on their own but also introduce high workloads into other components of the underlying operating system, leading to a substantial performance degradation of the whole system. In addition, the mitigation approaches have also been discussed."
  },
  {
    "id": 3633,
    "year": 2025,
    "title": "Transparent Attested DNS for Confidential Computing Services",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/delignat-lavaud",
    "abstract": "Confidential services running in hardware-protected Trusted Execution Environments (TEEs) can provide higher security assurance, but this requires custom clients and protocols to distribute, update, and verify their attestation evidence. Compared with classic Internet security, built upon universal abstractions such as domain names, origins, and certificates, this puts a significant burden on service users and providers. In particular, Web browsers and other legacy clients do not get the same security guaranties as custom clients.\nWe present a new approach for users to establish trust in confidential services. We propose attested DNS (aDNS): a name service that securely binds the attested implementation of confidential services to their domain names. ADNS enforces policies for all names in its zone of authority: any TEE that runs a service must present hardware attestation that complies with the domain-specific policy before registering keys and obtaining certificates for any name in this domain. ADNS provides protocols for zone delegation, TEE registration, and certificate issuance. ADNS builds on standards such as DNSSEC, DANE, ACME and Certificate Transparency. ADNS provides DNS transparency by keeping all records, policies, and attestations in a public append-only log, thereby enabling auditing and preventing targeted attacks.\nWe implement aDNS as a confidential service using a fault-tolerant network of TEEs. We evaluate it using sample confidential services that illustrate various TEE platforms. On the client side, we provide a generic browser extension that queries and verifies attestation records before opening TLS connections, with negligible performance overhead, and we show that, with aDNS, even legacy Web clients benefit from confidential computing as long as some enlightened clients verify attestations to deter or blame malicious actors."
  },
  {
    "id": 3634,
    "year": 2025,
    "title": "Dorami: Privilege Separating Security Monitor on RISC-V TEEs",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/kuhne",
    "abstract": "TEE implementations on RISC-V offer an enclave abstraction by introducing a trusted component called the security monitor (SM). The SM performs critical tasks such as isolating enclaves from each other as well as from the OS by using privileged ISA instructions that enforce the physical memory protection. However, the SM executes at the highest privilege layer on the platform (machine-mode) along side firmware that is not only large in size but also includes third-party vendor code specific to the platform. In this paper, we present Dorami—a privilege separation approach that isolates the SM from the firmware thus reducing the attack surface on TEEs. Dorami re-purposes existing ISA features to enforce its isolation and achieves its goals without large overheads."
  },
  {
    "id": 3635,
    "year": 2025,
    "title": "TLBlur: Compiler-Assisted Automated Hardening against Controlled Channels on Off-the-Shelf Intel SGX Platforms",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/vanoverloop",
    "abstract": "Intel SGX's vision of secure enclaved execution has been plagued by a continuous line of side channels. Among these, the ability to track enclave page accesses emerged as a particularly versatile and indispensable attack primitive. Despite nearly a decade since the original controlled-channel attack, existing mitigations remain focused on detection rather than prevention or depend on impractical developer annotations and hypothetical hardware extensions. This paper introduces TLBlur, a novel approach that leverages the recent AEX-Notify hardware extension in modern Intel SGX processors to essentially limit the bandwidth of controlled-channel attacks to the anonymity set of recently used pages.\nOur defense leverages the fact that page translations served from the processor's Translation Lookaside Buffer (TLB), which is forcibly flushed during enclave interruptions, remain oblivious to adversaries. We introduce practical compile-time instrumentation to seamlessly log page accesses within the protected enclave application. Additionally, we utilize AEX-Notify to implement a custom enclave interrupt handler that hides the N most recently accessed application pages by transparently prefetching them into the hardware TLB. Our evaluation on real-world libraries such as libjpeg, yescrypt, wolfSSL, and OpenSSL yields acceptable performance overheads, improving over prior work with several orders of magnitude."
  },
  {
    "id": 3636,
    "year": 2025,
    "title": "TETD: Trusted Execution in Trust Domains",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/wang-zhanbo",
    "abstract": "Intel TDX empowers cloud service providers to construct confidential virtual machines called trust domains (TDs) on x86 platforms. Similar to its counterparts from AMD and Arm, TDX's hardware based protection over integrity and secrecy of virtual machine memory and vCPU states inevitably hinders legitimate virtual machine management such as introspection. At the presence of compromised high-privileged software (e.g., the guest kernel), neither the cloud service provider nor the TD owner can securely carry out a task within the TD. To tackle this problem, we propose TETD, an in-TD trusted execution technique without trusting any TD system software. Our design does not pivot on in-VM privilege layering, a popular approach used in existing VM security enhancement schemes. Instead, we leverage the virtual machine monitor's existing capability of resource management to directly separate memory and vCPU used for trusted execution from the TD system software. We implement a TETD prototype on a TDX server and run extensive experiments. The performance overhead incurred by TETD to the TD depends on the workload. In our benchmark evaluations, the highest toll is about 6.8%. Moreover, our three applications also demonstrate that TETD provides a TD owner a practical and secure foothold at the presence of a compromised kernel."
  },
  {
    "id": 3637,
    "year": 2025,
    "title": "TDXploit: Novel Techniques for Single-Stepping and Cache Attacks on Intel TDX",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/rauscher",
    "abstract": "Intel TDX is a trusted execution environment (TEE) protecting arbitrary code, e.g., an entire OS, from the host system in trust domains (TDs). While TDX isolates the memory of TDs, side channels are still a threat due to shared hardware. Prior work showed that single-stepping is a powerful technique for attacking TEEs. After TDX was found vulnerable to these attacks, Intel improved their mitigations with TDX module version 1.5.06, stopping all known single-stepping attacks.\nIn this paper, we introduce TDXploit, a novel technique to revive single-stepping attacks on Intel TDX. TDXploit exploits a fundamental flaw in Intel's single-stepping mitigation, ironically, achieving a higher (>99.99 %) single-stepping accuracy than without mitigations. We recover the mitigation's internal state using an attacker-controlled TD. We not only predict the mitigation's behavior without any side channel but also manipulate it for reliable single- and multi-stepping. TDXploit can perform one single-step every 3.7 ms. We evaluate TDXploit with an attack on ECDSA in OpenSSL. Furthermore, we systematically evaluate 6 state-of-the-art side-channel attack techniques on TDX and their compatibility with TDXploit. A key finding is that clflush bypasses Intel's defenses, allowing Flush+Flush attacks on TDX guest physical memory. Compared to all previous Flush+Flush attacks, our Flush+Flush attack requires no shared memory and can target any memory location of a TD. We demonstrate the impact of this finding in a full key recovery on an AES T-Table implementation, requiring only 8 986 encryption traces. Finally, we combine our novel Flush+Flush with TDXploit to leak TOTP secrets with a single trace. We conclude that further mitigations against single-stepping and side channels on TDX are necessary"
  },
  {
    "id": 3638,
    "year": 2025,
    "title": "Auspex: Unveiling Inconsistency Bugs of Transaction Fee Mechanism in Blockchain",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/he-zheyuan",
    "abstract": "The transaction fee mechanism (TFM) in blockchain prevents resource abuse by charging users based on resource usage, but inconsistencies between charged fees and actual resource consumption, termed as TFM inconsistency bugs, introduce significant security and financial risks.\nIn this paper, we present Auspex, the first tool that automatically detects TFM inconsistency bugs in Ethereum ecosystem by leveraging fuzzing technology. To efficiently trigger and identify TFM inconsistency bugs, Auspex introduces three novel technologies: (i) a chain-based test case generation strategy that enables Auspex to efficiently generate the test cases; (ii) a charging-guided fuzzing approach that guides Auspex to explore more code logic; and (iii) fee consistency property and resource consistency property, two general bug oracles for automatically detecting bugs. We evaluate Auspex on Ethereum and demonstrate its effectiveness by discovering 13 previously unknown TFM inconsistency bugs, and achieving 3.5 times more code branches than state-of-the-art tools. We further explore the financial and security impact of the bugs. On one hand, these bugs have caused losses exceeding millions of dollars for users on both Ethereum and BSC. On the other hand, the denial-of-service (DoS) attack exploiting these bugs can prolong transaction wait time by 4.5 times during the attack period."
  },
  {
    "id": 3639,
    "year": 2025,
    "title": "Blockchain Address Poisoning",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/tsuchiya",
    "abstract": "In many blockchains, e.g., Ethereum, Binance Smart Chain (BSC), the primary representation used for wallet addresses is a hardly memorable 40-digit hexadecimal string. As a result, users often select addresses from their recent transaction history, which enables blockchain address poisoning. The adversary first generates lookalike addresses similar to one with which the victim has previously interacted, and then engages with the victim to \"poison\" their transaction history. The goal is to have the victim mistakenly send tokens to the lookalike address, as opposed to the intended recipient. Compared to contemporary studies, this paper provides four notable contributions. First, we develop a detection system and perform measurements over two years on both Ethereum and BSC. We identify 13~times more attack attempts than reported previously—totaling 270M on-chain attacks targeting 17M victims. 6,633 incidents have caused at least 83.8M USD in losses, which makes blockchain address poisoning one of the largest cryptocurrency phishing schemes observed in the wild. Second, we analyze a few large attack entities using improved clustering techniques, and model attacker profitability and competition. Third, we reveal attack strategies—targeted populations, success conditions (address similarity, timing), and cross-chain attacks. Fourth, we mathematically define and simulate the lookalike address generation process across various software- and hardware-based implementations, and identify a large-scale attacker group that appears to use GPUs. We also discuss defensive countermeasures."
  },
  {
    "id": 3640,
    "year": 2025,
    "title": "Available Attestation: Towards a Reorg-Resilient Solution for Ethereum Proof-of-Stake",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/zhang-mingfei",
    "abstract": "Ethereum transitioned from Proof-of-Work consensus to Proof-of-Stake (PoS) consensus in September 2022. While this upgrade brings significant improvements (e.g., lower energy costs and higher throughput), it also introduces new vulnerabilities. One notable example is the so-called malicious reorganization attack. Malicious reorganization denotes an attack in which the Byzantine faulty validators intentionally manipulate the canonical chain so the blocks by honest validators are discarded. By doing so, the faulty validators can gain benefits such as higher rewards, lower chain quality, or even posing a liveness threat to the system.\nIn this work, we show that the majority of the known attacks on Ethereum PoS are some form of reorganization attacks. In practice, most of these attacks can be launched even if the network is synchronous (there exists a known upper bound for message transmission and processing). Different from existing studies that mitigate the attacks in an ad-hoc way, we take a systematic approach and provide an elegant yet efficient solution to reorganization attacks. Our solution is provably secure such that no reorganization attacks can be launched in a synchronous network. In a partially synchronous network, our approach achieves the conventional safety and liveness properties of the consensus protocol. Our evaluation results show that our solution is resilient to five types of reorganization attacks and also highly efficient."
  },
  {
    "id": 3641,
    "year": 2025,
    "title": "Approve Once, Regret Forever: On the Exploitation of Ethereum's Approve-TransferFrom Ecosystem",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/ruaro",
    "abstract": "Smart contracts are immutable programs hosted on the blockchain that power decentralized applications. With the growth of decentralized finance (DeFi), many services interact with contracts that must be trusted to manage digital assets. To this end, several Ethereum standards (e.g., ERC20, ERC721) introduced an approval mechanism that allows decentralized applications to trade digital assets (or \"tokens\") on behalf of others. After receiving an approval, the (approved) application can invoke the token's transferFrom function to trade the approved tokens. Unfortunately, approved applications often contain vulnerabilities. If an attacker maliciously controls the parameters of a transferFrom call, they can steal not only the application's assets but also the assets of any user who previously approved the application. We refer to this widespread issue as Approved Controllable TransferFrom (ACT), which has already led to losses exceeding 65 million USD.\nWe present Osprey, an end-to-end system that detects ACT vulnerabilities and automatically generates proof-of-concept attacks. Our evaluation across the entire Ethereum ecosystem identified 32,582 potentially vulnerable contracts, with 410 confirmed exploitable at the time of writing. Our findings reveal previously unknown attack vectors threatening digital assets worth over 3.4 million USD."
  },
  {
    "id": 3642,
    "year": 2025,
    "title": "Voting-Bloc Entropy: A New Metric for DAO Decentralization",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/fabrega-entropy",
    "abstract": "Decentralized Autonomous Organizations (DAOs) use smart contracts to foster communities working toward common goals. Existing definitions of decentralization, however—the 'D' in DAO—fall short of capturing the key properties characteristic of diverse and equitable participation.\nThis work proposes a new framework for measuring DAO decentralization called Voting-Bloc Entropy (VBE, pronounced \"vibe\"). VBE is based on the idea that voters with closely aligned interests act as a centralizing force and should be modeled as such. VBE formalizes this notion by measuring the similarity of participants' utility functions across a set of voting rounds. Unlike prior, ad hoc definitions of decentralization, VBE derives from first principles: We introduce a simple (yet powerful) reinforcement learning-based conceptual model for voting, that in turn implies VBE.\nWe first show VBE's utility as a theoretical tool. We prove a number of results about the (de)centralizing effects of vote delegation, proposal bundling, bribery, etc. that are overlooked in previous notions of DAO decentralization. Our results lead to practical suggestions for enhancing DAO decentralization.\nWe also show how VBE can be used empirically by presenting measurement studies and VBE-based governance experiments. We make the tools we developed for these results available to the community in the form of open-source artifacts in order to facilitate future study of DAO decentralization."
  },
  {
    "id": 3643,
    "year": 2025,
    "title": "Deanonymizing Ethereum Validators: The P2P Network Has a Privacy Issue",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/heimbach",
    "abstract": "Many blockchain networks aim to preserve the anonymity of validators in the peer-to-peer (P2P) network, ensuring that no adversary can link a validator's identifier to the IP address of a peer due to associated privacy and security concerns.\nThis work demonstrates that the Ethereum P2P network does not offer this anonymity. We present a methodology that enables any node in the network to identify validators hosted on connected peers and empirically verify the feasibility of our proposed method. Using data collected from four nodes over three days, we locate more than 15% of Ethereum validators in the P2P network. The insights gained from our deanonymization technique provide valuable information on the distribution of validators across peers, their geographic locations, and hosting organizations. We further discuss the implications and risks associated with the lack of anonymity in the P2P network and propose methods to help validators protect their privacy.\nThe Ethereum Foundation has awarded us a bug bounty, acknowledging the impact of our results."
  },
  {
    "id": 3644,
    "year": 2025,
    "title": "Let's Move2EVM",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/benetollo",
    "abstract": "The Move programming language, designed with strong safety guarantees such as linear resource semantics and borrow-checking, has emerged as a secure and reliable choice for writing smart contracts. However, these guarantees depend on the assumption that all interacting contracts are well-formed—a condition naturally met in Move's native execution environment but not in heterogeneous or untrusted platforms like the Ethereum Virtual Machine (EVM). This hinders the usage of Move as a source language for such platforms: for instance, we show in this paper that the existing Move-to-EVM compiler is not secure, meaning the compilation of secure Move contracts yields vulnerable EVM bytecode. \nThis work addresses the challenge of preserving Move's security guarantees when compiling to EVM. We introduce a novel compiler design extending the existing Move-to-EVM compiler with an Inlined-Reference-Monitor-(IRM)-based protection layer. Our approach enforces Move's linear semantics and borrow-checking rules at runtime in EVM, ensuring the correctness and safety of the compiled smart contracts, even in adversarial execution environments. We formally define the compilation process, establish correctness guarantees for the translation, and implement our protection mechanism in the original compiler. Our evaluation draws on three datasets: (i) an ERC-20 implementation in Solidity and Move, (ii) the Rosetta dataset curated by Bartoletti et al., and (iii) modules scraped from the Aptos blockchain. The performance evaluation shows that the gas cost overhead introduced by our compiler—compared both to the original compiler and Solidity-compiled code—is modest, thereby confirming our approach as a practical solution for bringing the security guarantees of Move code to the EVM."
  },
  {
    "id": 3645,
    "year": 2025,
    "title": "Ghost Clusters: Evaluating Attribution of Illicit Services through Cryptocurrency Tracing",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/lubbertsen",
    "abstract": "One of the principles in cryptocurrency tracing is putting a name to an address—a process called attribution. Attribution is key for both law enforcement and compliance professionals. Blockchain intelligence companies sell attribution as a service by leveraging pseudonymous blockchains, clustering heuristics, and labeling of addresses. In this paper, we perform a case study on Chainalysis, the market leader, and evaluate its attribution by comparing it against ground-truth data on three seized illicit services—BestMixer, Hansa Market, and Wall Street Market. To design the evaluation, we interview front-line law enforcement professionals and learn how they trace cryptocurrencies using blockchain intelligence providers. We identify three evaluation techniques— i.e., address overlap, money flows, and address roles—that realistically measure attribution in line with law enforcement use cases. Using these techniques, we show that for our three illicit services, Chainalysis provides a reliable lower bound (24.54 to 94.85 percent accurate), and produces very few false positives (less than 0.5 percent). Also, we find that coverage changes over time. We reason about factors that influence attribution and demonstrate the importance of attributing certain key addresses to achieve high coverage, and with that, show that when including a second blockchain intelligence provider, the difficulties in generalizing results."
  },
  {
    "id": 3646,
    "year": 2025,
    "title": "Surviving in Dark Forest: Towards Evading the Attacks from Front-Running Bots in Application Layer",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/ma-zuchao",
    "abstract": "Blockchains face significant risks from front-running attacks, leading to multi-billion USD losses. These attacks are often executed by front-running bots, automated tools that operate at high speed to execute transactions, exacerbating the threat landscape. Consequently, it is crucial for blockchain developers to design strategies at the application layer to mitigate these attacks. Interestingly, real-world strategies for evading front-running remain under-explored in their taxonomy and distribution due to their covert nature. Understanding these evasion tactics is vital for assessing the resilience of the current blockchain application layer and identifying areas for potential enhancement, thereby strengthening the ecosystem. In this work, we take the first step to demystify evading strategies in Ethereum and BNB Smart Chain. We propose EVScope, a novel framework combining binary analysis and machine learning to detect known and unknown evading strategies. Using EVScope, we examine 6,761,186 arbitrage transactions and 71 significant attack transactions that evaded the front-running attacks from bots in the wild. Our findings uncover 32 refined strategies involving access control, profit control, execution split, and code obfuscation. 25/32 are first introduced in this work, and 28/32 are first applied in evading front-running, which fills a critical gap in the literature."
  },
  {
    "id": 3647,
    "year": 2025,
    "title": "SoK: Inaccessible & Insecure: An Exposition of Authentication Challenges Faced by Blind and Visually Impaired Users in State-of-the-Art Academic Proposals",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/akanda",
    "abstract": "Despite the proliferation of advanced authentication methods in the academic research literature, it is not clear whether these methods would be suitable for blind and visually impaired users in terms of accessibility and security. To address this issue, we first developed the Authentication Literature Evaluation for Security and Accessibility (ALESA) framework consisting of 5 accessibility and 8 security features to measure the accessibility and security of these methods. Then, using this framework, we systematically evaluated 37 selected general-purpose academic authentication schemes if they were to be used by blind and visually impaired users and also explored 13 selected authentication schemes specifically designed for blind and visually impaired users, categorizing each type of scheme according to its underlying user interaction method. Our analysis reveals that many studied schemes may not only be insecure but also often fail to meet the specific needs of blind and visually impaired users, even when specifically designed for them. We found that most schemes struggle to balance accessibility and security, with many security issues arising from accessibility challenges, particularly in screen reader-assisted interaction scenarios. Our research urges researchers, developers, and policymakers to address these gaps and develop secure, accessible solutions for blind users."
  },
  {
    "id": 3648,
    "year": 2025,
    "title": "Scanned and Scammed: Insecurity by ObsQRity? Measuring User Susceptibility and Awareness of QR Code-Based Attacks",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/kowalewski",
    "abstract": "QR codes offer a seamless user experience and have become universal – from accessing websites over handling payments to using electric vehicles. However, their nature of displaying embedded data in a non human-readable format raises concerns about their misuse. While traditional phishing and scams are well-studied, how QR codes might increase users' exposure to such threats remains under-explored. Our research explores users' susceptibility to QR code-based scams and phishing and examines their perception of, experiences with, and (mis)understandings about QR codes. Across three experiments with 1,876 participants, we simulated everyday tasks like online payments and shopping, comparing user reactions to traditional and QR code-mediated attacks. While several participants detected traditional phishing, almost no one identified QR-based attacks. Similarly, only 13 % recognized fraudulent QR payment requests, compared to 46 % with manually entered payment details. These findings highlight the need for security measures, as users tend to be unaware of QR codes' characteristics and potential for misuse."
  },
  {
    "id": 3649,
    "year": 2025,
    "title": "URL Inspection Tasks: Helping Users Detect Phishing Links in Emails",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/lain",
    "abstract": "The most widespread type of phishing attack involves email messages with links pointing to malicious content. Despite user training and the use of detection techniques, these attacks are still highly effective. Recent studies show that it is user inattentiveness, rather than lack of education, that is one of the key factors in successful phishing attacks. To this end, we develop a novel phishing defense mechanism based on URL inspection tasks: small challenges (loosely inspired by CAPTCHAs) that, to be solved, require users to interact with, and understand, the basic URL structure. We implemented and evaluated three tasks that act as \"barriers\" to visiting the website: (1) correct click-selection from a list of URLs, (2) mouse-based highlighting of the domain-name URL component, and (3) re-typing the domain-name. These tasks follow best practices in security interfaces and warning design.\nWe assessed the efficacy of these tasks through an extensive on-line user study with 2,673 participants from three different cultures, native languages, and alphabets. Results show that these tasks significantly decrease the rate of successful phishing attempts, compared to the baseline case. Results also showed the highest efficacy for difficult URLs, such as typo-squats, with which participants struggled the most. This highlights the importance of (1) slowing down users while focusing their attention and (2) helping them understand the URL structure (especially, the domain-name component thereof) and matching it to their intent."
  },
  {
    "id": 3650,
    "year": 2025,
    "title": "Digital Security Perceptions and Practices Around the World: A WEIRD versus Non-WEIRD Comparison",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/herbert",
    "abstract": "Existing usable security and privacy research remains skewed toward WEIRD (Western, Educated, Industrialized, Rich, and Democratic) societies, whereas studies on non-WEIRD societies are scarce and mostly qualitative. The lack of large-scale cross-country comparisons makes it difficult to understand how people's security needs, perceptions, and practices vary across contexts and cultures. To fill this gap, we surveyed participants (N=12,351) from 12 countries across four continents – with seven WEIRD and five non-WEIRD countries – to examine participants' perceptions (e.g., regarding importance of different data types and risks posed by possible attackers) and practices (e.g., adoption of protective measures and prior negative experiences). We found significant differences between WEIRD versus non-WEIRD countries across almost all variables, with varying effect sizes. For instance, participants from non-WEIRD countries relied more on friends and family for advice on digital security than their WEIRD counterparts, but they also viewed friends and family as more likely attackers. We provide our interpretations of the cross-country differences, discuss how our findings inform security interventions and education, and summarize lessons learned from conducting cross-country research."
  },
  {
    "id": 3651,
    "year": 2025,
    "title": "SoK: Come Together – Unifying Security, Information Theory, and Cognition for a Mixed Reality Deception Attack Ontology & Analysis Framework",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/teymourian",
    "abstract": "We present a primary attack ontology and analysis framework for deception attacks in Mixed Reality (MR). This is achieved through multidisciplinary Systematization of Knowledge (SoK), integrating concepts from MR security, information theory, and cognition. While MR grows in popularity, it presents many cybersecurity challenges, particularly concerning deception attacks and their effects on humans. In this paper, we use the Borden-Kopp model of deception to develop a comprehensive ontology of MR deception attacks. Further, we derive two models to assess impact of MR deception attacks on information communication and decision-making. The first, an information-theoretic model, mathematically formalizes the effects of attacks on information communication. The second, a decision-making model, details the effects of attacks on interlaced cognitive processes. Using our ontology and models, we establish the MR Deception Analysis Framework (DAF) to assess the effects of MR deception attacks on information channels, perception, and attention. Our SoK uncovers five key findings for research and practice and identifies five research gaps to guide future work."
  },
  {
    "id": 3652,
    "year": 2025,
    "title": "Am I Infected? Lessons from Operating a Large-Scale IoT Security Diagnostic Service",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/sasaki",
    "abstract": "There is an expectation that users of home IoT devices will be able to secure those devices, but they may lack information about what they need to do. In February 2022, we launched a web service that scans users' IoT devices to determine how secure they are. The service aims to diagnose and remediate vulnerabilities and malware infections of IoT devices of Japanese users. This paper reports on findings from operating this service drawn from three studies: (1) the engagement of 114,747 users between February, 2022 - May, 2024; (2) a large-scale evaluation survey among service users (n=4,103), and; (3) an investigation and targeted survey (n=90) around the remediation actions of users of non-secure devices. During the operation, we notified 417 (0.36%) users that one or more of their devices were detected as vulnerable, and 171 (0.15%) users that one of their devices was infected with malware. The service found no issues for 99% of users. Still, 96% of all users evaluated the service positively, most often for it providing reassurance, being free of charge, and short diagnosis time. Of the 171 users with malware infections, 67 returned to the service later for a new check, with 59 showing improvement. Of the 417 users with vulnerable devices, 151 users revisited and re-diagnosed, where 75 showed improvement. We report on lessons learned, including a consideration of the capabilities that non-expert users will assume of a security scan."
  },
  {
    "id": 3653,
    "year": 2025,
    "title": "AirTag-Facilitated Stalking Protection: Evaluating Unwanted Tracking Notifications and Tracker Locating Features",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/gerhardt",
    "abstract": "Apple introduced AirTags in 2021 to help users find lost items. Their small size, affordability, and precise tracking functionality predestined them for technology-facilitated stalking, i.e., consentless tracking of others. As a countermeasure, Apple introduced anti-stalking features to impede misuse of AirTags: unwanted tracking notifications and two locating features. However, the reliability and effectiveness of these measures remain unclear.\nWe present two studies to evaluate unwanted tracking notifications and the tracker locating features. First, we quantify the reliability of unwanted tracking notifications on iOS and Android with NA = 50 fully informed participants. Second, we present a deception study to understand NB =19 participants' reactions to an unexpected tracking notification. Additionally, we asked participants to locate a hidden AirTag to study the locating features.\nWe found that unwanted tracking notifications are significantly more reliable and timely on iOS than on Android. Effective and safe responses to the tracking notification depended on prior knowledge about the technology or awareness of technology-facilitated abuse. Many disregarded the unobtrusive warning entirely. The Find My app's confusing UI made locating the tracker harder than necessary. We recommend (i) enhancing the urgency and clarity of tracking notifications and (ii) offering a guided UX for identifying and disabling trackers."
  },
  {
    "id": 3654,
    "year": 2025,
    "title": "PrivaCI in VR: Exploring Perceptions and Acceptability of Data Sharing in Virtual Reality Through Contextual Integrity",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/kablo",
    "abstract": "Virtual Reality (VR) is rapidly integrating into our everyday life, offering immersive experiences through interactive environments. However, its extensive data collection capabilities, including personal and behavioral information, pose significant privacy risks, which remain poorly understood. Despite existing research on VR privacy concerns, few studies explore the critical factors influencing data-sharing acceptability across user and non-user groups. To address this, we conducted an online survey with 1,198 participants from Germany, employing the Contextual Integrity (CI) framework to assess data-sharing acceptability, awareness, and privacy behaviors. Our findings indicate that consent and recipient are key factors influencing acceptability across all demographic groups examined, including age, gender, education, IT background, and VR usage. Many individuals remain unaware of the risks posed by VR's broad data collection and are dissatisfied with current privacy controls. This study contributes to understanding VR-specific privacy perceptions and highlights the urgent need for policymakers, developers, and manufacturers to establish clear standards and empower users with more transparent and granular privacy controls. Proactively addressing these challenges is crucial to maintaining user trust and ensuring VR's responsible integration into society."
  },
  {
    "id": 3655,
    "year": 2025,
    "title": "Shadowed Realities: An Investigation of UI Attacks in WebXR",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/mukherjee",
    "abstract": "WebXR is a standard web interface for extended reality that offers virtual environments and immersive 3D interactions, distinguishing it from the traditional web. However, these novel UI properties also introduce potential avenues for dark design exploitation. For instance, the absence of iframe-like elements in WebXR can be exploited by third parties, such as ad service providers, to inject JavaScript scripts and induce unintentional clicks or extract sensitive user information.\nIn this work, our objective is to identify and analyze the UI properties of WebXR vulnerable to exploitation by both first and third parties and to understand their impact on user experience. First, we examine vulnerable UI properties and propose five novel attack techniques that exploit one or more of these properties. We systematically categorize both existing and newly identified attacks within the advertising domain, to create a comprehensive taxonomy. Second, we design a user study framework to evaluate the impact of these attack categories employing dark designs on user experience. We develop a logging system to collect spatial data from 3D user interactions and integrate it with different WebXR applications that have different interaction needs. Additionally, we develop a set of metrics to derive meaningful insights from user interaction logs and assess how dark designs affect user behavior. Finally, we conduct a 100-participant between-subjects study using our user-study framework and survey.\nOur findings suggest that most of these dark patterns go largely unnoticed by users while effectively achieving their intended goals. However, the impact of these designs varies depending on their category and application type. Our comprehensive taxonomy, logging framework, metrics, and user study results help developers review and improve their practices and inspire researchers to develop more robust defense mechanisms to protect user data in immersive platforms."
  },
  {
    "id": 3656,
    "year": 2025,
    "title": "Unlocking the Power of Differentially Private Zeroth-order Optimization for Fine-tuning LLMs",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/bao-ergute",
    "abstract": "Differentially private zeroth-order optimization (DPZO in short) has shown promise in fine-tuning large language models (LLMs) while protecting record-level privacy. Compared with classical first-order methods, such as DPSGD, the main difference is that DPZO replaces the exact first-order gradients that are computed via back-propagation with its random zeroth-order approximations that are computed via querying the model's losses. However, DPZO still lags in the resulting model utility compared to existing methods, indicating that further work is needed to fully realize its potential. \nIn this paper, we make a solid step towards designing a better differentially private algorithm for fine-tuning LLMs based on zeroth-order optimization. Our design is centered around the major performance issue of differentially private optimization for large models caused by artificial clipping, which creates biases in the model updates. Using our method called DP-AggZO, we theoretically prove that this issue can be mitigated, leading to an improved convergence rate over the prior DPZO methods and better model utility under the same privacy constraints. We back up our theory with extensive experiments, validating the performance improvement of DP-AggZO. Surprisingly, our DP-AggZO even outperforms the state-of-the-art method DP-AdamW significantly on some benchmark settings."
  },
  {
    "id": 3657,
    "year": 2025,
    "title": "Membership Inference Attacks Against Vision-Language Models",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/hu-yuke",
    "abstract": "Vision-Language Models (VLMs), built on pre-trained vision encoders and large language models (LLMs), have shown exceptional multi-modal understanding and dialog capabilities, positioning them as catalysts for the next technological revolution. However, while most VLM research focuses on enhancing multi-modal interaction, the risks of data misuse and leakage have been largely unexplored. This prompts the need for a comprehensive investigation of such risks in VLMs.\nIn this paper, we conduct the first analysis of misuse and leakage detection in VLMs through the lens of membership inference attack (MIA). In specific, we focus on the instruction tuning data of VLMs, which is more likely to contain sensitive or unauthorized information. To address the limitation of existing MIA methods, we introduce a novel approach that infers membership based on a set of samples and their sensitivity to temperature, a unique parameter in VLMs. Based on this, we propose four membership inference methods, each tailored to different levels of background knowledge, ultimately arriving at the most challenging scenario. Our comprehensive evaluations show that these methods can accurately determine membership status, e.g., achieving an AUC greater than 0.8 targeting a small set consisting of only 5 samples on LLaVA."
  },
  {
    "id": 3658,
    "year": 2025,
    "title": "Towards Label-Only Membership Inference Attack against Pre-trained Large Language Models",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/he-yu",
    "abstract": "Membership Inference Attacks (MIAs) aim to predict whether a data sample belongs to the model's training set or not. Although prior research has extensively explored MIAs in Large Language Models (LLMs), they typically require accessing to complete output logits (i.e., logits-based attacks), which are usually not available in practice. In this paper, we study the vulnerability of pre-trained LLMs to MIAs in the label-only setting, where the adversary can only access generated tokens (text). We first reveal that existing label-only MIAs have minor effects in attacking pre-trained LLMs, although they are highly effective in inferring fine-tuning datasets used for personalized LLMs. We find that their failure stems from two main reasons, including better generalization and overly coarse perturbation. Specifically, due to the extensive pre-training corpora and exposing each sample only a few times, LLMs exhibit minimal robustness differences between members and non-members. This makes token-level perturbations too coarse to capture such differences.\nTo alleviate these problems, we propose PETAL: a label-only membership inference attack based on PEr-Token semAntic simiLarity. Specifically, PETAL leverages token-level semantic similarity to approximate output probabilities and subsequently calculate the perplexity. It finally exposes membership based on the common assumption that members are 'better' memorized and have smaller perplexity. We conduct extensive experiments on the WikiMIA benchmark and the more challenging MIMIR benchmark. Empirically, our PETAL performs better than the extensions of existing label-only attacks against personalized LLMs and even on par with other advanced logit-based attacks across all metrics on five prevalent open-source LLMs. Our study highlights that pre-trained LLMs remain vulnerable to privacy risks posed by MIAs even in the most challenging and realistic setting, calling for attention to develop more effective defenses."
  },
  {
    "id": 3659,
    "year": 2025,
    "title": "Depth Gives a False Sense of Privacy: LLM Internal States Inversion",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/dong-tian",
    "abstract": "Large Language Models (LLMs) are increasingly integrated into daily routines, yet they raise significant privacy and safety concerns. Recent research proposes collaborative inference, which outsources the early-layer inference to ensure data locality, and introduces model safety auditing based on inner neuron patterns. Both techniques expose the LLM's Internal States (ISs), which are traditionally considered irreversible to inputs due to optimization challenges and the highly abstract representations in deep layers. In this work, we challenge this assumption by proposing four inversion attacks that significantly improve the semantic similarity and token matching rate of inverted inputs. Specifically, we first develop two white-box optimization-based attacks tailored for low-depth and high-depth ISs. These attacks avoid local minima convergence, a limitation observed in prior work, through a two-phase inversion process. Then, we extend our optimization attack under more practical black-box weight access by leveraging the transferability between the source and the derived LLMs. Additionally, we introduce a generation-based attack that treats inversion as a translation task, employing an inversion model to reconstruct inputs. Extensive evaluation of short and long prompts from medical consulting and coding assistance datasets and 6 LLMs validates the effectiveness of our inversion attacks. Notably, a 4,112-token long medical consulting prompt can be nearly perfectly inverted with 86.88 F1 token matching from the middle layer of Llama-3 model. Finally, we evaluate four practical defenses that we found cannot perfectly prevent ISs inversion and draw conclusions for future mitigation design."
  },
  {
    "id": 3660,
    "year": 2025,
    "title": "I Know What You Said: Unveiling Hardware Cache Side-Channels in Local Large Language Model Inference",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/gao-zibo",
    "abstract": "Large Language Models (LLMs) that can be deployed locally have recently gained popularity for privacy-sensitive tasks, with companies such as Meta, Google, and Intel playing significant roles in their development. However, the security of local LLMs through the lens of hardware cache side-channels remains unexplored. In this paper, we unveil novel side-channel vulnerabilities in local LLM inference: token value and token position leakage, which can expose both the victim's input and output text, thereby compromising user privacy. Specifically, we found that adversaries can infer the token values from the cache access patterns of the token embedding operation, and deduce the token positions from the timing of autoregressive decoding phases. To demonstrate the potential of these leaks, we design a novel eavesdropping attack framework targeting both open-source and proprietary LLM inference systems. The attack framework does not directly interact with the victim's LLM and can be executed without privilege.\nWe evaluate the attack on a range of practical local LLM deployments (e.g., Llama, Falcon, and Gemma), and the results show that our attack achieves promising accuracy. The restored output and input text have an average edit distance of 5.2% and 17.3% to the ground truth, respectively. Furthermore, the reconstructed texts achieve average cosine similarity scores of 98.7% (input) and 98.0% (output)."
  },
  {
    "id": 3661,
    "year": 2025,
    "title": "Evaluating LLM-based Personal Information Extraction and Countermeasures",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/liu-yupei",
    "abstract": "Automatically extracting personal information—such as name, phone number, and email address—from publicly available profiles at a large scale is a stepstone to many other security attacks including spear phishing. Traditional methods—such as regular expression, keyword search, and entity detection—achieve limited success at such personal information extraction. In this work, we perform a systematic measurement study to benchmark large language model (LLM) based personal information extraction and countermeasures. Towards this goal, we present a framework for LLM-based extraction attacks; collect four datasets including a synthetic dataset generated by GPT-4 and three real-world datasets with manually labeled eight categories of personal information; introduce a novel mitigation strategy based on prompt injection; and systematically benchmark LLM-based attacks and countermeasures using ten LLMs and five datasets. Our key findings include: LLM can be misused by attackers to accurately extract various personal information from personal profiles; LLM outperforms traditional methods; and prompt injection can defend against strong LLM-based attacks, reducing the attack to less effective traditional ones."
  },
  {
    "id": 3662,
    "year": 2025,
    "title": "Synthetic Artifact Auditing: Tracing LLM-Generated Synthetic Data Usage in Downstream Applications",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/wu-yixin-auditing",
    "abstract": "Large language models (LLMs) have facilitated the generation of high-quality, cost-effective synthetic data for developing downstream models and conducting statistical analyses in various domains. However, the increased reliance on synthetic data may pose potential negative impacts. Numerous studies have demonstrated that LLM-generated synthetic data can perpetuate and even amplify societal biases and stereotypes, and produce erroneous outputs known as \"hallucinations'' that deviate from factual knowledge. In this paper, we aim to audit artifacts, such as classifiers, generators, or statistical plots, to identify those trained on or derived from synthetic data and raise user awareness, thereby reducing unexpected consequences and risks in downstream applications. To this end, we take the first step to introduce synthetic artifact auditing to assess whether a given artifact is derived from LLM-generated synthetic data. We then propose an auditing framework with three methods including metric-based auditing, tuning-based auditing, and classification-based auditing. These methods operate without requiring the artifact owner to disclose proprietary training details. We evaluate our auditing framework on three text classification tasks, two text summarization tasks, and two data visualization tasks across three training scenarios. Our evaluation demonstrates the effectiveness of all proposed auditing methods across all these tasks. For instance, black-box metric-based auditing can achieve an average accuracy of 0.868 pm 0.071 for auditing classifiers and 0.880 pm 0.052 for auditing generators using only 200 random queries across three scenarios. We hope our research will enhance model transparency and regulatory compliance, ensuring the ethical and responsible use of synthetic data."
  },
  {
    "id": 3663,
    "year": 2025,
    "title": "Data-Free Model-Related Attacks: Unleashing the Potential of Generative AI",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/ye-attacks",
    "abstract": "Generative AI technology has become increasingly integrated into our daily lives, offering powerful capabilities to enhance productivity. However, these same capabilities can be exploited by adversaries for malicious purposes. While existing research on adversarial applications of generative AI predominantly focuses on cyberattacks, less attention has been given to attacks targeting deep learning models. In this paper, we introduce the use of generative AI for facilitating model-related attacks, including model extraction, membership inference, and model inversion. Our study reveals that adversaries can launch a variety of model-related attacks against both image and text models in a data-free and black-box manner, achieving comparable performance to baseline methods that have access to the target models' training data and parameters in a white-box manner. This research serves as an important early warning to the community about the potential risks associated with generative AI-powered attacks on deep learning models. The source code is provided at: https://zenodo.org/records/14737003."
  },
  {
    "id": 3664,
    "year": 2025,
    "title": "When LLMs Go Online: The Emerging Threat of Web-Enabled LLMs",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/kim-hanna",
    "abstract": "Recent advancements in Large Language Models (LLMs) have established them as agentic systems capable of planning and interacting with various tools. These LLM agents are often paired with web-based tools, enabling access to diverse sources and real-time information. Although these advancements offer significant benefits across various applications, they also increase the risk of malicious use, particularly in cyberattacks involving personal information. In this work, we investigate the risks associated with misuse of LLM agents in cyberattacks involving personal data. Specifically, we aim to understand: 1) how potent LLM agents can be when directed to conduct cyberattacks, 2) how cyberattacks are enhanced by web-based tools, and 3) how affordable and easy it becomes to launch cyberattacks using LLM agents. We examine three attack scenarios: the collection of Personally Identifiable Information (PII), the generation of impersonation posts, and the creation of spear-phishing emails. Our experiments reveal the effectiveness of LLM agents in these attacks: LLM agents achieved a precision of up to 95.9% in collecting PII, generated impersonation posts where 93.9% of them were deemed authentic, and boosted click rate of phishing links in spear phishing emails by 46.67%. Additionally, our findings underscore the limitations of existing safeguards in contemporary commercial LLMs, emphasizing the urgent need for robust security measures to prevent the misuse of LLM agents."
  },
  {
    "id": 3665,
    "year": 2025,
    "title": "Enabling Low-Cost Secure Computing on Untrusted In-Memory Architectures",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/ghinani",
    "abstract": "Modern computing systems are limited in performance by the memory bandwidth available to processors, a problem known as the memory wall. Processing-in-Memory (PIM) promises to substantially improve this problem by moving processing closer to the data, improving effective data bandwidth, and leading to superior performance on memory-intensive workloads. However, integrating PIM modules within a secure computing system raises an interesting challenge: unencrypted data has to move off-chip to the PIM, exposing the data to attackers and breaking assumptions on Trusted Computing Bases (TCBs). To tackle this challenge, this paper leverages multi-party computation (MPC) techniques, specifically arithmetic secret sharing and Yao's garbled circuits, to outsource bandwidth-intensive computation securely to PIM. Additionally, we leverage precomputation optimization to prevent the CPU's portion of the MPC from becoming a bottleneck. We evaluate our approach using the UPMEM PIM system over various applications such as Deep Learning Recommendation Model inference and Logistic Regression. Our evaluations demonstrate up to a 14.66x speedup compared to a secure CPU configuration while maintaining data confidentiality and integrity when outsourcing linear and/or nonlinear computation."
  },
  {
    "id": 3666,
    "year": 2025,
    "title": "AidFuzzer: Adaptive Interrupt-Driven Firmware Fuzzing via Run-Time State Recognition",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/wang-jianqiang",
    "abstract": "Fuzzing has proven to be an effective method for discovering vulnerabilities in firmware images. However, several hard-to-bypass obstacles still block the way for fuzzers to achieve higher code coverage in the firmware fuzzing process. One major issue is interrupt handling, which is fundamental to emulate the firmware: If interrupts are triggered incorrectly, the firmware may crash or get stuck, even at an early stage. Thus, a proper mechanism for triggering and handling interrupts is a crucial yet under-researched aspect of firmware fuzzing. In this paper, we present AidFuzzer, an adaptive interrupt-driven firmware fuzzing method, to tackle the interrupt triggering problem. The key observation is that firmware images commonly exhibit a consistent run-time state transition cycle. In each state, the firmware may require specific interrupts to continue running, or it may not need any interrupts to continue processing data. Based on this observation, we model the type and status of the interrupts to verify that they are exactly the interrupts that the firmware needs at a specific point in time. Moreover, we monitor the run-time state of the firmware and trigger certain interrupts when the firmware expects them or let the firmware run when it does not require interrupts. We have implemented a prototype of AidFuzzer and evaluated it on 10 open-source firmware projects, including well-known real-time operating systems such as RT-Thread and Apache Mynewt-OS. The experiment demonstrates that our framework outperforms state-of-the-art works in terms of coverage when dealing with complex interrupt handling. We also discovered eight previously unknown vulnerabilities in the tested firmware images."
  },
  {
    "id": 3667,
    "year": 2025,
    "title": "GenHuzz: An Efficient Generative Hardware Fuzzer",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/wu-lichao",
    "abstract": "Hardware security is crucial for ensuring trustworthy computing systems. However, the growing complexity of hardware designs has introduced new vulnerabilities that are challenging and expensive to address after fabrication. Hardware fuzz testing, particularly whitebox fuzzing, is promising for scalable and adaptable hardware vulnerability detection. Despite its potential, existing hardware fuzzers face significant challenges, including the complexity of input semantics, limited feedback utilization, and the need for extensive test cases.\nTo address these limitations, we propose GenHuzz, a novel white-box hardware fuzzing framework that reframes fuzzing as an optimization problem by optimizing the fuzzing policy to generate more subtle and effective test cases for vulnerability and bug detection. GenHuzz utilizes a language model-based fuzzer to intelligently generate RISC-V assembly instructions, which are then dynamically optimized through a Hardware-Guided Reinforcement Learning framework incorporating real-time feedback from the hardware. GenHuzz is uniquely capable of understanding and exploiting complex interdependencies between instructions, enabling the discovery of deeper bugs and vulnerabilities. Our evaluation of three RISC-V cores demonstrates that GenHuzz achieves significantly higher hardware coverage with fewer test cases than four state-of-the-art fuzzers. GenHuzz detects all known bugs reported in existing studies with fewer test cases. Furthermore, it uncovers 10 new vulnerabilities, 5 of which are the most severe hardware vulnerabilities ever detected by a hardware fuzzer targeting the same cores, with CVSS v3 severity scores exceeding 7.3 out of 10."
  },
  {
    "id": 3668,
    "year": 2025,
    "title": "Software Availability Protection in Cyber-Physical Systems",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/li-ao",
    "abstract": "Existing efforts in software protection have mostly focused on how to detect violations of confidentiality or integrity, with the goal of safeguarding information or ensuring the correctness of execution. Little has been done to study the handling of such violations, where the common practice is to crash the program. However, such strategies sacrifice availability, which is not acceptable in real-time safety-critical cyber-physical systems (CPSs), where untimely computation can have catastrophic physical-world consequences.\nTo bridge this gap, we present Gecko, an attack recovery approach that not only timely recovers the execution from the attack but also disables exploited features to improve system availability. Realizing Gecko presents two technical challenges. To defend against repeated exploitation, Gecko utilizes compartmentalization for runtime attack input identification and introduces fail-safe shadow compartments to disable the exploited features while ensuring graceful degradation. To remove attack impacts in a timely manner, Gecko employs selective data reset through snapshot recovery. It further uses an I/O reference monitor to avoid peripheral re-configuration. We developed a prototype of Gecko and evaluated it on three CPS platforms: ArduPilot, Jackal UGV, and OpenManipulator. Gecko achieves recovery with 83.3% task deadline hits while incurring a runtime overhead of 8.28%."
  },
  {
    "id": 3669,
    "year": 2025,
    "title": "GDMA: Fully Automated DMA Rehosting via Iterative Type Overlays",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/scharnowski",
    "abstract": "Embedded systems are the critical interface between the physical and the digital world, where security breaches can lead to significant harm. In recent years, rehosting has proven to be an effective method for dynamic security testing of embedded systems. However, existing approaches largely ignore the automated rehosting of Direct Memory Access (DMA), a key mechanism for receiving untrusted data. The only fully automated DMA rehosting approach considers just one out of six common DMA mechanisms, leaving significant gaps in the security analysis of firmware.\nIn this work, we introduce GDMA, a comprehensive solution for fully automated DMA rehosting. GDMA successfully emulates all six DMA configuration mechanisms by analyzing emulation traces to identify the two critical DMA usage steps: DMA configuration and DMA buffer usage. More specifically, it first collects type information on MMIO registers that consistently behave like pointers. We organize this information in type trees, which capture relationships between MMIO registers and the memory regions they reference. GDMA then overlays and merges these trees to iteratively distill a DMA configuration. By applying this configuration in a generic DMA peripheral, GDMA enables effective testing of DMA-dependent firmware. We evaluate GDMA on a total of 114 firmware images. Compared to the state of the art, GDMA is the first to successfully emulate all samples of the state-of-the-art benchmark, reaching 3x the DMA mechanism coverage. We also introduce a fully reproducible data set to systematically evaluate DMA rehosting of all six mechanisms. GDMA successfully rehosts all of these, which is a factor of 6x compared to existing methods. Finally, we evaluate GDMA on various DMA-enabled firmware and discover 6 new bugs with 6 assigned CVEs following a coordinated disclosure."
  },
  {
    "id": 3670,
    "year": 2025,
    "title": "Kintsugi: Secure Hotpatching for Code-Shadowing Real-Time Embedded Systems",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/mackensen",
    "abstract": "Mission-critical embedded devices deal with strict real-time constraints, and thus make traditional updates or reboots unsuitable. While runtime fixes (i.e., hotpatching) reduce downtime, they pose challenges for resource management and real-time performance. Previous work has focused mainly on hotpatching devices executing their firmware from flash, neglecting those that use code-shadowing to execute firmware from RAM. These approaches neglect secure end-to-end hotpatch deployment during runtime, putting vulnerable devices at risk.\nWe introduce Kintsugi, the first secure hotpatching framework for real-time embedded devices that uses code-shadowing. By leveraging the context switch of real-time operating systems, we achieve atomic application of hotpatches while enforcing strict memory policies to protect Kintsugi's resources with minimal overhead. Kintsugi is designed to prevent tampering attacks on both the framework and deployed hotpatches. Evaluated on the NRF52840-DK with an ARM Cortex-M4 MCU running at 64 MHz, a processor deployed in millions of devices, our results demonstrate Kintsugi's performance advantage with overheads as low as 38 cycles (0.59 \\mu s) during normal operation, peaking at 216 cycles (3.38 \\mu s). We show Kintsugi's effectiveness addressing real-world vulnerabilities in popular real-time operating systems like FreeRTOS and Zephyr, and libraries such as mbedTLS and picoTCP. Our approach introduces negligible overhead, making it ideal for real-time applications, as illustrated by our case study."
  },
  {
    "id": 3671,
    "year": 2025,
    "title": "Security Implications of Malicious G-Codes in 3D Printing",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/rossel",
    "abstract": "The rapid growth of 3D printing technology has transformed a wide range of industries, enabling the on-demand production of complex objects, from aerospace components to medical devices. However, this technology also introduces significant security challenges. Previous research highlighted the security implications of G-Codes—commands used to control the printing process. These studies assumed powerful attackers and focused on manipulations of the printed models, leaving gaps in understanding the full attack potential.\nIn this study, we systematically analyze security threats associated with 3D printing, focusing specifically on vulnerabilities caused by G-Code commands. We introduce attacks and attacker models that assume a less powerful adversary than traditionally considered, broadening the scope of potential security threats. Our findings show that even minimal access to the 3D printer can result in significant security breaches, such as unauthorized access to subsequent print jobs or persistent misconfiguration of the printer. We identify 278 potentially malicious G-Codes across the attack categories Information Disclosure, Denial of Service, and Model Manipulation. Our evaluation demonstrates the applicability of these attacks across various 3D printers and their firmware. Our findings underscore the need for a better standardization process of G-Codes and corresponding security best practices."
  },
  {
    "id": 3672,
    "year": 2025,
    "title": "Secure Information Embedding in Forensic 3D Fingerprinting",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/wang-canran",
    "abstract": "Printer fingerprinting techniques have long played a critical role in forensic applications, including the tracking of counterfeiters and the safeguarding of confidential information. The rise of 3D printing technology introduces significant risks to public safety, enabling individuals with internet access and consumer-grade 3D printers to produce untraceable firearms, counterfeit products, and more. This growing threat calls for a better mechanism to track the production of 3D-printed parts.\nInspired by the success of fingerprinting on traditional 2D printers, we introduce SIDE (Secure Information EmbeDding and Extraction), a novel fingerprinting framework tailored for 3D printing. SIDE addresses the adversarial challenges of 3D print forensics by offering both secure information embedding and extraction. First, through novel coding-theoretic techniques, SIDE is both~break-resilient and~loss-tolerant, enabling fingerprint recovery even if the adversary breaks the print into fragments and conceals a portion of them. Second, SIDE further leverages Trusted Execution Environments (TEE) to secure the fingerprint embedding process."
  },
  {
    "id": 3673,
    "year": 2025,
    "title": "SoK: A Security Architect's View of Printed Circuit Board Attacks",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/harrison",
    "abstract": "Many recent papers have proposed novel electrical measurements or physical inspection technologies for defending printed circuit boards (PCBs) and PCB assemblies (PCBAs) against tampering. As motivation, these papers frequently cite Bloomberg News' \"The Big Hack'', video game modchips, and \"interdiction attacks'' on IT equipment. We find this trend concerning for two reasons. First, implementation errors and security architecture are rarely discussed in recent PCBA security research, even though they were the root causes of these commonly-cited attacks and most other attacks that have occurred or been proposed by researchers. This suggests that the attacks may be poorly understood. Second, if we assume that novel countermeasures and validation methodologies are tailored to these oft-cited attacks, then significant recent work has focused on attacks that can already be mitigated instead of on open problems.\nWe write this SoK to address these concerns. We explain which tampering threats can be mitigated by a PCBA security architecture. Then, we enumerate assumptions that security architecture depends on. We compare and contrast assurances achieved by security architecture vs. by recently-proposed electrical or inspection-based tamper detection. Finally, we review over fifty PCBA attacks to show how most can be prevented by proper architecture and careful implementation."
  },
  {
    "id": 3674,
    "year": 2025,
    "title": "Dumbo-MPC: Efficient Fully Asynchronous MPC with Optimal Resilience",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/su-yuan",
    "abstract": "Fully asynchronous multi-party computation (AMPC) has superior robustness in realizing privacy and guaranteed output delivery (G.O.D.) against asynchronous adversaries that can arbitrarily delay communications. However, none of these protocols are truly practical, as they either have sub-optimal resilience, incur cumbersome communication cost, or suffer from an online phase with extra cryptographic overhead. The only attempting implementation—HoneyBadgerMPC (hbMPC)—merely ensures G.O.D. in some implausible optimistic cases due to a non-robust offline pre-processing phase.\nWe propose Dumbo-MPC a concretely efficient AMPC-as-a-service design with all-phase G.O.D. and optimal resilience against t < n/3 malicious parties (where n is the total number of parties). Similar to hbMPC, Dumbo-MPC has a robust (almost) information-theoretic online phase that can efficiently perform online computations, given pre-processed multiplication triples. To achieve all-phase G.O.D., we design a novel dual-mode offline protocol that can robustly pre-process multiplication triples in asynchrony. The offline phase features O(n) per-triple communication in the optimistic case, followed by a fully asynchronous fallback to a pessimistic path to securely restore G.O.D. in the bad case. To (concretely) efficiently implement the pessimistic path, we devise a concretely efficient zk-proof for the product relationship of secret shares over compact KZG polynomial commitments, which enables us to reduce the degree of two secret shares' product from 2t to t and could be of independent interest.\nWe also implement and extensively evaluate Dumbo-MPC (particularly its offline phase) in varying network settings with up to 31 AWS servers. To our knowledge, we provide the first AMPC implementation with all-phase G.O.D. A recent asynchronous triple generation protocol from Groth and Shoup (GS23) is also implemented and experimentally compared. When n = 31, Dumbo-MPC generates 94 triples/sec (almost twice as many as GS23) in the pessimistic case and 349 triples/sec (about 6X of GS23) in the good case."
  },
  {
    "id": 3675,
    "year": 2025,
    "title": "FABLE: Batched Evaluation on Confidential Lookup Tables in 2PC",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/su-zhengyuan",
    "abstract": "Secure two-party computation (2PC) is a cryptographic technique that enables two mutually distrusting parties to jointly evaluate a function over their private inputs. We consider a 2PC primitive called confidential lookup table (LUT) evaluation, which is useful in privacy-preserving ML inference and data analytics. In this setting, a server holds a confidential LUT and evaluates it over an input secret shared between a client and the server, producing a secret-shared output. Existing approaches suffer from high asymptotic complexity and practical inefficiency, with some designs lacking confidentiality guarantees for the LUT. Recognizing that many applications of confidential LUT evaluation require processing multiple inputs with the same LUT, we propose FABLE, a system designed to efficiently evaluate a LUT on a large batch of queries simultaneously. Compared to the state-of-the-art confidential LUT evaluation methods, FABLE achieves up to 28-101× speedup in LAN environments and up to 50-393× speedup in WAN environments."
  },
  {
    "id": 3676,
    "year": 2025,
    "title": "MAESTRO: Multi-Party AES Using Lookup Tables",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/morita",
    "abstract": "Secure multi-party computation (MPC) enables multiple distrusting parties to jointly compute a function while keeping their inputs private. Computing the AES block cipher in MPC, where the key and/or the input are secret-shared among the parties is important for various applications, particularly threshold cryptography.\nIn this work, we propose a family of dedicated, high-performance MPC protocols to compute the non-linear S-box part of AES in the honest majority setting. Our protocols come in both semi-honest and maliciously secure variants. The core technique is a combination of lookup table protocols based on random one-hot vectors and the decomposition of finite field inversion in GF(2^8) into multiplications and inversion in the smaller field GF(2^4), taking inspiration from ideas used for hardware implementations of AES. We also apply and improve the analysis of a batch verification technique for checking inner products with logarithmic communication. This allows us to obtain malicious security with almost no communication overhead, and we use it to obtain new, secure table lookup protocols with only O(\\sqrt{N}) communication for a table of size N, which may be useful in other applications.\nOur protocols have different trade-offs, such as having a similar round complexity as previous state-of-the-art by Chida et al. [WAHC '18] but 37% lower bandwidth costs, or having 27% fewer rounds and 16% lower bandwidth costs. An experimental evaluation in various network conditions using three party replicated secret sharing shows improvements in throughput between 28% and 71% in the semi-honest setting. For malicious security, we improve throughput by 319% to 384% in LAN and by 717% in WAN due to sublinear batch verification."
  },
  {
    "id": 3677,
    "year": 2025,
    "title": "Efficient 2PC for Constant Round Secure Equality Testing and Comparison",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/lu",
    "abstract": "Secure equality testing and comparison are two important primitives widely used in many secure computation scenarios, such as privacy-preserving machine learning, private set intersection, and secure data mining, etc. This work proposes new constant-round two-party computation (2PC) protocols for secure equality testing and comparison. Our protocols are designed in the online/offline paradigm. For 32-bit inputs, the online communication cost of our equality testing protocol and secure comparison protocol are as low as 76 bits (1% of ABY) and 384 bits (5% of ABY) , respectively. \nOur benchmarks show that (i) for 32-bit equality testing, our scheme performs 9x faster than the Guo et al. (EUROCRYPT 2023) and 15x of the garbled circuit (GC) with the half-gate optimization (CRYPTO 2015). (ii) for 32-bit secure comparison, our scheme performs 3x faster than Guo et al. (EUROCRYPT 2023), 6x faster than both Rathee et al. (CCS 2020) and GC with the half-gate optimization."
  },
  {
    "id": 3678,
    "year": 2025,
    "title": "Efficient Multi-Party Private Set Union Without Non-Collusion Assumptions",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/dong-minglang",
    "abstract": "Multi-party private set union (MPSU) protocol enables m (m > 2) parties, each holding a set, to collectively compute the union of their sets without revealing any additional information to other parties. There are two main categories of multi-party private set union (MPSU) protocols: The first category builds on public-key techniques, where existing works require a super-linear number of public-key operations, resulting in their poor practical efficiency. The second category builds on oblivious transfer and symmetric-key techniques. The only work in this category, proposed by Liu and Gao (ASIACRYPT 2023), features the best concrete performance among all existing protocols, but still has super-linear computation and communication. Moreover, it does not achieve the standard semi-honest security, as it inherently relies on a non-collusion assumption, which is unlikely to hold in practice.\nThere remain two significant open problems so far: no MPSU protocol achieves semi-honest security based on oblivious transfer and symmetric-key techniques, and no MPSU protocol achieves both linear computation and linear communication complexity. In this work, we resolve both of them.\n\nWe propose the first MPSU protocol based on oblivious transfer and symmetric-key techniques in the standard semi-honest model. This protocol is 3.9-10.0 x faster than Liu and Gao in the LAN setting. Concretely, our protocol requires only 4.4 seconds in online phase for 3 parties with sets of 2^20 items each.\nWe propose the first MPSU protocol achieving both linear computation and linear communication complexity, based on public-key operations. This protocol has the lowest overall communication costs and shows a factor of 3.0-36.5x improvement in terms of overall communication compared to Liu and Gao.\n\nWe implement our protocols and conduct an extensive experiment to compare the performance of our protocols and the state-of-the-art. To the best of our knowledge, our code is the first correct and secure implementation of MPSU that reports on large-size experiments."
  },
  {
    "id": 3679,
    "year": 2025,
    "title": "Scalable Collaborative zk-SNARK and Its Application to Fully Distributed Proof Delegation",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/liu-xuanming",
    "abstract": "Collaborative zk-SNARK (USENIX '22) allows multiple parties to compute a proof over distributed witness. It offers a promising application called proof delegation (USENIX '23), where a client delegates the tedious proof generation to many servers while ensuring no one can learn the witness. Unfortunately, existing works suffer from significant efficiency issues and face challenges when scaling to complex applications.\nIn this work, we introduce the first scalable collaborative zk-SNARK for general circuits, built upon HyperPlonk (Eurocrypt '23). Our result overcomes existing barriers, offering fully distributed workload and small communication. For data-parallel circuits, the communication overhead is even sublinear. We propose several efficient collaborative and distributed protocols for multivariate primitives, which form the main building blocks of our results and may be of independent interest. In addition, we design a new permutation check protocol for Plonk arithmetization, which is MPC-friendly and suitable for collaborative zk-SNARKs.\nWith 128 servers jointly generating a proof for a circuit of size 2^21 gates, the experiment demonstrates over 30x speedup and reduced RAM requirements compared to a local prover, while the witness is still private. Previous works were unable to achieve such savings in both time and memory efficiency. Moreover, our protocol performs well under various network conditions, making it practical for real-world applications."
  },
  {
    "id": 3680,
    "year": 2025,
    "title": "zkGPT: An Efficient Non-interactive Zero-knowledge Proof Framework for LLM Inference",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/qu-zkgpt",
    "abstract": "Large Language Models (LLMs) are widely employed for their ability to generate human-like text. However, service providers may deploy smaller models to reduce costs, potentially deceiving users. Zero-Knowledge Proofs (ZKPs) offer a solution by allowing providers to prove LLM inference without compromising the privacy of model parameters. Existing solutions either do not support LLM architectures or suffer from significant inefficiency and tremendous overhead. To address this issue, this paper introduces several new techniques. We propose new methods to efficiently prove linear and non-linear layers in LLMs, reducing computation overhead by orders of magnitude. To further enhance efficiency, we propose constraint fusion to reduce the overhead of proving non-linear layers and circuit squeeze to improve parallelism. We implement our efficient protocol, specifically tailored for popular LLM architectures like GPT-2, and deploy optimizations to enhance performance. Experiments show that our scheme can prove GPT-2 inference in less than 25 seconds. Compared with state-of-the-art systems such as Hao et al. (USENIX Security'24) and ZKML (Eurosys'24), our work achieves nearly 279x and 185x speedup, respectively."
  },
  {
    "id": 3681,
    "year": 2025,
    "title": "DFS: Delegation-friendly zkSNARK and Private Delegation of Provers",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/hu-yuncong",
    "abstract": "Zero-Knowledge Succinct Non-interactive Arguments of Knowledge (zkSNARKs) lead to proofs that can be succinctly verified but require huge computational resources to generate. Prior systems outsource proof generation either through public delegation, which reveals the witness to the third party, or, more preferably, private delegation that keeps the witness hidden using multiparty computation (MPC). However, current private delegation schemes struggle with scalability and efficiency due to MPC inefficiencies, poor resource utilization, and suboptimal design of zkSNARK protocols.\nIn this paper, we introduce DFS, a new zkSNARK that is delegation-friendly for both public and private scenarios. Prior work focused on optimizing the MPC protocols for existing zkSNARKs, while DFS uses co-design between MPC and zkSNARK so that the protocol is efficient for both distributed computing and MPC. In particular, DFS achieves linear prover time and logarithmic verification cost in the non-delegated setting. For private delegation, DFS introduces a scheme with zero communication overhead in MPC and achieves malicious security for free, which results in logarithmic overall communication; while prior work required linear communication. Our evaluation shows that DFS is as efficient as state-of-the-art zkSNARKs in public delegation; when used for private delegation, it scales better than previous work. In particular, for 2^24 constraints, the total communication of DFS is less than 500KB, while prior work incurs 300GB, which is linear to the circuit size. Additionally, we identify and address a security flaw in prior work, EOS (USENIX'23)."
  },
  {
    "id": 3682,
    "year": 2025,
    "title": "SoK: Understanding zk-SNARKs: The Gap Between Research and Practice",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/liang-sok",
    "abstract": "Zero-knowledge succinct non-interactive argument of knowledge (zk-SNARK) serves as a powerful technique for proving the correctness of computations and has attracted significant interest from researchers. Numerous concrete schemes and implementations have been proposed in academia and industry. Unfortunately, the inherent complexity of zk-SNARK has created gaps between researchers, developers and users, as they focus differently on this technique. For example, researchers are dedicated to constructing new efficient proving systems with stronger security and new properties. At the same time, developers and users care more about the implementation's toolchains, usability and compatibility. This gap has hindered the development of zk-SNARK field.\nIn this work, we provide a comprehensive study of zk-SNARK, from theory to practice, pinpointing gaps and limitations. We first present a master recipe that unifies the main steps in converting a program into a zk-SNARK. We then classify existing zk-SNARKs according to their key techniques. Our classification addresses the main difference in practically valuable properties between existing zk-SNARK schemes. We survey over 40 zk-SNARKs since 2013 and provide a reference table listing their categories and properties. Following the steps in master recipe, we then survey 11 general-purpose popular used libraries. We elaborate on these libraries' usability, compatibility, efficiency and limitations. Since installing and executing these zk-SNARK systems is challenging, we also provide a completely virtual environment in which to run the compiler for each of them. We identify that the proving system is the primary focus in cryptography academia. In contrast, the constraint system presents a bottleneck in industry. To bridge this gap, we offer recommendations and advocate for the open-source community to enhance documentation, standardization and compatibility."
  },
  {
    "id": 3683,
    "year": 2025,
    "title": "A Mixed-Methods Study of Open-Source Software Maintainers On Vulnerability Management and Platform Security Features",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/ayala",
    "abstract": "In open-source software (OSS), software vulnerabilities have significantly increased. Although researchers have investigated the perspectives of vulnerability reporters and OSS contributor security practices, understanding the perspectives of OSS maintainers on vulnerability management and platform security features is currently understudied. In this paper, we investigate the perspectives of OSS maintainers who maintain projects listed in the GitHub Advisory Database. We explore this area by conducting two studies: identifying aspects through a listing survey ($n_1 = 80$) and gathering insights from semi-structured interviews ($n_2 = 22$). Of the 37 identified aspects, we find that supply chain mistrust and lack of automation for vulnerability management are the most challenging, and barriers to adopting platform security features include a lack of awareness and the perception that they are not necessary. Surprisingly, we find that despite being previously vulnerable, some maintainers still allow public vulnerability reporting, or ignore reports altogether. Based on our findings, we discuss implications for OSS platforms and how the research community can better support OSS vulnerability management efforts."
  },
  {
    "id": 3684,
    "year": 2025,
    "title": "\"Threat modeling is very formal, it's very technical, and also very hard to do correctly\": Investigating Threat Modeling Practices in Open-Source Software Projects",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/kaur",
    "abstract": "Vulnerabilities in open-source software (OSS) projects can potentially impact millions of users and large parts of the software supply chain. Rigorous secure design practices, such as threat modeling (TM), can help identify threats and determine and prioritize mitigations early in the development lifecycle. However, there is limited evidence regarding how OSS developers consider threats and mitigations and whether they use established TM methods.\nOur research is the first to fill this gap by investigating OSS developers' TM practices and experiences. Using semi-structured interviews with 25 OSS developers, we explore participants' threat finding and mitigation practices, their challenges and reasons for adopting their practices, as well as desired support for implementing TM in their open-source projects. Because OSS development is often a volunteer effort, decentralized, and lacking security expertise, more structured TM methods introduce additional costs and are perceived as having limited benefit. Instead, we find almost all OSS developers conduct TM practices in an ad hoc manner due to the ease-of-use, flexibility, and low overhead of this approach. Based on our findings, we provide recommendations for the OSS community to better support TM processes in OSS."
  },
  {
    "id": 3685,
    "year": 2025,
    "title": "\"I wasn't sure if this is indeed a security risk\": Data-driven Understanding of Security Issue Reporting in GitHub Repositories of Open Source npm Packages",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/ghosh",
    "abstract": "The npm (Node Package Manager) ecosystem is the most important package manager for JavaScript development with millions of users. Consequently, a plethora of earlier work investigated how vulnerability reporting, patch propagation, and in general detection as well as resolution of security issues in such ecosystems can be facilitated. However, understanding the ground reality of security-related issue reporting by users (and bots) in npm--along with the associated challenges--has been relatively less explored at scale.\nIn this work, we bridge this gap by collecting 10,907,467 issues reported across GitHub repositories of 45,466 diverse npm packages. We found that the tags associated with these issues indicate the existence of only 0.13% security-related issues. However, our approach of manual analysis followed by developing high-accuracy machine learning models identify 1,617,738 security-related issues which are not tagged as security-related (14.8% of all issues) as well as 4,461,934 comments made on these issues. We found that the bots which are in wide use today might not be sufficient for either detecting or offering assistance with these issues. Furthermore, our analysis of user-developer interaction data hints that many user-reported security issues might not be addressed by developers—they are not tagged as security-related issues and might be closed without valid justification. Consequently, a correlation analysis hints that the developers quickly handle security issues with known solutions (e.g., corresponding to CVE, or with a suggested solution). However, security issues without such known solutions (even with reproducible code) might not be resolved, hinting at a need for better-automated assistance for npm developers to address security issues. Our findings offer actionable insights for improving security management in open-source ecosystems, highlighting the need for smarter tools and better collaboration. The data and code for this work is available at https://doi.org/10.5281/zenodo.15614029"
  },
  {
    "id": 3686,
    "year": 2025,
    "title": "Context Matters: Qualitative Insights into Developers' Approaches and Challenges with Software Composition Analysis",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/lin-elizabeth",
    "abstract": "Software Composition Analysis (SCA) is an important part in the software security lifecycle. Establishing the individual software components and versions that make up an application allows for identifying and remediating vulnerabilities. However, SCA tools have not kept up with the ever growing number of new vulnerabilities each year. Developers are flooded with vulnerability alerts and often struggle to quickly remediate critical issues with external components.\nWe conducted 20 interviews with developers to investigate their processes and challenges around using SCA in their software projects. Interviews covered how SCA tools are integrated into workflows, how reports are interpreted and acted upon, and what challenges were encountered. We find that SCA tools are most often integrated into build pipelines and that users report that information in SCA alerts is too generic and lack context, specifically context on infrastructure, network configurations, reachability, and exploitability. Based on our findings we conclude that context matters throughout the SCA process, including for evaluating impact, when to trigger SCA scan runners, and how to integrate and communicate tool findings."
  },
  {
    "id": 3687,
    "year": 2025,
    "title": "Expert Insights into Advanced Persistent Threats: Analysis, Attribution, and Challenges",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/saha",
    "abstract": "Advanced Persistent Threats (APTs) are sophisticated and targeted threats that demand significant effort from analysts for detection and attribution. Researchers have developed various techniques to support these efforts. However, security practitioners' perceptions and challenges in analyzing APT-level threats are not yet well understood. To address this gap, we conducted semi-structured interviews with 15 security practitioners across diverse roles and expertise. From the interview responses, we identify a three-layer approach to APT attribution, each having its own goals and challenges. We find that practitioners typically prioritize understanding the adversary's tactics, techniques, procedures (TTPs), and motivations over identifying the specific entity behind an attack. We also find challenges in existing tools and processes mostly stemming from their inability to handle diverse and complex data and issues with both internal and external collaboration. Based on these findings, we provide four recommendations for improving attribution approaches and discuss how these improvements can address the identified challenges."
  },
  {
    "id": 3688,
    "year": 2025,
    "title": "How Researchers De-Identify Data in Practice",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/guo-wentao",
    "abstract": "Human-subjects researchers are increasingly expected to de-identify and publish data about research participants. However, de-identification is difficult, lacking objective solutions for how to balance privacy and utility, and requiring significant time and expertise. To understand researchers' approaches, we interviewed 18 practitioners who have de-identified data for publication and 6 curators who review data submissions for repositories and funding organizations. We find that researchers account for the kinds of risks described by k-anonymity, but they address them through manual and social processes and not through systematic assessments of risk across a dataset. This allows for nuance but may leave published data vulnerable to re-identification. We explore why researchers take this approach and highlight three main barriers to more rigorous de-identification: threats seem unrealistic, stronger standards are not incentivized or supported, and tools do not meet researchers' needs. We conclude with takeaways for repositories, funding agencies, and privacy experts."
  },
  {
    "id": 3689,
    "year": 2025,
    "title": "A limited technical background is sufficient for attack-defense tree acceptability",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/schiele",
    "abstract": "Attack-defense trees (ADTs) are a prominent graphical threat modeling method that is highly recommended for analyzing and communicating security-related information. Despite this, existing empirical studies of attack trees have established their acceptability only for users with highly technical (computer science) backgrounds while raising questions about their suitability for threat modeling stakeholders with a limited technical background. Our research addresses this gap by investigating the impact of the users' technical background on ADT acceptability in an empirical study.\nOur Method Evaluation Model-based study consisted of n=102 participants (53 with a strong computer science background and 49 with a limited computer science background) who were asked to complete a series of ADT-related tasks. By analyzing their responses and comparing the results, we reveal that a very limited technical background is sufficient for ADT acceptability. This finding underscores attack trees' viability as a threat modeling method."
  },
  {
    "id": 3690,
    "year": 2025,
    "title": "\"It's not my responsibility to write them\": An Empirical Study of Software Product Managers and Security Requirements",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/naji",
    "abstract": "Product managers play a key role in defining and prior- itizing requirements overall, yet little is known about how they approach security requirements (SRs). To address this gap, we conducted a study with 50 participants in product management roles. Our 60-minute online study consisted of a requirement-writing task, followed by a questionnaire. Our analysis shows that, while security is not the top priority for our participants, only 10% did not include any SRs, and only 4% did not identify any security risks in their tasks. Most par- ticipants viewed SRs as a shared responsibility that should be discharged in collaboration with other roles - security experts, architects, and development teams - but without a clear as- signment or process. There is an assumption that security will be taken care of, somehow, in the process, with 54% believ- ing that security will be addressed, even when not explicitly stated in the requirements. To mitigate the concern of \"diffu- sion of responsibility\" for security, we identified a number of recommendations to involve stakeholders to address security throughout the development process."
  },
  {
    "id": 3691,
    "year": 2025,
    "title": "Patching Up: Stakeholder Experiences of Security Updates for Connected Medical Devices",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/kustosch-patching",
    "abstract": "Medical devices become increasingly connected and thus require security measures to ensure patient safety and data protection. However, such connected medical devices are often reported to lack basic security and to run on unpatched and outdated software. Thus, there is an increasing push to deliver security patches faster and more regularly to devices in the field. In this work, we empirically study current practices of patching connected medical devices by conducting 23 semi-structured interviews with participants from nine healthcare delivery organizations (HDOs) and three medical device manufacturers, also capturing data on actual updating practices for 25 specific medical devices. We find that delivering software updates to medical devices is an laborious and costly process for HDOs and manufacturers, as operational demands for medical use and an increasing need for infrastructure management put significant strain on involved stakeholders, thus rendering it questionable if conventional security patching will actually work in the healthcare sector without overwhelming it operationally and financially."
  },
  {
    "id": 3692,
    "year": 2025,
    "title": "Digital Product Safety: Rejecting Software as Magic",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/levasseur",
    "abstract": "The digital age is well underway, yet many still behave as if we're dealing with something—technology—that is utterly novel and opaque. It is neither of those things. Software and software-driven technologies are merely new kinds of products, digital products. What makes digital products different and more complicated? Must we view the risks of digital products in fragments like security and privacy? What happens if we view technology from the holistic lens of digital products and, therefore, digital product safety? How similar is the arc of digital product safety when compared to other new product categories in history, like cigarettes, alcohol, and automobiles and what can we learn from the past?"
  },
  {
    "id": 3693,
    "year": 2025,
    "title": "PRSA: Prompt Stealing Attacks against Real-World Prompt Services",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/yang-yong",
    "abstract": "Recently, large language models (LLMs) have garnered widespread attention for their exceptional capabilities. Prompts are central to the functionality and performance of LLMs, making them highly valuable assets. The increasing reliance on high-quality prompts has driven significant growth in prompt services. However, this growth also expands the potential for prompt leakage, increasing the risk that attackers could replicate original functionalities, create competing products, and severely infringe on developers' intellectual property. Despite these risks, prompt leakage in real-world prompt services remains underexplored.\nIn this paper, we present PRSA, a practical attack framework designed for prompt stealing. PRSA infers the detailed intent of prompts through very limited input-output analysis and can successfully generate stolen prompts that replicate the original functionality. Extensive evaluations demonstrate PRSA's effectiveness across two main types of real-world prompt services. Specifically, compared to previous works, it improves the attack success rate from 17.8% to 46.1% in prompt marketplaces (with attack costs only 1.3%--12.3% of the original prompt price) and from 39% to 52% in LLM application stores, respectively. Notably, in the attack on \"Math\", one of the most popular educational applications in OpenAI's GPT Store with over 1 million conversations, PRSA uncovered a hidden Easter egg that had not been revealed previously. Besides, our analysis reveals that higher mutual information between a prompt and its output correlates with an increased risk of leakage. This insight guides the design and evaluation of two potential defenses against the security threats posed by PRSA. We have reported these findings to the prompt service vendors, including PromptBase and OpenAI, and actively collaborate with them to implement defensive measures."
  },
  {
    "id": 3694,
    "year": 2025,
    "title": "Cross-Modal Prompt Inversion: Unifying Threats to Text and Image Generative AI Models",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/ye-inversion",
    "abstract": "Generative models, including both text-to-text and text-to-image modalities, have underscored the significance of 'prompt engineering', a technique critical for enhancing the quality of model outputs. Crafting high-quality prompts is not only time-intensive but also economically valuable, making them prime targets for manipulation. Recent research has revealed that these prompts can be stolen through a technique known as prompt inversion, which reconstructs prompts merely by analyzing the outputs of models. However, existing studies are typically confined to either text-to-text or text-to-image models and are not cross-applicable, thus limiting their real-world utility. This gap raises a crucial question: Is there a unified approach capable of addressing both model types? In this paper, we present the first comprehensive study on a unified prompt inversion approach that targets both text and image models. Our approach involves two model-agnostic phases: (1) training an inversion model to generate initial prompt approximations from model outputs, and (2) using reinforcement learning to fine-tune the inversion model for enhanced accuracy. We further extend our investigation to the text-to-video modality to demonstrate the broad generalizability of our approach. Experimental results highlight our approach's superior performance in comparison to existing state-of-the-art methods, which are typically optimized for a single model type. The source code is available at: https://zenodo.org/records/15603408."
  },
  {
    "id": 3695,
    "year": 2025,
    "title": "Prompt Obfuscation for Large Language Models",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/pape",
    "abstract": "System prompts that include detailed instructions to describe the task performed by the underlying LLM can easily transform foundation models into tools and services with minimal overhead. They are often considered intellectual property, similar to the code of a software product, because of their crucial impact on the utility. However, extracting system prompts is easily possible. As of today, there is no effective countermeasure to prevent the stealing of system prompts, and all safeguarding efforts could be evaded.\nIn this work, we propose an alternative to conventional system prompts. We introduce prompt obfuscation to prevent the extraction of the system prompt with little overhead. The core idea is to find a representation of the original system prompt that leads to the same functionality, while the obfuscated system prompt does not contain any information that allows conclusions to be drawn about the original system prompt. We evaluate our approach by comparing our obfuscated prompt output with the output of the original prompt, using eight distinct metrics to measure the lexical, character-level, and semantic similarity. We show that the obfuscated version is constantly on par with the original one. We further perform three different deobfuscation attacks with varying attacker knowledge—covering both black-box and white-box conditions—and show that in realistic attack scenarios an attacker is unable to extract meaningful information. Overall, we demonstrate that prompt obfuscation is an effective mechanism to safeguard the intellectual property of a system prompt while maintaining the same utility as the original prompt."
  },
  {
    "id": 3696,
    "year": 2025,
    "title": "TwinBreak: Jailbreaking LLM Security Alignments based on Twin Prompts",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/krauss",
    "abstract": "Machine learning is advancing rapidly, with applications bringing notable benefits, such as improvements in translation and code generation. Models like ChatGPT, powered by Large Language Models (LLMs), are increasingly integrated into daily life. However, alongside these benefits, LLMs also introduce social risks. Malicious users can exploit LLMs by submitting harmful prompts, such as requesting instructions for illegal activities. To mitigate this, models often include a security mechanism that automatically rejects such harmful prompts. However, they can be bypassed through LLM jailbreaks. Current jailbreaks often require significant manual effort, high computational costs, or result in excessive model modifications that may degrade regular utility.\nWe introduce TwinBreak, an innovative safety alignment removal method. Building on the idea that the safety mechanism operates like an embedded backdoor, TwinBreak identifies and prunes parameters responsible for this functionality. By focusing on the most relevant model layers, TwinBreak performs fine-grained analysis of parameters essential to model utility and safety. TwinBreak is the first method to analyze intermediate outputs from prompts with high structural and content similarity to isolate safety parameters. We present the TwinPrompt dataset containing 100 such twin prompts. Experiments confirm TwinBreak's effectiveness, achieving 89% to 98% success rates with minimal computational requirements across 16 LLMs from five vendors."
  },
  {
    "id": 3697,
    "year": 2025,
    "title": "Exploiting Task-Level Vulnerabilities: An Automatic Jailbreak Attack and Defense Benchmarking for LLMs",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/zhang-lan",
    "abstract": "Recent advancements in large language models (LLMs) have notably improved their proficiency in executing complex tasks. However, these advancements are accompanied by an increased risk of generating toxic content as well as leaking private information. Jailbreak is an emerging trend to amplify this vulnerability by carefully modifying prompts such asDAN\" to circumvent the LLMs' defense. Notwithstanding, existing jailbreaks typically focus on specific prompts or tokens, rendering them susceptible to countermeasures such as realignments. In contrast to these prompt-level or token-level jailbreaks, we present a novel task-level jailbreak based on knowledge decomposition, which does not rely on any specific prompts or tokens. Our attack demonstrates significantly enhanced resistance against realignments compared to previous jailbreak techniques. Furthermore, our attack not only achieves about 10% higher success rates than SOTA attacks but also generates responses that are richer in detail and information. This is attributed to aggregation of responses from multiple well-designed queries rather than relying on only a singular query as in previous attacks, thus signifying an elevated risk of threat. On the other hand, knowledge decomposition provide us a method to generate plenty tasks with varying risk levels, thereby establishing a novel benchmark to assess the defensive effectiveness of LLMs."
  },
  {
    "id": 3698,
    "year": 2025,
    "title": "StruQ: Defending Against Prompt Injection with Structured Queries",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/chen-sizhe",
    "abstract": "Recent advances in Large Language Models (LLMs) enable exciting LLM-integrated applications, which perform text-based tasks by utilizing their advanced language understanding capabilities. However, as LLMs have improved, so have the attacks against them. Prompt injection attacks are an important threat: they trick the model into deviating from the original application's instructions and instead follow user directives. These attacks rely on the LLM's ability to follow instructions and inability to separate prompts and user data.\nWe introduce structured queries, a general approach to tackle this problem. Structured queries separate prompts and data into two channels. We implement a system that supports structured queries. This system is made of (1) a secure front-end that formats a prompt and user data into a special format, and (2) a specially trained LLM that can produce high-quality outputs from these inputs. The LLM is trained using a novel fine-tuning strategy: we convert a base (non-instruction-tuned) LLM to a structured instruction-tuned model that will only follow instructions in the prompt portion of a query. To do so, we augment standard instruction tuning datasets with examples that also include instructions in the data portion of the query, and fine-tune the model to ignore these. Our system significantly improves resistance to prompt injection attacks, with little or no impact on utility. Our code is released at https://github.com/Sizhe-Chen/StruQ."
  },
  {
    "id": 3699,
    "year": 2025,
    "title": "PAPILLON: Efficient and Stealthy Fuzz Testing-Powered Jailbreaks for LLMs",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/gong-xueluan",
    "abstract": "Large Language Models (LLMs) have excelled in various tasks but are still vulnerable to jailbreaking attacks, where attackers create jailbreak prompts to mislead the model to produce harmful or offensive content. Current jailbreak methods either rely heavily on manually crafted templates, which pose challenges in scalability and adaptability, or struggle to generate semantically coherent prompts, making them easy to detect. Additionally, most existing approaches involve lengthy prompts, leading to higher query costs. In this paper, to remedy these challenges, we introduce a novel jailbreaking attack framework called PAPILLON, which is an automated, blackbox jailbreaking attack framework that adapts the black-box fuzz testing approach with a series of customized designs. Instead of relying on manually crafted templates, PAPILLON starts with an empty seed pool, removing the need to search for any related jailbreaking templates. We also develop three novel question-dependent mutation strategies using an LLM helper to generate prompts that maintain semantic coherence while significantly reducing their length. Additionally, we implement a two-level judge module to accurately detect genuine successful jailbreaks.\nWe evaluated PAPILLON on 7 representative LLMs and compared it with 5 state-of-the-art jailbreaking attack strategies. For proprietary LLM APIs, such as GPT-3.5 turbo, GPT4, and Gemini-Pro, PAPILLON achieves attack success rates of over 90%, 80%, and 74%, respectively, exceeding existing baselines by more than 60%. Additionally, PAPILLON can maintain high semantic coherence while significantly reducing the length of jailbreak prompts. When targeting GPT-4, PAPILLON can achieve over 78% attack success rate even with 100 tokens. Moreover, PAPILLON demonstrates transferability and is robust to state-of-the-art defenses. We will open-source our codes upon publication."
  },
  {
    "id": 3700,
    "year": 2025,
    "title": "Great, Now Write an Article About That: The Crescendo Multi-Turn LLM Jailbreak Attack",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/russinovich",
    "abstract": "Large Language Models (LLMs) have risen significantly in popularity and are increasingly being adopted across multiple applications. These LLMs are heavily aligned to resist engaging in illegal or unethical topics as a means to avoid contributing to responsible AI harms. However, a recent line of attacks, known as \"jailbreaks'', seek to overcome this alignment. Intuitively, jailbreak attacks aim to narrow the gap between what the model can do and what it is willing to do. In this paper, we introduce a novel jailbreak attack called Crescendo. Unlike existing jailbreak methods, Crescendo is a simple multi-turn jailbreak that interacts with the model in a seemingly benign manner. It begins with a general prompt or question about the task at hand and then gradually escalates the dialogue by referencing the model's replies progressively leading to a successful jailbreak. We evaluate Crescendo on various public systems, including ChatGPT, Gemini Pro, Gemini-Ultra, LlaMA-2 70b and LlaMA-3 70b Chat, and Anthropic Chat. Our results demonstrate the strong efficacy of Crescendo, with it achieving high attack success rates across all evaluated models and tasks. Furthermore, we present Crescendomation, a tool that automates the Crescendo attack and demonstrate its efficacy against state-of-the-art models through our evaluations. Crescendomation surpasses other state-of-the-art jailbreaking techniques on the AdvBench subset dataset, achieving 29-61% higher performance on GPT-4 and 49-71% on Gemini-Pro. Finally, we also demonstrate Crescendo's ability to jailbreak multimodal models."
  },
  {
    "id": 3701,
    "year": 2025,
    "title": "SelfDefend: LLMs Can Defend Themselves against Jailbreaking in a Practical Manner",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/wang-xunguang",
    "abstract": "Jailbreaking is an emerging adversarial attack that bypasses the safety alignment deployed in off-the-shelf large language models (LLMs) and has evolved into multiple categories: human-based, optimization-based, generation-based, and the recent indirect and multilingual jailbreaks. However, delivering a practical jailbreak defense is challenging because it needs to not only handle all the above jailbreak attacks but also incur negligible delays to user prompts, as well as be compatible with both open-source and closed-source LLMs.\nInspired by how the traditional security concept of shadow stacks defends against memory overflow attacks, this paper introduces a generic LLM jailbreak defense framework called SelfDefend, which establishes a shadow LLM as a defense instance (in detection state) to concurrently protect the target LLM instance (in normal answering state) in the normal stack and collaborate with it for checkpoint-based access control. The effectiveness of SelfDefend builds upon our observation that existing LLMs can identify harmful prompts or intentions in user queries, which we empirically validate using mainstream GPT-3.5/4 models against major jailbreak attacks. To further improve the defense's robustness and minimize costs, we employ a data distillation approach to tune dedicated open-source defense models. When deployed to protect GPT-3.5/4, Claude, Llama-2-7b/13b, and Mistral, these models outperform seven state-of-the-art defenses and match the performance of GPT-4-based SelfDefend, with significantly lower extra delays. Further experiments show that the tuned models are robust to adaptive jailbreaks and prompt injections."
  },
  {
    "id": 3702,
    "year": 2025,
    "title": "SoK: So, You Think You Know All About Secure Randomized Caches?",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/bhatla",
    "abstract": "Over the past decade, numerous side-channel attacks on shared resources, such as the Last-Level Cache (LLC), have exposed security risks in the form of flush-based, conflict-based, and occupancy-based attacks, driving the development of secure cache designs. To defend against conflict-based attacks, which is one of the most effective classes of side-channel attacks, many modern designs randomize LLC set indexing to hinder eviction set construction. Various randomized cache designs have been proposed recently, offering distinct security guarantees. While these designs incorporate several microarchitectural modifications (we call them security knobs) over the conventional set-associative cache to ensure security, the individual impact of these microarchitectural modifications has never been evaluated. This leaves a gap in the understanding of randomized LLCs—the design space has not been explored completely and systematically. \nIn this SoK, we identify and systematically analyze the design knobs employed in state-of-the-art secure randomized cache designs that mitigate conflict-based attacks. Using conventional set-associative caches as our baseline, we study five key knobs: skewing, extra invalid tags, high associativity, replacement policy, and remapping. We also evaluate their impact on occupancy-based attacks. Our findings show that no single knob provides a comprehensive security guarantee. Instead, only specific combinations of knobs yield effective protection, while others offer little to no security benefit."
  },
  {
    "id": 3703,
    "year": 2025,
    "title": "TEEcorrelate: An Information-Preserving Defense against Performance-Counter Attacks on TEEs",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/weissteiner",
    "abstract": "Trusted-execution environments (TEEs) offer confidentiality in shared environments. While Intel restricts performance counter access, limiting load-balancing and anomaly detection on TEEs, AMD exposes performance counters to the host, leaving the TEE vulnerable to side-channel leakage.\nIn this paper, we propose TEEcorrelate, a lightweight information-preserving defense against performance-counter attacks on TEEs. TEEcorrelate reconciles monitoring capabilities of the host and confidentiality requirements of the TEE, by statistically decorrelating performance counters. TEEcorrelate combines two components, temporal decorrelation using counter aggregation windows, and value decorrelation using fuzzy performance counter increases. With default parameters, TEEcorrelate guarantees that the host can read performance counters hundreds of times per second, while the read value never deviates by more than 1024 from the actual value. Hence, the host can still use them for load-balancing, accounting, and detection of unusual or malicious activity. In state-of-the-art attacks on MbedTLS RSA 4096, a TOTP implementation, and the post-quantum HQC key-encapsulation mechanism, attack runtimes increase from 0.58 - 429 seconds to 1 -775.6 days, even for a powerful, fully-informed attacker. We estimate that TEEcorrelate on AMD SEV-SNP has a negligible performance impact of 0.03 % for most context switches, and overall less than 0.09 %. Hence, TEEcorrelate is an effective low cost mitigation for all TEEs."
  },
  {
    "id": 3704,
    "year": 2025,
    "title": "Systematic Evaluation of Randomized Cache Designs against Cache Occupancy",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/chakraborty",
    "abstract": "Randomizing the address-to-set mapping and partitioning of the cache has been shown to be an effective mechanism in designing secured caches. Several designs have been proposed on a variety of rationales: (1) randomized design, (2) randomized-and-partitioned design, and (3) psuedo-fully associative design. This work fills in a crucial gap in current literature on randomized caches: currently most randomized cache designs defend only contention-based attacks, and leave out considerations of cache occupancy. We perform a systematic evaluation of 5 randomized cache designs- CEASER, CEASER-S, MIRAGE, ScatterCache, and SassCache against cache occupancy wrt. both performance as well as security.\n\nWith respect to performance, we first establish that benchmarking strategies used by contemporary designs are unsuitable for a fair evaluation (because of differing cache configurations, choice of benchmarking suites, additional implementation-specific assumptions). We thus propose a uniform benchmarking strategy, which allows us to perform a fair and comparative analysis across all designs under various replacement policies. Likewise, with respect to security against cache occupancy attacks, we evaluate the cache designs against various threat assumptions: (1) covert channels, (2) process fingerprinting, and (3) AES key recovery (to the best of our knowledge, this work is the first to demonstrate full AES key recovery on a randomized cache design using cache occupancy attack). Our results establish the need to also consider cache occupancy side-channel in randomized cache design considerations."
  },
  {
    "id": 3705,
    "year": 2025,
    "title": "Exploiting Inaccurate Branch History in Side-Channel Attacks",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/zhu-yuhui",
    "abstract": "Modern out-of-order CPUs heavily rely on speculative execution for performance optimization, with branch prediction serving as a cornerstone to minimize stalls and maximize efficiency. Whenever shared branch prediction resources lack proper isolation and sanitization methods, they may originate security vulnerabilities that expose sensitive data across different software contexts.\nThis paper examines the fundamental components of modern Branch Prediction Units (BPUs) and investigates how resource sharing and contention affect two widely implemented but underdocumented features: Bias-Free Branch Prediction and Branch History Speculation. Our analysis demonstrates that these BPU features, while designed to enhance speculative execution efficiency through more accurate branch histories, can also introduce significant security risks. We show that these features can inadvertently modify the Branch History Buffer (BHB) update behavior and create new primitives that trigger malicious mis-speculations.\nThis discovery exposes previously unknown cross-privilege attack surfaces for Branch History Injection (BHI). Based on these findings, we present three novel attack primitives: two Spectre attacks, namely Spectre-BSE and Spectre-BHS, and a cross-privilege control flow side-channel attack called BiasScope. Our research identifies corresponding patterns of vulnerable control flows and demonstrates exploitation on multiple processors. Finally, Chimera is presented: an attack demonstrator based on eBPF for a variant of Spectre-BHS that is capable of leaking kernel memory contents at 24,628 bit/s."
  },
  {
    "id": 3706,
    "year": 2025,
    "title": "Phantom Trails: Practical Pre-Silicon Discovery of Transient Data Leaks",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/de-faveri-tron",
    "abstract": "Transient execution vulnerabilities have affected CPUs for the better part of the decade, yet, we are still missing methods to efficiently uncover them at the design stage. Existing approaches try to find programs that leak explicitly defined secrets, sometimes including the transmission over a sidechannel, which severely restricts the space of programs that can trigger detection. As a result, current fuzzers are forced to constrain the search space using templates of known vulnerabilities, which risks overfitting. What is missing is a general detection mechanism that (1) makes it easy for the fuzzer to trigger a violation and (2) catches vulnerabilities at their root cause — similarly to sanitizers in software. In this paper, we propose Phantom Trails, an efficient yet generic method for discovering transient execution vulnerabilities. Phantom Trails relies on a fuzzer-friendly detection model that can be applied without the need for templating. Ourndetector builds on two key design choices. First, it concentrates on finding microarchitectural data leaks independently of the covert channel, thereby focusing on the core of the attack. Second, it automatically infers all secret locations from the architectural behavior of a program, making it easier for the detector to find leaks. We evaluate Phantom Trails by fuzzing the BOOM RISC-V CPU, where it finds all known speculative vulnerabilities in 24-hours, starting from an empty seed and without pre-defined templates, as well as a new Spectre variant specific to BOOM — Spectre-LoopPredictor."
  },
  {
    "id": 3707,
    "year": 2025,
    "title": "Place Protections at the Right Place: Targeted Hardening for Cryptographic Code against Spectre v1",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/zhu-yiming",
    "abstract": "Spectre v1 attacks pose a substantial threat to security-critical software, particularly cryptographic implementations. Existing software mitigations, however, often introduce excessive overhead by indiscriminately hardening instructions without assessing their vulnerability. We propose an analysis framework that employs a novel fixpoint algorithm to detect Spectre vulnerabilities and apply targeted hardening. The fixpoint algorithm accounts for program behavior changes induced by stepwise hardening, enabling precise, sound and efficient vulnerability detection. This framework also  provides flexibility for diverse hardening strategies and attacker models, enabling customized targeted hardening. We instantiate the framework as LightSLH, which hardens program with provable security.\nWe evaluate LightSLH on cryptographic algorithms from OpenSSL, Libsodium, and NaCL.  Across all experimental cases, LightSLH provides the lowest overhead among current provable protection strategies, including 0% overhead in 58.3% cases. Notably, the analysis of LightSLH reveals two previously unknown security issues: (1) The compiler can introduce risks overlooked by LLSCT, a hardening method proven secure at the LLVM IR level. We successfully construct a side channel by exploiting compiler-inserted stack loads, confirming this risk. (2) Memory access patterns generated by the scatter-gather algorithm still depend on secrets, even for observers with cache line granularity. These findings and results highlight the importance of applying accurate protections to specific instructions."
  },
  {
    "id": 3708,
    "year": 2025,
    "title": "Encarsia: Evaluating CPU Fuzzers via Automatic Bug Injection",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/bolcskei",
    "abstract": "Hardware fuzzing has recently gained momentum with many discovered bugs in open-source RISC-V CPU designs. Comparing the effectiveness of different hardware fuzzers, however, remains a challenge: each fuzzer optimizes for a different metric and is demonstrated on different CPU designs. Furthermore, the number of newly-discovered bugs is not an appropriate metric since finding new bugs becomes increasingly more difficult as designs mature. We argue that a corpus of automatically injectable bugs will help compare hardware fuzzers to better understand their strengths and weaknesses. Through a large-scale study of 177 software-observable bugs in open-source RISC-V CPUs, we discover that CPU bugs can be modelled by manipulating conditional statements or signal drivers. Based on this observation, we design Encarsia, a framework that automatically transforms the intermediate representation of a given CPU design to inject bugs that are equivalent to incorrect conditions or assignments at the HDL level. To ensure that an injected bug has an observable architectural effect, we leverage formal methods to prove the existence of an architectural deviation due to the bug-specific transformation. We evaluate Encarsia by injecting bugs into three open-source RISC-V CPUs, fuzzing these CPUs with recently-proposed CPU fuzzers, and comparing their bug-finding performance. Our experiments reveal key insights into the limitations of existing hardware fuzzers, including their inability to cover large sections of the designs under test, ineffective coverage metrics, and bug detection mechanisms that often miss bugs or produce false positives, highlighting the urgent need to reassess current approaches."
  },
  {
    "id": 3709,
    "year": 2025,
    "title": "FLOP: Breaking the Apple M3 CPU via False Load Output Predictions",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/kim-jason",
    "abstract": "To bridge the ever-increasing gap between the fast execution speed of modern processors and the long latency of memory accesses, CPU vendors continue to introduce newer and more advanced optimizations. While these optimizations improve performance, research has repeatedly demonstrated that they may also have an adverse impact on security.\nIn this work, we identify that recent Apple M- and A-series processors implement a load value predictor (LVP), an optimization that predicts the contents of memory that the processor loads before the contents are actually available. This allows processors to alleviate slowdowns from Read-After-Write dependencies, as instructions can now be executed in parallel rather than sequentially. \nTo evaluate the security impact of Apple's LVP implementation, we first investigate the implementation, identifying the conditions for prediction. We then show that although the LVP cannot directly predict 64-bit values (e.g., pointers), prediction of smaller-size values can be leveraged to achieve arbitrary memory access. Finally, we demonstrate end-to-end attack exploit chains that build on the LVP to obtain a 64-bit read primitive within the Safari and Chrome browsers."
  },
  {
    "id": 3710,
    "year": 2025,
    "title": "Branch Privilege Injection: Compromising Spectre v2 Hardware Mitigations by Exploiting Branch Predictor Race Conditions",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/ruegge",
    "abstract": "Modern branch predictors prevent Spectre v2 attacks by associating predictions with the privilege domain they should be restricted to, or by providing barriers for invalidating predictions when switching contexts. Such branch predictors receive branch resolution and privilege domain feedback asynchronously, but it is unclear whether they always consider the correct order of events. In this paper, we introduce Branch Predictor Race Conditions (BPRC), a class of vulnerabilities where asynchronous branch predictor operations violate hardware-enforced privilege and context separation mechanisms in all recent Intel CPUs. Our analysis reveals three variants, breaching the security boundaries between user and kernel, guest and hypervisor, and across indirect branch predictor barriers. Leveraging BPRC, we introduce Branch Privilege Injection (BPI), a new Spectre v2 primitive that injects arbitrary branch predictions tagged with kernel privilege from user mode. Our end-to-end BPI exploit leaks arbitrary kernel memory from up-to-date Linux systems across six generations of Intel CPUs, at 5.6KiB/s on Intel Raptor Cove."
  },
  {
    "id": 3711,
    "year": 2025,
    "title": "GraphAce: Secure Two-Party Graph Analysis Achieving Communication Efficiency",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/yu-jiping",
    "abstract": "Graph analysis has achieved success in challenging tasks such as importance measures, fraud detection, and anti-money laundering. For a deep understanding of various complex systems in real life, a whole graph may involve data and connections from multiple sources. Secure multi-party computation is suitable for this scenario, which allows untrusted parties to compute collectively without revealing their individual data. However, a significant challenge is the high communication overhead, especially during intricate computations of large-scale input, and existing secure graph analysis frameworks incur a lower bound of Omega(|V|+|E|) communication per iteration, where V and E denote vertices and edges, respectively.\nThis paper proposes GraphAce, an efficient secure two-party graph analysis framework, which adopts a distinct technical roadmap from existing solutions. We identify and address the security challenges when utilizing local graph data of parties, with the mixed primitives system of homomorphic encryption and secret sharing, and a novel ChaosTable data structure that protects privacy during cross-party computation. Consequently, GraphAce eliminates any network traffic related to the edges. For each iteration, it achieves low complexities of Theta(|V|) communication, breaking the Omega(|V|+|E|) lower bound of previous secure solutions, and Theta(|V|+|E|) computation, which is the same as insecure methods.\nEvaluations show that GraphAce exceeds previous methods by up to tens of thousands of times in speed and saves up to 99.99% communication, depending on the application and the network. This is the first secure two-party graph analysis framework capable of processing over 1 million vertices and 132 million edges in a reasonable time, which is 128x larger than previous reports, to the best of our knowledge."
  },
  {
    "id": 3712,
    "year": 2025,
    "title": "Breaking the Layer Barrier: Remodeling Private Transformer Inference with Hybrid CKKS and MPC",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/xu-tianshi",
    "abstract": "This paper presents an efficient framework for private Transformer inference that combines Homomorphic Encryption (HE) and Secure Multi-party Computation (MPC) to protect data privacy. Existing methods often leverage HE for linear layers (e.g., matrix multiplications) and MPC for non-linear layers (e.g., Softmax activation functions), but the conversion between HE and MPC introduces significant communication costs. The proposed framework, dubbed BLB, overcomes this by breaking down layers into fine-grained operators and further fusing adjacent linear operators, reducing the need for HE/MPC conversions. To manage the increased ciphertext bit width from the fused linear operators, BLB proposes the first secure conversion protocol between CKKS and MPC and enables CKKS-based computation of the fused operators. Additionally, BLB proposes an efficient matrix multiplication protocol for fused computation in Transformers. Extensive evaluations on BERT-base, BERT-large, and GPT2-base show that BLB achieves a 21x reduction in communication overhead compared to BOLT (S&P '24) and a 2x reduction compared to Bumblebee (NDSS '25), along with latency reductions of 13x and 1.8x, respectively, when leveraging GPU acceleration."
  },
  {
    "id": 3713,
    "year": 2025,
    "title": "HawkEye: Statically and Accurately Profiling the Communication Cost of Models in Multi-party Learning",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/ruan",
    "abstract": "Multi-party computation (MPC) based machine learning, referred to as multi-party learning (MPL), has become an important technology for utilizing data from multiple parties with privacy preservation. In recent years, in order to apply MPL in more practical scenarios, various MPC-friendly models have been proposedto reduce the extraordinary communication overhead of MPL. Within the optimization of MPC-friendly models, a critical element to tackle the challenge is profiling the communication cost of models. However, the current solutions mainly depend on manually establishing the profiles to identify communication bottlenecks of models, often involving burdensome human efforts in a monotonous procedure.\nIn this paper, we propose HawkEye, a static model communication cost profiling framework, which enables model designers to get the accurate communication cost of models in MPL frameworks without dynamically running the secure model training or inference processes on a specific MPL framework. Firstly, to profile the communication cost of models with complex structures, we propose a static communication cost profiling method based on a prefix structure that records the function calling chain during the static analysis. Secondly, HawkEye employs an automatic differentiation library to assist model designers in profiling the communication cost of models in PyTorch. Finally, we compare the static profiling results of HawkEye against the profiling results obtained through dynamically running secure model training and inference processes on five popular MPL frameworks, CryptFlow2, CrypTen, Delphi, Cheetah, and SecretFlow-SEMI2K. The experimental results show that HawkEye can accurately profile the model communication cost without dynamic profiling."
  },
  {
    "id": 3714,
    "year": 2025,
    "title": "Privacy Audit as Bits Transmission: (Im)possibilities for Audit by One Run",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/xiang-zihang",
    "abstract": "Auditing algorithms' privacy typically involves simulating a game-based protocol that determines which of two adjacent datasets was the original input. Traditional approaches require thousands of such simulations, leading to significant computational overhead. Recent methods propose single-run auditing of the target algorithm to address this, substantially reducing computational cost. However, these methods' general applicability and tightness in producing empirical privacy guarantees remain uncertain.\nThis work studies such problems in detail. Our contributions are twofold: First, we introduce a unifying framework for privacy audits based on information-theoretic principles, modeling the audit as a bit transmission problem in a noisy channel. This formulation allows us to derive fundamental limits and develop an audit approach that yields tight privacy lower bounds for various DP protocols. Second, leveraging this framework, we demystify the method of privacy audit by one run, identifying the conditions under which single-run audits are feasible or infeasible. Our analysis provides general guidelines for conducting privacy audits and offers deeper insights into the privacy audit.\nFinally, through experiments, we demonstrate that our approach produces tighter privacy lower bounds on common differentially private mechanisms while requiring significantly fewer observations. We also provide a case study illustrating that our method successfully detects privacy violations in flawed implementations of private algorithms."
  },
  {
    "id": 3715,
    "year": 2025,
    "title": "General-Purpose f-DP Estimation and Auditing in a Black-Box Setting",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/askin",
    "abstract": "In this paper we propose new methods to statistically assess f-Differential Privacy (f-DP), a recent refinement of differential privacy (DP) that remedies certain weaknesses of standard DP (including tightness under algorithmic composition). A challenge when deploying differentially private mechanisms is that DP is hard to validate, especially in the black-box setting. This has led to numerous empirical methods for auditing standard DP, while f-DP remains less explored. We introduce new black-box methods for f-DP that, unlike existing approaches for this privacy notion, do not require prior knowledge of the investigated algorithm. Our procedure yields a complete estimate of the f-DP trade-off curve, with theoretical guarantees of convergence. Additionally, we propose an efficient auditing method that empirically detects f-DP violations with statistical certainty, merging techniques from non-parametric estimation and optimal classification theory. Through experiments on a range of DP mechanisms, we demonstrate the effectiveness of our estimation and auditing procedures."
  },
  {
    "id": 3716,
    "year": 2025,
    "title": "FastLloyd: Federated, Accurate, Secure, and Tunable k-Means Clustering with Differential Privacy",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/diaa",
    "abstract": "We study the problem of privacy-preserving k-means clustering in the horizontally federated setting. Existing federated approaches using secure computation suffer from substantial overheads and do not offer output privacy. At the same time, differentially private (DP) k-means algorithms either assume a trusted central curator or significantly degrade utility by adding noise in the local DP model. Naively combining the secure and central DP solutions results in a protocol with impractical overhead. Instead, our work provides enhancements to both the DP and secure computation components, resulting in a design that is faster, more private, and more accurate than previous work. By utilizing the computational DP model, we design a lightweight, secure aggregation-based approach that achieves five orders of magnitude speed-up over state-of-the-art related work. Furthermore, we not only maintain the utility of the state-of-the-art in the central model of DP, but we improve the utility further by designing a new DP clustering mechanism."
  },
  {
    "id": 3717,
    "year": 2025,
    "title": "Addressing Sensitivity Distinction in Local Differential Privacy: A General Utility-Optimized Framework",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/he-xingyu",
    "abstract": "Local Differential Privacy (LDP) is widely employed to address privacy concerns in data collection. Nevertheless, the LDP model ignores the sensitivity distinction, as it regards all personal data equally sensitive, leading to excessive obfuscation and the loss of utility. Utility-optimized LDP (ULDP) aims to mitigate this issue. However, existing ULDP mechanisms address sensitivity distinction in only a limited subset of LDP mechanisms. To systematically address sensitivity distinction in the LDP model, we propose the General LDP-to-ULDP Transformation Framework. This framework can convert any LDP mechanism into its corresponding ULDP mechanism while preserving key properties such as order-optimality and unbiased estimation. Then, we present the pure ULDP framework, which generalizes a class of ULDP mechanisms with strong performance guarantees. We develop a universal aggregation and utility analysis method applicable to all pure ULDP mechanisms, facilitating the analysis, comparison, and optimization of different ULDP mechanisms. After that, we transform three widely-used LDP mechanisms into their ULDP counterparts (uSS, uUE and uLH). We theoretically demonstrate that our proposed mechanisms exceed existing ULDP mechanisms in data utility and communication costs. Specifically, our uSS, uUE and uLH match the minimax risk lower bound within the ULDP framework. We also identify the optimal mechanism for various usage scenarios. Finally, we conduct experiments on both real and synthetic datasets, showing that uUE and uLH achieve the lowest Mean Squared Error (MSE) when size of sensitive dataset is large, and uSS consistently achieves the lowest MSE."
  },
  {
    "id": 3718,
    "year": 2025,
    "title": "Further Study on Frequency Estimation under Local Differential Privacy",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/fang",
    "abstract": "Local Differential Privacy (LDP) protects user privacy while collecting user data without the need for a trusted data collector. Nowadays, LDP protocols have been adopted and deployed by several major technology companies. A basic building block of LDP protocols is the frequency protocol, which estimates the frequency of each value in a specified domain. Although several frequency protocols have been proposed, all these protocols make compromises among the performances of accuracy, computation cost, and communication cost. In this paper, we introduce a precise and convenient equation to evaluate the accuracy of frequency protocols. We use it to analyze the advantages and disadvantages of existing protocols quantitatively. Based on the analysis, we address the shortcomings of these protocols and propose a new protocol, Random Wheel Spinner (RWS), which achieves optimal accuracy with low computation and communication costs simultaneously. Extensive experiments on both synthetic and real-world datasets demonstrate the advantages of our proposed protocols."
  },
  {
    "id": 3719,
    "year": 2025,
    "title": "Beyond Statistical Estimation: Differentially Private Individual Computation via Shuffling",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/wang-shaowei",
    "abstract": "In data-driven applications, preserving user privacy while enabling valuable computations remains a critical challenge. Technologies like differential privacy have been pivotal in addressing these concerns. The shuffle model of DP requires no trusted curators and can achieve high utility by leveraging the privacy amplification effect yielded from shuffling. These benefits have led to significant interest in the shuffle model. However, the computation tasks in the shuffle model are limited to statistical estimation, making it inapplicable to real-world scenarios in which each user requires a personalized output. This paper introduces a novel paradigm termed Private Individual Computation (PIC), expanding the shuffle model to support a broader range of permutation-equivariant computations. PIC enables personalized outputs while preserving privacy, and enjoys privacy amplification through shuffling. We propose a concrete protocol that realizes PIC. By using one-time public keys, our protocol enables users to receive their outputs without compromising anonymity, which is essential for privacy amplification. Additionally, we present an optimal randomizer, the Minkowski Response, designed for the PIC model to enhance utility. We formally prove the security and privacy properties of the PIC protocol. Theoretical analysis and empirical evaluations demonstrate PIC's capability in handling non-statistical computation tasks, and the efficacy of PIC and the Minkowski randomizer in achieving superior utility compared to existing solutions."
  },
  {
    "id": 3720,
    "year": 2025,
    "title": "Stack Overflow Meets Replication: Security Research Amid Evolving Code Snippets",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/jallow",
    "abstract": "We study the impact of Stack Overflow code evolution on the stability of prior research findings derived from Stack Overflow data and provide recommendations for future studies. We systematically reviewed papers published between 2005–2023 to identify key aspects of Stack Overflow that can affect study results, such as the language or context of code snippets. Our analysis reveals that certain aspects are non-stationary over time, which could lead to different conclusions if experiments are repeated at different times. We replicated six studies using a more recent dataset to demonstrate this risk. Our findings show that four papers produced significantly different results than the original findings, preventing the same conclusions from being drawn with a newer dataset version. Consequently, we recommend treating Stack Overflow as a time series data source to provide context for interpreting cross-sectional research conclusions."
  },
  {
    "id": 3721,
    "year": 2025,
    "title": "\"I'm regretting that I hit run\": In-situ Assessment of Potential Malware",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/lit",
    "abstract": "We conduct the first ever two-session controlled lab study (n = 36) where participants are prompted to install real benign and malicious software on a standard Windows laptop. In the first session, we establish users' strategies by asking them to assess the threat from software without any instructions. In the second session, we repeat the experiment after introducing an \"enhanced task manager\" application with system process information like CPU usage, files accessed, and network destination country to understand their decision making with the knowledge of some attack indicators. We measure the time and accuracy to classify software as benign or malicious and participant comments using a \"think-aloud\" protocol. The comments form a dataset of 2,651 excerpts that are coded into four top-level categories of \"indicators\" with 25 sub-categories. We employ the indicators to provide a perspective into how end-users examine and analyze software in-situ. Our results show end-users are surprisingly accurate at classifying malware and become even better when provided with the attack indicators. Our analysis uncovers common misconceptions, shows reliance on indicators that are circumventable, and provides actionable insights for software and operating system providers to improve their interfaces or notifications."
  },
  {
    "id": 3722,
    "year": 2025,
    "title": "Beyond Exploit Scanning: A Functional Change-Driven Approach to Remote Software Version Identification",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/chen-jinsong",
    "abstract": "Traditional attacks on remote software often fail to be armed with targeted software version information, leading to conspicuous brute-force attacks. Existing version identification tools, relying on predefined strings or patterns as fingerprints, can often not sketch software versions with defensive measures such as obfuscation or authentication.\nThis paper presents a covert and accurate version identification method based on noticeably different functional changes introduced by version updates. Our tool minimizes server noticeable probing behaviors by distilling domain knowledge from documents and change logs, and carefully designing dynamic probing sequences. We implemented and evaluated our prototype framework on Elasticsearch, Redis, Dubbo, Joomla, and phpMyAdmin, focusing on their versions from the past decade. Our tool achieved 2.8 times identification rates higher than previous works, with 65.37% fewer packages sent. Additionally, we conducted a large-scale scan of real-time data from Shodan and FOFA collected over two months, successfully identifying version information for 240,020 remote software instances, with 156,256 unrecognized by either platform. Our result reveals that over 72.25% users are still deploying versions released at least one year ago, facing significant vulnerability threats."
  },
  {
    "id": 3723,
    "year": 2025,
    "title": "\"I'm trying to learn…and I'm shooting myself in the foot\": Beginners' Struggles When Solving Binary Exploitation Exercises",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/mattei",
    "abstract": "Vulnerability discovery is an essential security skill that is often daunting for beginners. Although there are various supportive organizations and ample online resources to learn from, beginners often struggle, become frustrated, and quit. We conducted semi-structured observational interviews with 37 vulnerability discovery beginners attempting to exploit 51 vulnerable programs. We capture the questions beginners have when trying to identify and exploit vulnerabilities, how they search for answers, and the challenges they face applying their searches' results. We performed a rigorous qualitative coding of our dataset of 3950 events characterizing participants' actions to identify several behaviors and obstacles faced, along with quantitative measures to determine their most frequent issues.\nWe found beginners struggle to understand how to exploit vulnerabilities, craft their solutions, and even complete common technical tasks. They were often unable to find relevant information online to overcome these struggles, as they lacked the relevant vocabulary to craft effective keyword searches. When they did find relevant web pages, they struggled to properly transfer information from the web to their challenges due to misunderstandings and missing context. Based on our results, we offer suggestions for vulnerability discovery educators and resource creators to produce higher-quality materials to help facilitate beginner learning."
  },
  {
    "id": 3724,
    "year": 2025,
    "title": "Confusing Value with Enumeration: Studying the Use of CVEs in Academia",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/schloegel",
    "abstract": "Common Vulnerabilities and Exposures (CVE) IDs serve as unique identifiers for security-relevant bugs, facilitating clear communication and tracking of affected products. Originally intended solely for identification, the CVE system has faced increasing criticism due to the misconception that assigning a CVE implies a serious security issue. Notably, academic works on security vulnerabilities often claim CVEs, presumably to demonstrate the practical impact of their methods. We systematically study the use of CVEs in academic papers to better understand the correlation of academic CVEs with real-world implications. To this end, we present the trends we identified through quantitative analysis, qualitative review of published papers, and a user survey. We observe a clear shift towards more frequent use of CVEs in academic papers over the last 25 years, especially in certain research areas. Our qualitative review of 1,803 CVEs claimed in papers published in the past five years reveals that 34% have not been publicly confirmed or were disputed by the maintainers of the affected software, challenging the notion of real-world effects. Our survey of 103 academic reviewers and authors reveals widespread misconceptions about the CVE system and an explicit preference for reporting CVE numbers, but without indicating any implicit bias in the review process. We advise caution on using CVEs as a proxy for real-world impact and provide actionable recommendations for the academic security community and practitioners."
  },
  {
    "id": 3725,
    "year": 2025,
    "title": "\"That's my perspective from 30 years of doing this\": An Interview Study on Practices, Experiences, and Challenges of Updating Cryptographic Code",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/krause",
    "abstract": "Keeping cryptographic code up to date and free of vulnerabilities is critical for overall software security. Updating algorithms (e.g., SHA-1 to SHA-512), key sizes (e.g., 2048 to 4096 bits), protocols (e.g., TLS 1.2 to 1.3), or transitioning to post-quantum cryptography (PQC) are common objectives of cryptographic updates. However, previous work and recent incidents illustrate developers' struggle with cryptographic updates. The research illustrates that many software products include outdated and insecure cryptographic code and libraries. However, the security community lacks a solid understanding of cryptographic updates. We conducted an interview study with 21 experienced software developers to address this research gap. We wanted to learn about their experiences, approaches, challenges, and needs. Our participants updated for security and non-security reasons and generally perceived cryptographic updates as challenging and tedious. They lacked structured processes and faced significant challenges, such as insufficient cryptographic knowledge, legacy support hindering cryptographic transition, and a lack of helpful guidance. Participants desired the assistance of cryptographic experts and understandable resources for successful updates. We conclude with recommendations for developers, academia, standards organizations, and the upcoming transition to PQC."
  },
  {
    "id": 3726,
    "year": 2025,
    "title": "\"I have no idea how to make it safer\": Studying Security and Privacy Mindsets of Browser Extension Developers",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/agarwal-shubham",
    "abstract": "Browser extensions play a vital role in the Web ecosystem: they enable users to customize their experience while browsing. However, the higher privileges of extensions compared to the Web applications require in-depth security considerations to not threaten the security and privacy of their users; the security and privacy mindset of developers has not been studied yet, though. In this paper, we close this research gap. \nTo that end, we conducted a qualitative study with extension developers from diverse backgrounds and experience levels (N=21) to identify the root causes for vulnerable extensions existing in the ecosystem. Our findings suggest that developers often implicitly acknowledge the S&P risks associated with their extensions, but they frequently lack the necessary knowledge and resources to implement effective security and privacy-protecting mechanisms. Additionally, socio-technical barriers, such as insufficient incentives and external pressures, including platform-imposed restrictions, further hinder secure development practices. Based on our findings, we offer empirically grounded takeaways for the browser extension ecosystem to help strengthen security practices and ultimately provide better protection for users."
  },
  {
    "id": 3727,
    "year": 2025,
    "title": "Precise and Effective Gadget Chain Mining through Deserialization Guided Call Graph Construction",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/zhang-yiheng",
    "abstract": "Gadget chains of consecutive method invocations can trigger Java deserialization vulnerabilities, posing significant security threats to applications. Existing detection methods often rely on imprecise call graphs while overlooking complex features like deserialization, dynamic proxy, and reflection, leading to incomplete and inaccurate results.\nThis paper presents FLASH, a novel gadget chain detection tool leveraging a deserialization-guided call graph construction approach. FLASH begins with controllability analysis to determine if variables can be restored through deserialization. It then applies a hybrid dispatch technique to resolve callees at call sites based on the controllability of their receiver variable: if controllable, a more comprehensive but potentially less precise technique (e.g., CHA, proxy dispatch) is used; otherwise, a more precise technique (e.g., pointer analysis) is applied. FLASH also recovers missing call edges by handling reflection involving controllable variables, and prunes false or irrelevant edges to improve accuracy and efficiency.\nEvaluation on 30 applications demonstrates that FLASH achieves higher recall (with 30.8% lower false negative rate) and precision (with 25.9% lower false positive rate) than state-of-the-art methods, at the cost of limited overhead. Furthermore, FLASH detects a total of 90 new gadget chains and 10 existing CVEs. Leveraging the new gadget chains, FLASH uncovers 5 previously unknown exploitation methods of the vulnerabilities, which demonstrate a broader impact compared to previously known CVEs."
  },
  {
    "id": 3728,
    "year": 2025,
    "title": "Mitigating Injection Attacks against E2EE Applications via View-Based Partitioning",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/fabrega-partitioning",
    "abstract": "A recent line of work has explored injection attacks against end-to-end encrypted (E2EE) applications. These involve sending adversarial content to a target victim E2EE client, thereby \"injecting it\" into otherwise honest client state, followed by monitoring some encrypted backup or other server-side state to violate confidentiality. These attacks exploit features such as compression before encryption of backups, and practitioners so far lack a way to prevent these attacks while retaining practicality.\nWe address this gap by introducing a framework for preventing injection attacks. Underlying the framework is a new approach that we call view-based partitioning, which allows application features to be designed to ensure that injection attacks cannot be exploited to leak confidential information. At the same time, our framework allows for efficiency: intuitively, application state can be partitioned according to potential adversarial views, and within individual views (e.g., all the messages visible to a particular sender in an E2EE messaging app) compression and other performance features can be used without risk of injection attacks.\nWe provide, for the first time, a formal security model for injection attacks, and prove that designers can use our framework to ensure injection attacks fail. Finally, we evaluate various implementations of our framework as applied to backing up E2EE application state via SQLite and XML databases, showing that we can achieve injection resistance with negligible performance overheads."
  },
  {
    "id": 3729,
    "year": 2025,
    "title": "Boosting Gradient Leakage Attacks: Data Reconstruction in Realistic FL Settings",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/fan-boosting",
    "abstract": "Federated learning (FL) enables collaborative model training among multiple clients without the need to expose raw data. Its ability to safeguard privacy, at the heart of FL, has recently been a hot-button debate topic. To elaborate, several studies have introduced a type of attacks known as gradient leakage attacks (GLAs), which exploit the gradients shared during training to reconstruct clients' raw data. On the flip side, some literature, however, contends no substantial privacy risk in practical FL environments due to the effectiveness of such GLAs being limited to overly relaxed conditions, such as small batch sizes and knowledge of clients' data distributions. This paper bridges this critical gap by empirically demonstrating that clients' data can still be effectively reconstructed, even within realistic FL environments. Upon revisiting GLAs, we recognize that their performance failures stem from their inability to handle the gradient matching problem. To alleviate the performance bottlenecks identified above, we develop FEDLEAK, which introduces two novel techniques, partial gradient matching and gradient regularization. Moreover, to evaluate the performance of FEDLEAK in real-world FL environments, we formulate a practical evaluation protocol grounded in a thorough review of extensive FL literature and industry practices. Under this protocol, FEDLEAK can still achieve high-fidelity data reconstruction, thereby underscoring the significant vulnerability in FL systems and the urgent need for more effective defense methods."
  },
  {
    "id": 3730,
    "year": 2025,
    "title": "Refiner: Data Refining against Gradient Leakage Attacks in Federated Learning",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/fan-refiner",
    "abstract": "Recent works highlight the vulnerability of Federated Learning (FL) systems to gradient leakage attacks, where attackers reconstruct clients' data from shared gradients, undermining FL's privacy guarantees. However, existing defenses show limited resilience against sophisticated attacks. This paper introduces a novel defensive paradigm that departs from conventional gradient perturbation approaches and instead focuses on the construction of robust data. Our theoretical analysis indicates such data, which exhibits low semantic similarity to the clients' raw data while maintaining good gradient alignment to clients' raw data, is able to effectively obfuscate attackers and yet maintain model performance. We refer to such data as robust data, and to generate it, we design Refiner that jointly optimizes two metrics for privacy protection and performance maintenance. The utility metric promotes the gradient consistency of key parameters between robust data and clients' data, while the privacy metric guides the generation of robust data towards enlarging the semantic gap with clients' data. Extensive empirical evaluations on multiple benchmark datasets demonstrate the superior performance of Refiner at defending against state-of-the-art attacks."
  },
  {
    "id": 3731,
    "year": 2025,
    "title": "Aion: Robust and Efficient Multi-Round Single-Mask Secure Aggregation Against Malicious Participants",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/liu-yizhong",
    "abstract": "Federated learning enables multiple clients to collaboratively train a model without sharing their data. Secure aggregation (SA) allows for the computation of aggregated models while protecting the private models of clients from disclosure, making it highly promising in large-scale real-world applications. Masking-based SA stands out due to its higher efficiency and accuracy. However, existing masking-based SA methods face issues such as high overhead, loss of correctness under poisoning attacks, and inability to tolerate malicious participants. In this paper, we propose Aion, a robust and efficient multi-round single-mask SA tolerating malicious participants. We introduce an aggregatable SA pattern in which each client only adds a single mask and performs only one secret sharing operation, while each aggregator only reconstructs a total secret or mask. Compared to Flamingo (S&P '23), this reduces the secret sharing times from rq to q (r for training round number and q for client number per round) and lowers n aggregators'  mask reconstruction overhead from O(n^2) to O(n). Furthermore, we design a lightweight evolving input validation mechanism that efficiently filters out malicious client models by dynamically updating the mask range and overall bound, thereby improving model accuracy. Besides, we present robustness enhancements that tolerate malicious clients and aggregators. These constructions support aggregator share verification and asynchronous client model utilization. Finally, experiments demonstrate that Aion outperforms Flamingo by a factor of 563.64 in speed while achieving a 97.98% reduction in message overhead with 4096 clients and 8 aggregators, effectively defending against poisoning attacks with low overhead."
  },
  {
    "id": 3732,
    "year": 2025,
    "title": "SoK: On Gradient Leakage in Federated Learning",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/du",
    "abstract": "Federated learning (FL) facilitates collaborative model training among multiple clients without raw data exposure. However, recent studies have shown that clients' private training data can be reconstructed from shared gradients in FL, a vulnerability known as gradient inversion attacks (GIAs). While GIAs have demonstrated effectiveness under ideal settings and auxiliary assumptions, their actual efficacy against practical FL systems remains under-explored. To address this gap, we conduct a comprehensive study on GIAs in this work. We start with a survey of GIAs that establishes a timeline to trace their evolution and develops a systematization to uncover their inherent threats. By rethinking GIA in practical FL systems, three fundamental aspects influencing GIA's effectiveness are identified: training setup, model, and post-processing. Guided by these aspects, we perform extensive theoretical and empirical evaluations of SOTA GIAs across diverse settings. Our findings highlight that GIA is notably constrained, fragile, and easily defensible. Specifically, GIAs exhibit inherent limitations against practical local training settings. Additionally, their effectiveness is highly sensitive to the trained model, and even simple post-processing techniques applied to gradients can serve as effective defenses. Our work provides crucial insights into the limited threats of GIAs in practical FL systems. By rectifying prior misconceptions, we hope to inspire more accurate and realistic investigations on this topic."
  },
  {
    "id": 3733,
    "year": 2025,
    "title": "DP-BREM: Differentially-Private and Byzantine-Robust Federated Learning with Client Momentum",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/gu-xiaolan",
    "abstract": "Federated Learning (FL) allows multiple participating clients to train machine learning models collaboratively while keeping their datasets local and only exchanging the gradient or model updates with a coordinating server. Existing FL protocols are vulnerable to attacks that aim to compromise data privacy and/or model robustness. Recently proposed defenses focused on ensuring either privacy or robustness, but not both. In this paper, we focus on simultaneously achieving differential privacy (DP) and Byzantine robustness for cross-silo FL, based on the idea of learning from history. The robustness is achieved via client momentum, which averages the updates of each client over time, thus reducing the variance of the honest clients and exposing the small malicious perturbations of Byzantine clients that are undetectable in a single round but accumulate over time. In our initial solution DP-BREM, DP is achieved by adding noise to the aggregated momentum, and we account for the privacy cost from the momentum, which is different from the conventional DP-SGD that accounts for the privacy cost from the gradient. Since DP-BREM assumes a trusted server (who can obtain clients' local models or updates), we further develop the final solution called DP-BREM+, which achieves the same DP and robustness properties as DP-BREM without a trusted server by utilizing secure aggregation techniques, where DP noise is securely and jointly generated by the clients. Both theoretical analysis and experimental results demonstrate that our proposed protocols achieve better privacy-utility tradeoff and stronger Byzantine robustness than several baseline methods, under different DP budgets and attack settings."
  },
  {
    "id": 3734,
    "year": 2025,
    "title": "SLOTHE : Lazy Approximation of Non-Arithmetic Neural Network Functions over Encrypted Data",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/nam-slothe",
    "abstract": "Machine Learning as a Service (MLaaS) introduces strong privacy concerns for both clients and model providers. Fully Homomorphic Encryption (FHE) offers a promising solution by enabling inference over encrypted data, but its limited expressiveness requires approximating non-arithmetic functions (NAFs) with polynomials, often leading to significant accuracy and performance trade-offs. Existing works adopt an eager approximation (EA) strategy, which statically replaces each NAF with a fixed polynomial, locking in computational errors and limiting optimization opportunities. We propose SLOTHE, a lazy approximation (LA) solution that recursively decomposes NAF codes into arithmetic and non-arithmetic sub-functions, selectively approximating only the non-arithmetic components when required. SLOTHE introduces a tunable cost model to balance accuracy and latency, and incorporates FHE-aware optimizations to eliminate redundant computation. Implemented using CKKS, SLOTHE achieves up to 42,378× lower maximum error than EA-based works, with improved inference accuracy and latency across BERT-based transformers. SLOTHE can also be adapted for MPC-based protocols, making it a flexible tool for secure neural network inference."
  },
  {
    "id": 3735,
    "year": 2025,
    "title": "Sharpness-Aware Initialization: Improving Differentially Private Machine Learning from First Principles",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/wang-zihao",
    "abstract": "Recent advances in privacy-preserving machine learning underscore the critical role of differential privacy (DP) in protecting individual data. However, the noise introduced during DP training often leads to significant performance degradation, creating a major challenge for differentially private machine learning (DPML).\nIn this work, we address this challenge by controlling the detrimental effects of DP noise. Specifically, we focus on enhancing a model's robustness to random perturbations, thereby mitigating their negative impact on convergence—a central factor in maintaining high utility under DP. To this end, we propose sharpness-aware initialization (SAI), a method for improving the accuracy of DPML algorithms by achieving a flatter loss landscape. Our approach employs a two-phase training framework: SAI followed by standard Differentially Private Stochastic Gradient Descent (DPSGD). This strategy capitalizes on the observation that loss-landscape flatness converges more rapidly than the training loss, enabling an early stop on flatness optimization to limit divergence risk, followed by a phase dedicated to training-loss optimization. Moreover, splitting the training into two distinct phases allows for different privacy budgets in each phase, aligning their respective optimization objectives and tolerance to DP noise, which further mitigates performance degradation. Our experimental results show that SAI substantially improves the accuracy of state-of-the-art DPML algorithms across a range of datasets and model architectures, achieving gains of over 6% on CIFAR-10 under epsilon=1."
  },
  {
    "id": 3736,
    "year": 2025,
    "title": "Task-Oriented Training Data Privacy Protection for Cloud-based Model Training",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/wang-zhiqiang",
    "abstract": "Cloud-based model training presents significant privacy challenges, as users must upload personal data for training high-performance models. Once uploaded, this data goes beyond the user's control and could be misused for other purposes. Users need tools to control the usage scope of the uploaded training data, preventing unauthorized training without compromising authorized training. Unfortunately, existing solutions overlook this issue.\nIn this paper, we propose and achieve a unique privacy-utility goal tailored for cloud-based model training, considering both user demand and legal requirements. Our approach provides task-level control of training data usage, simultaneously ensuring each protected data exhibits noticeable visual changes to address fundamental privacy concerns. We introduce carefully designed noise to each training data for privacy protection. These noises are designed to provide visual protection while minimizing the shifts in the feature domain through adversarial optimization. By adjusting the correlation between noise and class labels, we guide the model to learn the correct features for the target task while preventing unauthorized privacy task training. Additionally, we introduce the overflow matrix for compatibility with existing encoding and transmission frameworks. Real-world experiments demonstrate that it can simultaneously protect visual privacy (SSIM is 0.028) and prevent unauthorized model training (protection success rate achieved 100%), while the accuracy of the target task model is slightly reduced by about 1.8%."
  },
  {
    "id": 3737,
    "year": 2025,
    "title": "From Risk to Resilience: Towards Assessing and Mitigating the Risk of Data Reconstruction Attacks in Federated Learning",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/xu-xiangrui",
    "abstract": "Data Reconstruction Attacks (DRA) pose a significant threat to Federated Learning (FL) systems by enabling adversaries to infer sensitive training data from local clients. Despite extensive research, the question of how to characterize and assess the risk of DRAs in FL systems remains unresolved due to the lack of a theoretically-grounded risk quantification framework.  In this work, we address this gap by introducing Invertibility Loss (InvLoss) to quantify the maximum achievable effectiveness of DRAs for a given data instance and FL model. We derive a tight and computable upper bound for InvLoss and explore its implications from three perspectives. First, we show that DRA risk is governed by the spectral properties of the Jacobian matrix of exchanged model parameters or feature embeddings, providing a unified explanation for the effectiveness of defense methods. Second, we develop InvRE, an InvLoss-based DRA risk estimator that offers attack method-agnostic, comprehensive risk evaluation across data instances and model architectures. Third, we propose two adaptive noise perturbation defenses that enhance FL privacy without harming classification accuracy. Extensive experiments on real-world datasets validate our framework, demonstrating its potential for systematic DRA risk evaluation and mitigation in FL systems."
  },
  {
    "id": 3738,
    "year": 2025,
    "title": "Demystifying the (In)Security of QR Code-based Login in Real-world Deployments",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/zhang-xin",
    "abstract": "QR code-based Login (QRLogin) has emerged as a prevalent method for web account authentication, offering a more user-friendly alternative to traditional username and password entry. However, despite its growing popularity, the security of QRLogin has been overlooked. In particular, the lack of standardized QRLogin design and implementation guidelines, coupled with its wide deployment variability, raises significant concerns on the real-world deployments of QRLogin.\n\nThis paper presents the first systematic study on the security of QRLogin in real-world deployments. We begin our research with real-world studies to understand the deployment status of QRLogin and user perceptions of this novel authentication paradigm, which assists us in establishing a realistic threat model. We then proceed with a systematic security analysis by generalizing the typical workflow of QRLogin, examining how key variables adhere to common security principles, and ultimately exposing 6 potential flaws. We conduct security analysis on real-world QRLogin deployments with a semi-automatic detection pipeline, and reveal surprising results that 47 top websites (43% of tested) are vulnerable to at least one of the above flaws. These design and implementation flaws can lead to 5 types of attacks, including Authorization Hijacking, Double Login, Brute-force Login, Universal Account Takeover, and Privacy Abuse. We have responsibly reported all the identified issues and received 42 vulnerability IDs from official vulnerability repositories. We further provide an auditing tool and suggestions for developers and users, contributing a concerted step towards more secure implementations of QRLogin."
  },
  {
    "id": 3739,
    "year": 2025,
    "title": "Doubly Dangerous: Evading Phishing Reporting Systems by Leveraging Email Tracking Techniques",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/chand",
    "abstract": "Given the significant threat posed by email as a highly prevalent phishing attack vector, we undertake the first study focused on real-world phishing email reporting systems. Our key idea in performing this study is to repurpose email tracking, a well-known privacy threat vector, for profiling and evading anti-phishing systems employed by popular email services. Our results show that the reporting systems of all major email services we tested are vulnerable to evasive phishing attacks affecting more than 2 billion users worldwide. We propose several countermeasures that email service operators can adopt to help ameliorate this issue in the future. We disclosed our findings to the affected email providers which resulted in remedial changes and a vulnerability reward."
  },
  {
    "id": 3740,
    "year": 2025,
    "title": "Evaluating the Effectiveness and Robustness of Visual Similarity-based Phishing Detection Models",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/ji",
    "abstract": "Phishing attacks pose a significant threat to Internet users, with cybercriminals elaborately replicating the visual appearance of legitimate websites to deceive victims. Visual similarity-based detection systems have emerged as an effective countermeasure, but their effectiveness and robustness in real-world scenarios have been underexplored. In this paper, we comprehensively scrutinize and evaluate the effectiveness and robustness of popular visual similarity-based anti-phishing models using a large-scale dataset of 451k real-world phishing websites. Our analyses of the effectiveness reveal that while certain visual similarity-based models achieve high accuracy on curated datasets in the experimental settings, they exhibit notably low performance on real-world datasets, highlighting the importance of real-world evaluation. Furthermore, we find that the attackers evade the detectors mainly in three ways: (1) directly attacking the model pipelines, (2) mimicking benign logos, and (3) employing relatively simple strategies such as eliminating logos from screenshots. To statistically assess the resilience and robustness of existing models against adversarial attacks, we categorize the strategies attackers employ into visible and perturbation-based manipulations and apply them to website logos. We then evaluate the models' robustness using these adversarial samples. Our findings reveal potential vulnerabilities in several models, emphasizing the need for more robust visual similarity techniques capable of withstanding sophisticated evasion attempts. We provide actionable insights for enhancing the security of phishing defense systems, encouraging proactive actions."
  },
  {
    "id": 3741,
    "year": 2025,
    "title": "Universal Cross-app Attacks: Exploiting and Securing OAuth 2.0 in Integration Platforms",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/luo-kaixuan",
    "abstract": "Integration Platforms such as Workflow Automation Platforms, Virtual Assistants and Smart Homes are becoming an integral part of the Internet. These platforms welcome third-parties to develop and distribute apps in their open marketplaces, and support \"account linking\" to connect end-users' app accounts to their platform account. This enables the platform to orchestrate a wide range of external services on behalf of the end-users. While OAuth is the de facto standard for account linking, the open nature of integration platforms poses new threats, as their OAuth architecture could be exploited by untrusted integrated apps.\nIn this paper, we examine the flawed designs of multi-app OAuth authorizations that support account linking in integration platforms. We unveil two new platform-wide attacks due to the lack of app differentiation: Cross-app OAuth Account Takeover (COAT) and Request Forgery (CORF). As long as a victim end-user establishes account linking with a malicious app, or potentially with just a click on a crafted link, they risk unauthorized access or privacy leakage of any apps on the platform.\nTo facilitate systematic discovery of vulnerabilities, we develop COVScan, a semi-automated black-box testing tool that profiles varied OAuth designs to identify cross-app vulnerabilities in real-world platforms. Our measurement study reveals that among 18 popular consumer- or enterprise-facing integration platforms, 11 are vulnerable to COAT and another 5 to CORF, including those built by Microsoft, Google and Amazon. The vulnerabilities render widespread impact, leading to unauthorized control over end-users' services and devices, covert logging of sensitive information, and compromising a major ecosystem in single click (a CVE with CVSS 9.6). We responsibly reported the vulnerabilities and collaborated with the affected vendors to deploy comprehensive solutions."
  },
  {
    "id": 3742,
    "year": 2025,
    "title": "Predictive Response Optimization: Using Reinforcement Learning to Fight Online Social Network Abuse",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/wilson",
    "abstract": "Detecting phishing, spam, fake accounts, data scraping, and other malicious activity in online social networks (OSNs) is a problem that has been studied for well over a decade, with a number of important results. Nearly all existing works on abuse detection have as their goal producing the best possible binary classifier; i.e., one that labels unseen examples as \"benign\" or \"malicious\" with high precision and recall. However, no prior published work considers what comes next: what does the service actually do after it detects abuse?\nIn this paper, we argue that detection as described in previous work is not the goal of those who are fighting OSN abuse. Rather, we believe the goal to be selecting actions (e.g., ban the user, block the request, show a CAPTCHA, or \"collect more evidence\") that optimize a tradeoff between harm caused by abuse and impact on benign users. With this framing, we see that enlarging the set of possible actions allows us to move the Pareto frontier in a way that is unattainable by simply tuning the threshold of a binary classifier.\nTo demonstrate the potential of our approach, we present Predictive Response Optimization (PRO), a system based on reinforcement learning that utilizes available contextual information to predict future abuse and user-experience metrics conditioned on each possible action, and select actions that optimize a multi-dimensional tradeoff between abuse/harm and impact on user experience.\nWe deployed versions of PRO targeted at stopping automated activity on Instagram and Facebook. In both cases our experiments showed that PRO outperforms a baseline classification system, reducing abuse volume by 59% and 4.5% (respectively) with no negative impact to users. We also present several case studies that demonstrate how PRO can quickly and automatically adapt to changes in business constraints, system behavior, and/or adversarial tactics."
  },
  {
    "id": 3743,
    "year": 2025,
    "title": "Hercules Droidot and the murder on the JNI Express",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/di-bartolomeo",
    "abstract": "Android developers rely on native libraries to improve app performance, often overlooking the increased security risk. Executed in the same process as the app Dalvik bytecode, vulnerable libraries expose the app to low-level security threats such as access to the app's private data. Vulnerability discovery in this environment exposes several key challenges: (i) coping with complex cross-language interactions between the app running on a high-level runtime environment and the low-level code of native libraries, (ii) inference of a precise interaction model between the app and the library, and (iii) scaling to the breadth of the Android ecosystem.\nAutomatic harness generation for libraries is challenging, especially in mixed language environments such as Android. Existing work either slices snippets of program code, ignoring the cross-language challenges of bringing up the Android runtime environment or require heavy manual efforts on a limited selection of applications. The current best practice to discover vulnerabilities in native libraries on Android is to task a human analyst to reverse engineer both the app and the library along with manually writing a test harness.\nOur solution, named POIROT, automatically synthesizes fuzzing harnesses for Android native libraries without source code or manual effort. POIROT supports bidirectional JNI (Java Native Interface) interactions, mimics the app's usage of a native API, and scales to the largest apps on the Google Play Store. We evaluated POIROT on the 3,967 most popular Android apps that use native libraries and report 4,282 unique crashes affecting 934 apps. We triaged 200 crashes and identified 25 bugs affecting 16 native libraries included in 34 high-impact apps such as WeChat (with 3 CVEs assigned). All the bugs have been responsibly disclosed to the respective vendors."
  },
  {
    "id": 3744,
    "year": 2025,
    "title": "No Way to Sign Out? Unpacking Non-Compliance with Google Play's App Account Deletion Requirements",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/yan-jingwen",
    "abstract": "Despite the significant convenience mobile apps bring to our daily lives, the collection and use of personal information by these apps remain a major concern, particularly regarding how such data is handled after users sign out. To align with regulations like the General Data Protection Regulation (GDPR) that have included specific provisions granting individuals the right to request data deletion, mobile app stores, such as Google Play, have introduced new account deletion requirements that require apps to provide proper account deletion methods. In this work, we conducted the first study on investigating non-compliance issues with Google Play's app account deletion requirements. Starting with a pilot study of the top 50 apps on Google Play, we identified potential issues related to account deletion and defined three main categories of issues: link issues, content issues, and functionality issues. Based on these findings, we developed a tool named DELETETRACKER to automatically collect account deletion-related information from Google Play and semi-automatically identify non-compliance issues regarding account deletion. Using DELETETRACKER, we analyzed 863 Google Play apps' account deletion information. Among the 494 apps with accessible account deletion links, DELETETRACKER found only 8.5% of apps to provide both in-app path and web-based account deletion methods, which fully comply with Google Play's account deletion requirements. 64.6% of apps offer only one account deletion method. We also found 12 apps that failed to delete user accounts. We have reported our findings to Google through the vulnerability reporting process. Following our disclosure, Google acknowledged the reported issue and assigned it a Medium (S2) severity level."
  },
  {
    "id": 3745,
    "year": 2025,
    "title": "Lost in the Mists of Time: Expirations in DNS Footprints of Mobile Apps",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/so",
    "abstract": "Compared to the traditional desktop setting where web applications (apps) are live by nature, mobile apps are similar to binary programs that are installed on devices, in that they remain static until they are updated. However, they can also contain live, dynamic components if they interface with the web. This may lead to a confusing scenario, in which a mobile app itself has not been updated, but changes in dynamic components have caused changes in the overall app behavior.\nIn this work, we present the ﬁrst large-scale analysis of mobile app dependencies through a dual perspective accounting for time and version updates, with a focus on expired domains. First, we detail a methodology to build a representative corpus comprising 77,206 versions of 15,124 unique Android apps. Next, we extract the unique eTLD+1 domain dependencies — the \"DNS footprint\" — of each APK by monitoring the network trafﬁc produced with a dynamic, UI-guided test input generator and report on the footprint of a typical app. Using these footprints, combined with a methodology that deduces potential periods of vulnerability for individual APKs by leveraging passive DNS, we characterize how apps may have been affected by expired domains throughout time. Our ﬁndings indicate that the threat of expired domains in app dependencies is nontrivial at scale, affecting hundreds of apps and thousands of APKs, occasionally affecting apps that rank within the top ten of their categories, apps that have hundreds of millions of downloads, or apps that were the latest version. Furthermore, we uncovered 41 immediately registrable domains that were found in app footprints during our analyses, and provide evidence in the form of case studies as to their potential for abuse. We also ﬁnd that even the most security-conscious users cannot protect themselves against the risk of their using an app that has an expired dependency, even if they can update their apps instantaneously."
  },
  {
    "id": 3746,
    "year": 2025,
    "title": "TapTrap: Animation-Driven Tapjacking on Android",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/beer",
    "abstract": "Users interact with mobile devices under the assumption that the graphical user interface (GUI) accurately reflects their actions, a trust fundamental to the user experience. In this work, we present TapTrap, a novel attack that enables zero-permission apps to exploit UI animations to undermine this trust relationship. TapTrap can be used by a malicious app to stealthily bypass Android's permission system and gain access to sensitive data or execute destructive actions, such as wiping the device without user approval. Its impact extends beyond the Android ecosystem, enabling tapjacking and Web clickjacking. TapTrap is able to bypass existing tapjacking defenses, as those are targeted toward overlays. Our novel approach, instead, abuses activity transition animations and is effective even on Android 15. We analyzed 99,705 apps from the Play Store to assess whether TapTrap is actively exploited in the wild. Our analysis found no evidence of such exploitation. Additionally, we conducted a large-scale study on these apps and discovered that 76.3% of apps are vulnerable to TapTrap. Finally, we evaluated the real-world feasibility of TapTrap through a user study with 20 participants, showing that all of them failed to notice at least one attack variant. Our findings have resulted in two assigned CVEs."
  },
  {
    "id": 3747,
    "year": 2025,
    "title": "BulletCT: Towards More Scalable Ring Confidential Transactions With Transparent Setup",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/wang-nan",
    "abstract": "RingCT signatures are essential components of Ring Confidential Transaction (RingCT) schemes on blockchain platforms, enabling anonymous transaction spending and significantly impacting the scalability of these schemes. This paper makes two primary contributions:\nWe provide the first thorough analysis of a recently developed Any-out-of-N proof in the discrete logarithm (DLOG) setting and the associated RingCT scheme, introduced by ZGSX23 (S&P '23). The proof conceals the number of the secrets to offer greater anonymity than K-out-of-N proofs and uses an efficient \"K-Weight\" technique for its construction. However, we identify for the first time several limitations of using Any-out-of-N proofs, such as increased transaction sizes, heightened cryptographic complexities and potential security risks. These limitations prevent them from effectively mitigating the longstanding scalability bottleneck.\nWe then continue to explore the potential of using K-out-of-N proofs to enhance scalability of RingCT schemes. Our primary innovation is a new DLOG-based RingCT signature that integrates a refined \"K-Weight\"-based K-out-of-N proof and an entirely new tag proof. The latter is the first to efficiently enable the linkability of RingCT signatures derived from the former, effectively resisting double-spending attacks. \nFinally, we identify and patch a linkability flaw in ZGSX23's signature. We benchmark our scheme against this patched one to show that our scheme achieves a boost in scalability, marking a promising step forward."
  },
  {
    "id": 3748,
    "year": 2025,
    "title": "PolySys: an Algebraic Leakage Attack Engine",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/espiritu",
    "abstract": "In this work, we propose a novel framework called PolySys for modeling and designing leakage attacks as constraint-solving algorithms over polynomial systems. PolySys formalizes the design of attacks using invertible encodings, structural and leakage equations, and efficient constraint-solving algorithms including SAT and constraint solvers. It is capable of modeling resolution, known-data, and inference attacks for common leakage patterns.\nTo demonstrate the practicality of our framework, we implement a PolySys attack engine in Python and apply it to state-of-the-art query recovery, data resolution, and query inference attacks on point and range multi-maps. Our results show that PolySys outperforms all existing attacks under identical assumptions, achieving up to 60× higher recovery rates in some scenarios. While scalability remains a challenge for larger datasets, PolySys represents a promising step toward a general-purpose framework for designing leakage attacks. We believe future work can further enhance its efficiency to scale to larger and more complex workloads."
  },
  {
    "id": 3749,
    "year": 2025,
    "title": "Distributional Private Information Retrieval",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/lehmkuhl",
    "abstract": "A private-information-retrieval (PIR) scheme lets a client fetch a record from a remote database without revealing which record it fetched. Classic PIR schemes treat all database records the same but, in practice, some database records are much more popular (i.e., commonly fetched) than others. We introduce distributional PIR, a new type of PIR that can run faster than classic PIR—both asymptotically and concretely—when the popularity distribution is skewed. Distributional PIR provides exactly the same cryptographic privacy as classic PIR. The speedup comes from a relaxed form of correctness: distributional PIR guarantees that in-distribution queries succeed with good probability, while out-of-distribution queries succeed with lower probability. Because of its relaxed correctness, distributional PIR is best suited for applications where \"best-effort\" retrieval is acceptable. Moreover, for security, a client's decision to query the server must be independent of whether its past queries were successful.\nWe construct a distributional-PIR scheme that makes black-box use of classic PIR protocols, and prove a lower bound on the server runtime of a natural class of distributional-PIR schemes. On two real-world popularity distributions, our construction reduces compute costs by 5-77x compared to existing techniques. Finally, we build CrowdSurf, an end-to-end system for privately fetching tweets, and show that distributional-PIR reduces the end-to-end server cost by 8x."
  },
  {
    "id": 3750,
    "year": 2025,
    "title": "Practical Keyword Private Information Retrieval from Key-to-Index Mappings",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/hao",
    "abstract": "This paper introduces practical schemes for keyword Private Information Retrieval (keyword PIR), enabling private queries on public databases using keywords. Unlike standard index-based PIR, keyword PIR presents greater challenges, since the query's position within the database is unknown and the domain of keywords is vast. Our key insight is to construct an efficient and compact key-to-index mapping, thereby reducing the keyword PIR problem to standard PIR. To achieve this, we propose three constructions incorporating several new techniques. The high-level approach involves (1) encoding the server's key-value database into an indexable database with a key-to-index mapping and (2) invoking standard PIR on the encoded database to retrieve specific positions based on the mapping. We conduct comprehensive experiments, with results showing substantial improvements over the state-of-the-art keyword PIR, ChalametPIR (CCS '24), i.e., a 15∼178 x reduction in communication and 1.1 ∼ 2.4 x runtime improvement, depending on database size and entry length. Our constructions are practical, executing keyword PIR in just 47 ms for a database containing 1 million 32-byte entries."
  },
  {
    "id": 3751,
    "year": 2025,
    "title": "SEAF: Secure Evaluation on Activation Functions with Dynamic Precision for Secure Two-Party Inference",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/guo-hao-seaf",
    "abstract": "Secure evaluation of non-linear functions is one of the most expensive operations in secure two-party computation, particularly for activation functions in privacy preserving machine learning (PPML). This work introduces SEAF, a novel framework for efficient Secure Evaluation on Activation Functions. SEAF is based on the linear approximation approach, but enhances it by introducing two key innovations: Trun-Eq based interval test protocols and linear approximation with dynamic precision, which have the potential for broader applicability. Furthermore, we classify common activation functions into several categories, and present specialized methodsa to evaluate them using our enhanced techniques. Our implementation of SEAF demonstrates 3.5 x to 5.9 x speedup on activation functions Tanh and Sigmoid compared to SirNN (S&P '21). When applied on GELU, SEAF outperforms Iron (NeurIPS '22) by more than 10 x and Bolt (S&P '24) by up to 3.4 x. For end-to-end secure inference on BERT, the original GELU accounts for 31.3% and 22.5% of the total runtime in Iron and Bolt, respectively. In contrast, our optimized GELU reduces these proportions to 4.3% and 9.8%, eliminating GELU as a bottleneck in secure inference."
  },
  {
    "id": 3752,
    "year": 2025,
    "title": "Fast Enhanced Private Set Union in the Balanced and Unbalanced Scenarios",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/tu",
    "abstract": "Private set union (PSU) allows two parties to compute the union of their sets without revealing anything else. It can be categorized into balanced and unbalanced scenarios depending on the size of the set on both sides. Recently, Jia et al. (USENIX Security 2024) highlight that existing scalable PSU solutions suffer from during-execution leakage and propose a PSU with enhanced security for the balanced setting. However, their protocol's complexity is superlinear with the size of the set. Thus, the problem of constructing a linear enhanced PSU remains open, and no unbalanced enhanced PSU exists. In this work, we address these two open problems:\n\nBalanced case: We propose the first linear enhanced PSU. Compared to the state-of-the-art enhanced PSU (Jia et al., USENIX Security 2024), our protocol achieves a 2.2 - 8.8x reduction in communication cost and a 1.2 - 8.6x speedup in running time, depending on set sizes and network environments.\nUnbalanced case: We present the first unbalanced enhanced PSU, which achieves sublinear communication complexity in the size of the large set. Experimental results demonstrate that the larger the difference between the two set sizes, the better our protocol performs. For unbalanced set sizes (2^10, 2^20) with single thread in 1Mbps bandwidth, our protocol requires only 2.322 MB of communication. Compared with the state-of-the-art enhanced PSU, there is 38.1x shrink in communication and roughly 17.6x speedup in the running time."
  },
  {
    "id": 3753,
    "year": 2025,
    "title": "BEAT-MEV: Epochless Approach to Batched Threshold Encryption for MEV Prevention",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/bormet",
    "abstract": "In decentralized finance (DeFi), the public availability of pending transactions presents significant privacy concerns, enabling market manipulation through miner extractable value (MEV). MEV occurs when block proposers exploit the ability to reorder, omit, or include transactions, causing financial loss to users from frontrunning. Recent research has focused on encrypting pending transactions, hiding transaction data until block finalization. To this end, Choudhuri et al. (USENIX '24) introduce an elegant new primitive called Batched Threshold Encryption (BTE) where a batch of encrypted transactions is selected by a committee and only decrypted after block finalization. Crucially, BTE achieves low communication complexity during decryption and guarantees that all encrypted transactions outside the batch remain private. An important shortcoming of their construction is, however, that it progresses in epochs and requires a costly setup in MPC for each batch decryption. In this work, we introduce a novel BTE scheme addressing the limitations by eliminating the need for an expensive epoch setup while achieving practical encryption and decryption times. Additionally, we explore a previously ignored question of how users can coordinate their transactions, which is crucial for the functionality of the system. Along the way, we present several optimizations and trade-offs between communication and computational complexity that allows us to achieve practical performance on standard hardware (< 2 ms for encryption and < 440 ms for decrypting 512 transactions). Finally, we prove our constructions secure in a model that captures practical attacks on MEV-prevention mechanisms."
  },
  {
    "id": 3754,
    "year": 2025,
    "title": "Practical Mempool Privacy via One-time Setup Batched Threshold Encryption",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/choudhuri",
    "abstract": "An important consideration with the growth of the DeFi ecosystem is the protection of clients who submit transactions to the system. As it currently stands, the public visibility of these transactions in the memory pool (mempool) makes them susceptible to market manipulations such as frontrunning and backrunning. More broadly, for various reasons—ranging from avoiding market manipulation to including time-sensitive information in their transactions—clients may want the contents of their transactions to remain private until they are executed, i.e. they have pending transaction privacy. Therefore, mempool privacy is becoming an increasingly important feature as DeFi applications continue to spread.\nWe construct the first practical mempool privacy scheme that uses a one-time DKG setup for n decryption servers. Our scheme ensures the strong privacy requirement by not only hiding the transactions until they are decrypted but also guaranteeing privacy for transactions that were not selected in the epoch (pending transaction privacy). For each epoch (or block), clients can encrypt their transactions so that, once B (encrypted) transactions are selected for the epoch, they can be decrypted by each decryption server while communicating only O(1) information.\nOur result improves upon the best-known prior works, which either: (i) require an expensive initial setup involving a (special purpose) multiparty computation protocol executed by the n decryption servers, along with an additional per-epoch setup; (ii) require each decryption server to communicate O(B) information; or (iii) do not guarantee pending transaction privacy.\nWe implement our scheme and find that transactions can be encrypted in approximately 8.5 ms, independent of committee size, and the communication required to decrypt an entire batch of transactions is 48 bytes per party, independent of the number of transactions. If deployed on Ethereum, which processes close to 500 transactions per block, it takes close to 3.2 s for each committee member to compute a partial decryption and 3.0 s to decrypt all transactions for a block in single-threaded mode. Compared to prior work, which had an expensive setup phase per epoch, we incur < 2x overhead in the worst case. On some metrics such as partial decryptions size, we actually fare better."
  },
  {
    "id": 3755,
    "year": 2025,
    "title": "DeepFold: Efficient Multilinear Polynomial Commitment from Reed-Solomon Code and Its Application to Zero-knowledge Proofs",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/guo-yanpei",
    "abstract": "This work presents Deepfold, a novel multilinear polynomial commitment scheme (PCS) based on Reed-Solomon code that offers optimal prover time and a more concise proof size. For the first time, Deepfold adapts the FRI-based multilinear PCS to the list decoding radius setting, requiring significantly fewer query repetitions and thereby achieving a 3x reduction in proof size compared to Basefold (Crypto '24), while preserving its advantages in prover time. Compared with PolyFRIM (USENIX Security '24), Deepfold achieves a 2x improvement in prover time, verifier time, and proof size. Another contribution of this work is a batch evaluation scheme, which enables the FRI-based multilinear PCS to handle polynomials whose size is not a power of two more efficiently.\nOur scheme has broad applications in zk-SNARKs, since PCS is a key component in modern zk-SNARK constructions. For example, when replacing the PCS component of Virgo (S&P '20) with Deepfold, our scheme achieves a 2.5x faster prover time when proving the knowledge of a Merkle tree with 256 leaves, while maintaining the similar proof size. When replacing the PCS component of HyperPlonk (Eurocrypt '23) with Deepfold, our scheme has about 3.6x faster prover time. Additionally, when applying our arbitrary length input commitment to verifiable matrix multiplications for matrices of size 1200x768 and 768x2304, which are actual use cases in GPT-2 model, the performance showcases a 2.4x reduction in prover time compared to previous approaches."
  },
  {
    "id": 3756,
    "year": 2025,
    "title": "Your Shield is My Sword: A Persistent Denial-of-Service Attack via the Reuse of Unvalidated Caches in DNSSEC Validation",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/zhang-shuhan",
    "abstract": "The Domain Name System Security Extensions (DNSSEC), designed to ensure the authenticity and integrity of DNS data, has been deployed in over 90% of top-level zones. To mitigate service outages due to DNSSEC misconfigurations, DNS resolvers allow the public to troubleshoot resource records without enforcing DNSSEC validation. Unfortunately, given no clear specifications, many resolvers mix the caching and reusing of DNS data introduced via troubleshooting with those in routine operations. This opens a new attack surface that thwarts domain resolution.\nBased on the above finding, we present a novel Denial-of-Service attack named RUC, which turns DNSSEC from a shield into a sword that breaks the resolution of domains under DNSSEC-signed zones. Specifically, adversaries can exploit the troubleshooting mechanism of DNSSEC to inject forged data into the resolver cache. In subsequent routine resolutions, the resolver continuously reuses the unvalidated data, leading to persistent DNSSEC validation failure. Due to the unrestricted TTL of the unvalidated caches, a single injection can cause a resolution outage lasting over 24 hours. Our Internet-wide measurements reveal that RUC affects mainstream DNS software, public DNS services and DNSSEC-compliant open resolvers. After disclosure, BIND, Cloudflare and OpenDNS have acknowledged the vulnerabilities and patched based on our suggestions. Our work calls for formal guidelines on handling troubleshooting data in DNSSEC."
  },
  {
    "id": 3757,
    "year": 2025,
    "title": "POPS: From History to Mitigation of DNS Cache Poisoning Attacks",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/afek",
    "abstract": "We present a novel yet simple and comprehensive DNS cache POisoning Prevention System (POPS), designed to integrate as a module in Intrusion Prevention Systems (IPS). POPS addresses statistical DNS poisoning attacks-documented from 2002 to the present-and offers robust protection against similar future threats. It comprises a detection module, which employs three simple rules, and a mitigation module that leverages the TC flag in the DNS header to enhance security. Once activated, the mitigation module has zero false positives or negatives, correcting any such errors on the side of the detection module. Thus, the detection module is allowed to err on the false positive side while minimizing false negatives.\nWe first analyze POPS against historical DNS services and attacks, showing that it would have mitigated all network-based statistical poisoning attacks. We then simulate POPS on traffic benchmarks (PCAPs), incorporating current potential network-based statistical poisoning attacks, and benign PCAPs; the simulated attacks still succeed with a probability of 0.0076%. This occurs because five malicious packets go through before POPS detects the attack and activates the mitigation module. In addition, POPS completes its task using only 20%–50% of the time required by other tools (e.g., Suricata or Snort), and after examining just 5%–10% as many packets. It successfully detects DNS cache poisoning attacks-including fragmentation-based variants-that Suricata and Snort consistently miss, highlighting POPS's superiority."
  },
  {
    "id": 3758,
    "year": 2025,
    "title": "DNS FLaRE: A Flush-Reload Attack on DNS Forwarders",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/moav",
    "abstract": "In this paper, we present DNS FLaRE, a DNS cache-based timing side-channel attack that allows an attacker to accurately infer the times at which a user visits specific websites. We demonstrate the attack on DNS forwarders, a widely used component of the DNS infrastructure that acts as an intermediary cache between DNS clients and recursive resolvers. The threat model assumes only that the victim is tricked into visiting a malicious website. We show that the attack can accurately infer the times at which a user visits specific websites by exploiting discrepancies in the DNS resolution times of a domain, depending on whether it is in the forwarder cache or not. Furthermore, when targeting IoT devices, the attack can infer when certain events were taking place at an IoT device. This is enabled by observing IoT related DNS resolution discrepancies by a browser in the same household. The attack facilitates sophisticated phishing attacks, IoT device detection and profiling and other potential privacy implications."
  },
  {
    "id": 3759,
    "year": 2025,
    "title": "Lemon: Network-Wide DDoS Detection with Routing-Oblivious Per-Flow Measurement",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/wu-wenhao",
    "abstract": "Network-wide DDoS (Distributed Denial-of-Service) detection enables early attack detection and mitigates victim losses. However, unpredictable routing of DDoS traffic will invalidate the network administrator's prior knowledge of the network topology, causing existing sketch-based measurement systems to suffer from packet over-counting and processing stage mis-allocating issues. To address this gap, we propose Lemon, a routing-oblivious, resource-friendly, and scalable DDoS detection system that provides accurate detection of DDoS attacks without any assumption on the traffic routing. Specifically, we design a novel data structure (Lemon sketch) that supports over-counting-free and mis-allocating-free measurements in the data plane. Lemon control plane aggregates Lemon sketches from measurement points and leverages per-flow level network-wide measurement results for DDoS attack detection and victim identification. We implement Lemon in both software switch (Bmv2) and programmable switch hardware (Tofino). The evaluation results show that Lemon can achieve consistently high accuracy for DDoS detection in various topology and traffic distribution configurations."
  },
  {
    "id": 3760,
    "year": 2025,
    "title": "Assessing the Aftermath: the Effects of a Global Takedown against DDoS-for-hire Services",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/vu",
    "abstract": "Law enforcement and private-sector partners have in recent years conducted various interventions to disrupt the DDoS-for-hire market. Drawing on multiple quantitative datasets, including web traffic and ground-truth visits to seized websites, millions of DDoS attack records from academic, industry, and self-reported statistics, along with chats on underground forums and Telegram channels, we assess the effects of an ongoing global intervention against DDoS-for-hire services since December 2022. This is the most extensive booter takedown to date conducted, combining targeting infrastructure with digital influence tactics in a concerted effort by law enforcement across several countries with two waves of website takedowns and the use of deceptive domains. We found over half of the seized sites in the first wave returned within a median of one day, while all booters seized in the second wave returned within a median of two days. Re-emerged booter domains, despite closely resembling old ones, struggled to attract visitors (80–90% traffic reduction). While the first wave cut the global DDoS attack volume by 20–40% with a statistically significant effect specifically on UDP-based DDoS attacks (commonly attributed to booters), the impact of the second wave appeared minimal. Underground discussions indicated a cumulative impact, leading to changes in user perceptions of safety and causing some operators to leave the market. Despite the extensive intervention efforts, all DDoS datasets consistently suggest that the illicit market is fairly resilient, with an overall short-lived effect on the global DDoS attack volume lasting for at most only around six weeks."
  },
  {
    "id": 3761,
    "year": 2025,
    "title": "BGP Vortex: Update Message Floods Can Create Internet Instabilities",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/stoeger",
    "abstract": "The Border Gateway Protocol (BGP), while essential for Internet connectivity, faces many stability and convergence challenges in today's evolving routing ecosystem.\nIn this paper, we present the discovery of the BGP Vortex, a configuration where just three legitimate BGP UPDATE messages can trigger persistent instability. We demonstrate that this vulnerability can be weaponized as an attack vector, potentially causing widespread Internet connectivity issues through router overload and forwarding loops. Crucially, a BGP Vortex cannot be prevented by existing security mechanisms such as BGPSEC or RPKI, because the protocol messages involved are legitimate. All major router implementations we could experiment with are susceptible to this threat. \nAt its root, the BGP Vortex is caused by standards-compliant BGP extensions—BGP Communities in this case—that allow the modification of route preferences for traffic engineering purposes. Therefore, to aid the mitigation of this attack as well as its potential future variations, we propose a framework to determine which BGP extensions are problematic, and which are safe to deploy. Our findings highlight the need to carefully balance network operators' traffic engineering capabilities with routing stability requirements."
  },
  {
    "id": 3762,
    "year": 2025,
    "title": "ImpROV: Measurement and Practical Mitigation of Collateral Damage in RPKI Route Origin Validation",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/li-weitong",
    "abstract": "The Resource Public Key Infrastructure (RPKI) enhances Internet routing security. RPKI are effective only when routers employ them to validate and filter invalid BGP announcements, a process known as Route Origin Validation (ROV). However, the partial deployment of ROV has led to the phenomenon of collateral damage, where even ROV-enabled ASes can inadvertently direct traffic to incorrect origins if subsequent hops fail to perform proper validation.\nIn this paper, we conduct the first comprehensive study to measure the extent of collateral damage in the real world. Our analysis reveals that a staggering 85.6% of RPKI-invalid announcements are vulnerable to collateral damage attacks and 34% of ROV-enabled ASes are still susceptible to collateral damage attacks. To address this critical issue, we introduce ImpROV, which detects and avoids next hops that are likely to cause collateral damage for a specific RPKI-invalid prefix; our approach operates without affecting other IP address spaces on the data plane that are not impacted by this collateral damage.\nOur extensive evaluations show that ImpROV can reduce the hijack success ratio for most ASes that deployed ROV, while only introduce less than 3% and 4% of Memory and CPU overhead."
  },
  {
    "id": 3763,
    "year": 2025,
    "title": "SoK: An Introspective Analysis of RPKI Security",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/mirdita",
    "abstract": "The Resource Public Key Infrastructure (RPKI) is the main mechanism to protect inter-domain routing with BGP from prefix hijacks. It has already been widely deployed by large providers and the adoption rate is getting to a critical point. Almost half of all the global prefixes are now covered by RPKI and measurements show that 27% of networks are already using RPKI to validate BGP announcements. Over the past 10 years, there has been much research effort in RPKI, analyzing different facets of the protocol, such as software vulnerabilities, robustness of the infrastructure or the proliferation of RPKI validation. In this work, we compile the first systemic overview of the vulnerabilities and misconfigurations in RPKI and quantify the security landscape of the global RPKI deployments based on our measurements and analysis. Our study discovers that 56% of the global RPKI validators suffer from at least one documented vulnerability. We also do a systematization of knowledge for existing RPKI security research and complement the existing knowledge with novel measurements in which we discover new trends in availability of RPKI repositories, and their communication patterns with the RPKI validators. We weave together the results of existing research and our study, to provide a comprehensive tableau of vulnerabilities, their sources, and to derive future research paths necessary to prepare RPKI for full global deployment."
  },
  {
    "id": 3764,
    "year": 2025,
    "title": "Onions Got Puzzled: On the Challenges of Mitigating Denial-of-Service Problems in Tor Onion Services",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/lee",
    "abstract": "Denial-of-service (DoS) attacks present significant challenges for Tor onion services, where strict anonymity requirements render conventional mitigation strategies inapplicable. In response, the Tor community has recently revived the client puzzle idea in an official update to address real-world DoS attacks, leading to its adoption by several major onion services. In this paper, we uncover a critical vulnerability in the current puzzle system in Tor through a novel family of attacks, dubbed OnionFlation. The proposed attacks artificially inflate the required puzzle difficulty for all clients without causing noticeable congestion at the targeted service, rendering any existing onion service largely unusable at an attack cost of a couple of dollars per hour. Our ethical evaluation on the live Tor network demonstrates the impact of these attacks, which we have reported to the Tor Project and received acknowledgment. Our analysis reveals an undesirable trade-off in the client puzzle mechanism, which is the root cause of the discovered vulnerability, that forces the Tor onion system to choose between inflation resistance and congestion resistance, but not both. We offer practical guidance for Tor onion services aimed at balancing the mitigation of these attacks."
  },
  {
    "id": 3765,
    "year": 2025,
    "title": "We Have a Package for You! A Comprehensive Analysis of Package Hallucinations by Code Generating LLMs",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/spracklen",
    "abstract": "The reliance of popular programming languages such as Python and JavaScript on centralized package repositories and open-source software, combined with the emergence of code-generating Large Language Models (LLMs), has created a new type of threat to the software supply chain: package hallucinations. These hallucinations, which arise from fact-conflicting errors when generating code using LLMs, represent a novel form of package confusion attack that poses a critical threat to the integrity of the software supply chain. This paper conducts a rigorous and comprehensive evaluation of package hallucinations across different programming languages, settings, and parameters, exploring how a diverse set of models and configurations affect the likelihood of generating erroneous package recommendations and identifying the root causes of this phenomenon. Using 16 popular LLMs for code generation and two unique prompt datasets, we generate 576,000 code samples in two programming languages that we analyze for package hallucinations. Our findings reveal that that the average percentage of hallucinated packages is at least 5.2% for commercial models and 21.7% for open-source models, including a staggering 205,474 unique examples of hallucinated package names, further underscoring the severity and pervasiveness of this threat. To overcome this problem, we implement several hallucination mitigation strategies and show that they are able to significantly reduce the number of package hallucinations while maintaining code quality. Our experiments and findings highlight package hallucinations as a persistent and systemic phenomenon while using state-of-the-art LLMs for code generation, and a significant challenge which deserves the research community's urgent attention."
  },
  {
    "id": 3766,
    "year": 2025,
    "title": "Mirage in the Eyes: Hallucination Attack on Multi-modal Large Language Models with Only Attention Sink",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/wang-yining",
    "abstract": "Fusing visual understanding into language generation, Multi-modal Large Language Models (MLLMs) are revolutionizing visual-language applications. Yet, these models are often plagued by the hallucination problem, which involves generating inaccurate objects, attributes, and relationships that do not match the visual content. In this work, we delve into the internal attention mechanisms of MLLMs to reveal the underlying causes of hallucination, exposing the inherent vulnerabilities in the instruction-tuning process.\nWe propose a novel hallucination attack against MLLMs that exploits attention sink behaviors to trigger hallucinated content with minimal image-text relevance, posing a significant threat to critical downstream applications. Distinguished from previous adversarial methods that rely on fixed patterns, our approach generates dynamic, effective, and highly transferable visual adversarial inputs, without sacrificing the quality of model responses. Comprehensive experiments on 6 prominent MLLMs demonstrate the efficacy of our attack in compromising black-box MLLMs even with extensive mitigating mechanisms, as well as the promising results against cutting-edge commercial APIs, such as GPT-4o and Gemini 1.5. Our code is available at https://huggingface.co/RachelHGF/Mirage-in-the-Eyes."
  },
  {
    "id": 3767,
    "year": 2025,
    "title": "\"I Cannot Write This Because It Violates Our Content Policy\": Understanding Content Moderation Policies and User Experiences in Generative AI Products",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/gao-lan",
    "abstract": "While recent research has focused on developing safeguards for generative AI (GAI) model-level content safety, little is known about how content moderation to prevent malicious content performs for end-users in real-world GAI products. To bridge this gap, we investigated content moderation policies and their enforcement in GAI online tools—consumer-facing web-based GAI applications. We first analyzed content moderation policies of 14 GAI online tools. While these policies are comprehensive in outlining moderation practices, they usually lack details on practical implementations and are not specific about how users can aid in moderation or appeal moderation decisions. Next, we examined user-experienced content moderation successes and failures through Reddit discussions on GAI online tools. We found that although moderation systems succeeded in blocking malicious generations pervasively, users frequently experienced frustration in failures of both moderation systems and user support after moderation. Based on these findings, we suggest improvements for content moderation policy and user experiences in real-world GAI products."
  },
  {
    "id": 3768,
    "year": 2025,
    "title": "Are CAPTCHAs Still Bot-hard? Generalized Visual CAPTCHA Solving with Agentic Vision Language Model",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/teoh",
    "abstract": "Visual CAPTCHAs, such as reCAPTCHA v2, hCaptcha, and GeeTest, are mainstream security mechanisms to deter bots online, based on the assumption that their visual challenges are bot-hard but human-friendly. While many deep-learning based solvers have been designed and trained to solve a specific type of visual challenge in a CAPTCHA, vendors can easily switch to out-of-distribution visual challenge of the same type or even new types of challenge with very low cost. However, the emergence of general-purpose AI models (e.g., ChatGPT) challenges the bot-hard assumption of existing visual challenges, potentially compromising the reliability of visual CAPTCHAs.\nIn this work, we report the first generalized visual CAPTCHA solver, Halligan, built upon the state-of-the-art vision language model (VLM), which can effectively solve unseen visual challenges in CAPTCHAs without making any adaptation. Our rationale lies in that a visual challenge can be reduced to a search problem where (i) its instruction is transformed into an optimization objective and (ii) its body is transformed into a search space for the objective. With well designed prompts built upon known VLMs, the transformation can be generalized to unseen visual challenges. Our extensive experiments show that Halligan is a game-changer to the known practice of adopting visual CAPTCHAs, which achieves a solving rate of 60.7% on 2,600 challenges belonging to 26 types of visual CAPTCHAs. Further, we use Halligan to infiltrate human-driven CAPTCHA farms, achieving an average solving rate of 70.6% on previously unseen visual challenges from CAPTCHAs in the wild over a 30-day period. Based on the experimental results, we further shed light on puzzle-less anti-bot alternatives in this era."
  },
  {
    "id": 3769,
    "year": 2025,
    "title": "Make Agent Defeat Agent: Automatic Detection of Taint-Style Vulnerabilities in LLM-based Agents",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/liu-fengyu",
    "abstract": "Large Language Models (LLMs) have revolutionized software development, enabling the creation of AI-powered applications known as LLM-based agents. However, recent studies reveal that LLM-based agents are highly susceptible to taint-style vulnerabilities, which allow malicious prompts to exploit security-sensitive operations. These vulnerabilities pose severe threats to the security of agents, potentially allowing attackers to take over the entire agent remotely.\nIn this paper, we propose a novel directed greybox fuzzing approach, called AgentFuzz, the first fuzzing framework for detecting taint-style vulnerabilities in LLM-based agents. AgentFuzz consists of three key phases. First, AgentFuzz leverages the LLM to generate functionality-specific seed prompts in the form of natural language. Second, AgentFuzz utilizes a multifaceted feedback design to assess seed quality from both semantic and distance levels, prioritizing seeds with higher quality. Finally, AgentFuzz employs functionality and argument mutator to refine seeds and trigger vulnerabilities effectively. In our evaluation against 20 widely-used open-source agent applications, AgentFuzz identified 34 high-risk 0-day vulnerabilities, achieving 33 times higher precision than the state-of-the-art approach. These vulnerabilities encompass serious threats like code injection, impacting 14 open-source agents, with 7 of them having over 10,000 stars on GitHub. To date, 23 CVE IDs have been assigned."
  },
  {
    "id": 3770,
    "year": 2025,
    "title": "Machine Against the RAG: Jamming Retrieval-Augmented Generation with Blocker Documents",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/shafran",
    "abstract": "Retrieval-augmented generation (RAG) systems respond to queries by retrieving relevant documents from a knowledge database and applying an LLM to the retrieved documents. We demonstrate that RAG systems that operate on databases with untrusted content are vulnerable to denial-of-service attacks we call jamming. An adversary can add a single \"blocker\" document to the database that will be retrieved in response to a specific query and result in the RAG system not answering this query, ostensibly because it lacks relevant information or because the answer is unsafe.\nWe describe and measure the efficacy of several methods for generating blocker documents, including a new method based on black-box optimization. Our method (1) does not rely on instruction injection, (2) does not require the adversary to know the embedding or LLM used by the target RAG system, and (3) does not employ an auxiliary LLM.\nWe evaluate jamming attacks on several embeddings and LLMs and demonstrate that the existing safety metrics for LLMs do not capture their vulnerability to jamming. We then discuss defenses against blocker documents."
  },
  {
    "id": 3771,
    "year": 2025,
    "title": "Topic-FlipRAG: Topic-Orientated Adversarial Opinion Manipulation Attacks to Retrieval-Augmented Generation Models",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/gong-yuyang",
    "abstract": "Retrieval-Augmented Generation (RAG) systems based on Large Language Models (LLMs) have become essential for tasks such as question answering and content generation. However, their increasing impact on public opinion and information dissemination has made them a critical focus for security research due to inherent vulnerabilities. Previous studies have predominantly addressed attacks targeting factual or single-query manipulations. In this paper, we address a more practical scenario: topic-oriented adversarial opinion manipulation attacks on RAG models, where LLMs are required to reason and synthesize multiple perspectives, rendering them particularly susceptible to systematic knowledge poisoning. Specifically, we propose Topic-FlipRAG, a two-stage manipulation attack pipeline that strategically crafts adversarial perturbations to influence opinions across related queries. This approach combines traditional adversarial ranking attack techniques and leverages the extensive internal relevant knowledge and reasoning capabilities of LLMs to execute semantic-level perturbations. Experiments show that the proposed attacks effectively shift the opinion of the model's outputs on specific topics, significantly impacting users' information perception. Current mitigation methods cannot effectively defend against such attacks, highlighting the necessity for enhanced safeguards for RAG systems, and offering crucial insights for LLM security research."
  },
  {
    "id": 3772,
    "year": 2025,
    "title": "PoisonedRAG: Knowledge Corruption Attacks to Retrieval-Augmented Generation of Large Language Models",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/zou-poisonedrag",
    "abstract": "Large language models (LLMs) have achieved remarkable success due to their exceptional generative capabilities. Despite their success, they also have inherent limitations such as a lack of up-to-date knowledge and hallucination. Retrieval-Augmented Generation (RAG) is a state-of-the-art technique to mitigate these limitations. The key idea of RAG is to ground the answer generation of an LLM on external knowledge retrieved from a knowledge database. Existing studies mainly focus on improving the accuracy or efficiency of RAG, leaving its security largely unexplored. We aim to bridge the gap in this work. We find that the knowledge database in a RAG system introduces a new and practical attack surface. Based on this attack surface, we propose PoisonedRAG, the first knowledge corruption attack to RAG, where an attacker could inject a few malicious texts into the knowledge database of a RAG system to induce an LLM to generate an attacker-chosen target answer for an attacker-chosen target question. We formulate knowledge corruption attacks as an optimization problem, whose solution is a set of malicious texts. Depending on the background knowledge (e.g., black-box and white-box settings) of an attacker on a RAG system, we propose two solutions to solve the optimization problem, respectively. Our results show PoisonedRAG could achieve a 90% attack success rate when injecting five malicious texts for each target question into a knowledge database with millions of texts. We also evaluate several defenses and our results show they are insufficient to defend against PoisonedRAG, highlighting the need for new defenses."
  },
  {
    "id": 3773,
    "year": 2025,
    "title": "TracLLM: A Generic Framework for Attributing Long Context LLMs",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/wang-yanting",
    "abstract": "Long context large language models (LLMs) are deployed in many real-world applications such as RAG, agent, and broad LLM-integrated applications. Given an instruction and a long context (e.g., documents, PDF files, webpages), a long context LLM can generate an output grounded in the provided context, aiming to provide more accurate, up-to-date, and verifiable outputs while reducing hallucinations and unsupported claims. This raises a research question: how to pinpoint the texts (e.g., sentences, passages, or paragraphs) in the context that contribute most to or are responsible for the generated output by an LLM? This process, which we call context traceback, has various real-world applications, such as 1) debugging LLM-based systems, 2) conducting post-attack forensic analysis for attacks (e.g., prompt injection attack, knowledge corruption attacks) to an LLM, and 3) highlighting knowledge sources to enhance the trust of users towards outputs generated by LLMs. When applied to context traceback for long context LLMs, existing feature attribution methods such as Shapley have sub-optimal performance and/or incur a large computational cost. In this work, we develop TracLLM , the first generic context traceback framework tailored to long context LLMs. Our framework can improve the effectiveness and efficiency of existing feature attribution methods. To improve the efficiency, we develop an informed search based algorithm in TracLLM. We also develop contribution score ensemble/denoising techniques to improve the accuracy of TracLLM. Our evaluation results show TracLLM can effectively identify texts in a long context that lead to the output of an LLM. Our code and data are at: https://github.com/Wang-Yanting/TracLLM."
  },
  {
    "id": 3774,
    "year": 2025,
    "title": "Sound of Interference: Electromagnetic Eavesdropping Attack on Digital Microphones Using Pulse Density Modulation",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/onishi",
    "abstract": "We introduce a novel electromagnetic (EM) side-channel attack that allows for acoustic eavesdropping on electronic devices. This method specifically targets modern digital microelectromechanical systems (MEMS) microphones, which transmit captured audio via pulse-density modulation (PDM), that translate the analog sound signal into the density of output pulses in the digital domain. We discover that each harmonic of these digital pulses retains acoustic information, allowing the original audio to be retrieved through simple FM demodulation using standard radio receivers. An attacker can exploit this phenomenon to capture what the victim microphone hears remotely without installing malicious software or tampering with the device. We verify the vulnerability presence by conducting real-world evaluation on several PDM microphones and electronic devices, including laptops and smart speakers. For example, we demonstrate that the attack achieves up to 94.2% accuracy in recognizing spoken digits, up to 2 meters from a victim laptop located behind a 25 cm concrete wall. We also evaluate the attacker capability to eavesdrop on speech using popular speech-to-text APIs (e.g., OpenAI) not trained on EM traces, achieving a maximum of 14% transcription error rate in recovering the Harvard Sentences dataset. We further demonstrate that similar accuracy can be achieved with a cheap and stealthy antenna made out of copper tape. We finally discuss the limited effectiveness of current defenses such as resampling, and we propose a new hardware defense based on clock randomization."
  },
  {
    "id": 3775,
    "year": 2025,
    "title": "TimeTravel: Real-time Timing Drift Attack on System Time Using Acoustic Waves",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/liu-jianshuo",
    "abstract": "Real-time Clock (RTC) has been widely used in various real-time systems to provide precise system time. In this paper, we reveal a new security vulnerability of the RTC circuit, where the internal storage time or timestamp can be arbitrarily modified forward or backward. The security threat of dynamic modifications of system time caused by this vulnerability is called TimeTravel. Based on acoustic resonance and piezoelectric effects, TimeTravel applies acoustic guide waves to the quartz crystal, thereby adjusting the characteristics of the oscillating signal transmitted into the RTC circuit. By manipulating the parameters of acoustic waves, TimeTravel can accelerate or decelerate the timing speed of system time at an adjustable rate, resulting in the relative drift of the timing, which can pose serious safety threats. To assess the severity of TimeTravel, we examine nine modules and two commercial devices under the RTC circuit. The experimental results show that TimeTravel can drift system time forward and backward at a chosen speed with a maximum 93% accuracy. Our analysis further shows that TimeTravel can maintain an attack success rate of no less than 77% under environments with typical obstacle items."
  },
  {
    "id": 3776,
    "year": 2025,
    "title": "DiskSpy: Exploring a Long-Range Covert-Channel Attack via mmWave Sensing of μm-level HDD Vibrations",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/xu-weiye",
    "abstract": "An air-gapped environment is widely regarded as a secure measure against the leakage of sensitive information, as it is physically isolated from insecure external networks. This paper presents a new covert-channel attack named DiskSpy, which reveals the risk of secretly sending sensitive information from air-gapped environments by modulating hard disk vibrations. In particular, DiskSpy leverages the vibrations of commonly used storage devices, hard disk drives (HDDs), in air-gapped computers to encode sensitive information. It then employs millimeter-wave (mmWave) to sense these vibrations and decode the underlying data. In practice, HDD vibrations are extremely weak and mmWave signals suffer significant power attenuation in long-distance propagation. To realize a practical attack at a long distance, we develop a novel mmWave-based long-range µm-level vibration sensing technique to push the limit of mmWave sensing. We implement DiskSpy with commercial off-the-shelf (COTS) mmWave radars and conduct extensive experiments. The experimental results show that even at a long attack range of 22m, DiskSpy can send secret information to a remote mmWave radar at 20bps with a BER lower than 1.2%. More importantly, DiskSpy has no restriction on the mounting manner and placement of the HDD, and can launch attacks even in the non-line-of-sight (NLOS) scenarios."
  },
  {
    "id": 3777,
    "year": 2025,
    "title": "HubBub: Contention-Based Side-Channel Attacks on USB Hubs",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/wan",
    "abstract": "Universal Serial Bus (USB) hubs enhance connectivity in modern computers by allowing multiple peripheral devices to share a single upstream port. Common peripherals include external storage devices, network interface cards, cameras, and keyboards. However, when several devices operate simultaneously, bus contention within the USB hub becomes unavoidable. Such contention causes timing variations that can be exploited to leak sensitive information.\nWe identify three types of USB bus contention and design multiple side-channel attacks to infer user activities based on these contentions. These attacks can be launched from a virtual machine, a remote website, or a USB peripheral, as demonstrated in three distinct attack scenarios. By collecting I/O interval data using our probers, we can recover information such as web browsing history, camera-captured activities, and keystrokes with accuracies ranging from 85% to 99%. We evaluated 15 leading USB 3.x external hubs on the market, a USB 2.0 hub, and an internal hub, most of which are vulnerable to HubBub attacks. We have reported our findings to the relevant stakeholders."
  },
  {
    "id": 3778,
    "year": 2025,
    "title": "Lost in Translation: Enabling Confused Deputy Attacks on EDA Software with TransFuzz",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/solt",
    "abstract": "We introduce MIRTL, a confused deputy attack on EDA software such as simulators or synthesizers. MIRTL relies on gadgets that exploit vulnerabilities in the EDA software's translation of RTL to lower-level representations. Invisible to white-box testing and verification methods, MIRTL gadgets harden traditional hardware trojans, enabling unprecedentedly stealthy attacks. To discover translation bugs, our new fuzzer, called TRANSFUZZ, generates randomized RTL designs containing many operators with complex interconnections for triggering translation bugs. The expressiveness of RTL, however, makes the construction of a golden RTL model for detecting deviations due to translation bugs challenging. To address this, TRANSFUZZ relies on comparing signal outputs from multiple RTL simulators for detecting vulnerabilities. TRANSFUZZ uncovers 20 translation vulnerabilities among 31 new bugs (25 CVEs) in four popular open-source EDA applications. We show how MIRTL gadgets harden traditional backdoors against white-box countermeasures and demonstrate a real-world instance of a MIRTL-hardened backdoor in the CVA6 RISC-V core."
  },
  {
    "id": 3779,
    "year": 2025,
    "title": "Automated Discovery of Semantic Attacks in Multi-Robot Navigation Systems",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/yeke",
    "abstract": "Finding collision-free paths is crucial for autonomous multi-robots (AMRs) to complete assigned missions, ranging from search operations to military tasks. To achieve this, AMRs rely on collaborative collision avoidance algorithms. Unfortunately, the robustness of these algorithms against false data injection attacks (FDIAs) remains unexplored. In this paper, we introduce Raven, a tool to identify effective and stealthy semantic attacks (e.g., herding). Effective attacks minimize positional displacement and the number of false data injections by using temporal logic and stochastic optimization techniques. Stealthy attacks remain within sensor noise ranges and maintain spatiotemporal consistency. We evaluate Raven against two state-of-the-art collision avoidance algorithms, ORCA and GLAS. Our results show that a single false data injection impacts multi-robot systems by causing position deviation or even collisions. We evaluate Raven on three testbeds–a numerical simulator, a high-fidelity simulator, and Crazyflie drones. Our results reveal five design flaws in these algorithms and underscore the importance of developing robust defenses against FDIAs. Finally, we propose countermeasures to mitigate the attacks we have uncovered."
  },
  {
    "id": 3780,
    "year": 2025,
    "title": "The Ghost Navigator: Revisiting the Hidden Vulnerability of Localization in Autonomous Driving",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/zhang-junqi",
    "abstract": "Localization is crucial for Autonomous Driving (AD), which serves as a critical foundation impacting the performance of downstream modules. While Multi-Sensor Fusion (MSF) techniques enhance localization accuracy and reliability, the security of fusion-based localization systems has emerged as a major concern. Although existing studies have extensively investigated security aspects of these systems, the impact of vehicle dynamics on the effectiveness of Global Positioning System (GPS) spoofing attacks is persistently overlooked.\nBridging this research gap, we propose the Motion-Sensitive Analysis Framework (MSAF), which focuses on analyzing previously underestimated dynamic behaviors of vehicles. Our investigation demonstrates that two dynamic scenarios, acceleration and high-speed cruising, significantly influence the success rates of GPS spoofing attacks. These scenarios, commonly encountered across driving conditions, exhibit heightened vulnerabilities under MSAF analysis. Building on these insights, we design two dynamics-targeted attack strategies and evaluate them across three testbeds: our simulated framework (MSAF_MSF) and two real-world MSF-based autonomous driving systems (Apollo_MSF and Shenlan_MSF). The results demonstrate a significant attack efficiency improvement by our method: MSAF requires substantially less time to complete attacks compared to the baseline while achieving higher success rates. Code and attack demos are available at https://sites.google.com/view/msaf-attack."
  },
  {
    "id": 3781,
    "year": 2025,
    "title": "NeuroScope: Reverse Engineering Deep Neural Network on Edge Devices using Dynamic Analysis",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/wu-ruoyu",
    "abstract": "The usage of Deep Neural Network (DNN) models in edge devices (e.g., IoT devices) has surged. In this usage scenario, the inference phase of the DNN model is executed by a dedicated, compiled piece of code (i.e., a DNN binary). From the security standpoint, the ability to reverse engineer such binaries (i.e., recovering the original, high-level representation of the implemented DNN) enables several applications, such as stealing DNN models, gray/white-box adversarial machine learning attacks and defenses, and backdoor detection. While a few recent works proposed dedicated approaches to reverse engineer DNN binaries, these approaches are fundamentally limited in the type of DNN binaries they support.\nTo address these limitations, in this paper, we propose NEUROSCOPE, a novel data-driven approach based on dynamic analysis and machine learning to reverse engineer DNN binaries. This compiler-independent and code-feature-free approach enables NEUROSCOPE to support a larger variety of DNN binaries across different DNN compilers and hardware platforms, including binaries implementing DNN models using an interpreter-based approach. We demonstrate NEUROSCOPE's capability by using it to reverse engineer DNN binaries unsupported by previous approaches with high accuracy. Moreover, we showcase how NEUROSCOPE can reverse engineer a proprietary DNN binary compiled with a closed-source compiler and enable gray-box adversarial machine learning attacks."
  },
  {
    "id": 3782,
    "year": 2025,
    "title": "BarraCUDA: Edge GPUs do Leak DNN Weights",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/horvath",
    "abstract": "Over the last decade, applications of neural networks have spread to every aspect of our lives. A large number of companies base their businesses on building products that use neural networks for tasks such as face recognition, machine translation, and self-driving cars. Much of the intellectual property underpinning these products is encoded in the exact parameters of the neural networks. Consequently, protecting these is of utmost priority to businesses. At the same time, many of these products need to operate under a strong threat model, in which the adversary has unfettered physical control of the product. In this work, we present BarraCUDA, a novel attack on general-purpose Graphics Processing Units (GPUs) that can extract parameters of neural networks running on the popular Nvidia Jetson devices. BarraCUDA relies on the observation that the convolution operation, used during inference, must be computed as a sequence of partial sums, each leaking one or a few parameters. Using correlation electromagnetic analysis with these partial sums, BarraCUDA can recover parameters of real-world convolutional neural networks."
  },
  {
    "id": 3783,
    "year": 2025,
    "title": "CollisionRepair: First-Aid and Automated Patching for Storage Collision Vulnerabilities in Smart Contracts",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/pan-yu",
    "abstract": "Storage collision vulnerabilities, a significant security risk in upgradeable smart contracts, often arise when a user-facing proxy contract and a backend logic contract share storage space. While static analysis techniques can detect such issues, they often over-approximate program states, leading to false positives and requiring developers to manually verify each issue, giving attackers time to exploit any overlooked vulnerabilities. To address this, we propose CollisionRepair, an automated patching technique for mitigating storage collision risks. CollisionRepair monitors storage access sequences between proxy and logic contracts by defining an \"ownership\" property for storage locations. It then replays historical transactions to recover existing storage ownership, ensuring the patched code aligns with the current state. A gas impact-aware differential analysis is applied to verify the patch, distinguishing genuine behavioral changes from variations caused by gas usage. Our evaluation on 12,526 real-world vulnerable upgradeable contracts shows that CollisionRepair effectively detects and mitigates storage collision attacks without interfering with normal contract operations."
  },
  {
    "id": 3784,
    "year": 2025,
    "title": "On the Atomicity and Efficiency of Blockchain Payment Channels",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/wu-di",
    "abstract": "Payment channels are a promising solution for scaling cryptocurrency payments by enabling secure off-chain transactions. However, existing protocols, including the widely-deployed Lightning Network and the state-of-the-art Sleepy Channels, suffer from a fundamental flaw: non-atomic state transitions can result in multiple valid states coexisting, introducing race conditions and ambiguity in protocol execution. This ambiguity can be exploited to cause unexpected financial loss. We first formalize existing protocols into a common paradigm and prove that such flaws are inherent to their design, preventing balance security. To overcome this, we propose an atomic paradigm that guarantees atomic state transitions while preserving all desired functionality. Based on this paradigm, we design Ultraviolet, the first payment channel protocol that achieves atomicity by introducing the novel Resolve Mechanism. We formally prove that Ultraviolet satisfies balance security under the Universal Composability framework. In addition, Ultraviolet reduces the number of required messages per transaction by half compared to existing solutions. Our evaluation across multiple regions shows that Ultraviolet reduces latency by 37% and 52% compared to the Lightning Network and Sleepy Channels, respectively, and achieves comparable throughput to the Lightning Network and 2× that of Sleepy Channels."
  },
  {
    "id": 3785,
    "year": 2025,
    "title": "Parallelizing Universal Atomic Swaps for Multi-Chain Cryptocurrency Exchanges",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/xiao-danlei",
    "abstract": "Universal atomic swap is an emerging technique for secure cryptocurrency exchanges across diverse blockchains, eliminating the need for custom scripting language support from blockchains. While existing schemes primarily focus on exchanges among two users, extending these to multiple users across multiple blockchains incurs significant overheads due to the need for performing multiple two-party swaps serially. An intuitive insight is to parallelize the universal processes, but this idea still faces two technical challenges: (i) avoid asset theft during parallel asset locking; (ii) ensure atomicity by preventing partial execution of transactions with a uniform refund time used to avoid asset deadlock in parallel.\nIn this paper, we present ParaSwap, the first framework to parallelize universal atomic swaps for cryptocurrency exchanges among multiple users across multiple blockchains. We replace the serial multiple two-party swaps with a concurrent mechanism, where each participant concurrently locks and withdraws coins, achieving parallel execution. To prevent asset theft, the necessary witness for swaps is collaboratively determined by all participants. Then we introduce a novel re-lock approach to ensure atomicity with a uniform refund time, allowing participants to re-lock their assets to new addresses when the remaining time is insufficient to complete their withdrawal. Notably, ParaSwap employs adaptor signatures and verifiable timed discrete logarithm (VTD) technology, relying only on the bare minimum ability of blockchain to verify transaction signatures. We implement ParaSwap on four public blockchain test networks: Bitcoin, Ethereum, Avalanche, and Binance Smart Chain. Our evaluation demonstrates that ParaSwap reduces the exchange time complexity from O(n) to O(1), where n is the number of participants, and lowers gas costs by 26.2x to 46.8x, compared to existing methods."
  },
  {
    "id": 3786,
    "year": 2025,
    "title": "Automated Soundness and Completeness Vetting of Polygon zkEVM",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/peng-xinghao",
    "abstract": "Zero-knowledge rollups have emerged as popular layer 2 scaling solutions for blockchains. Polygon zkEVM, a leading deployment of zk rollups, leverages non-deterministic execution to derive free inputs from an unconstrained command evaluator when implementing the zkEVM. This mechanism significantly simplifies the design of zkEVM and enhances the performance of proof generation. However, it introduces the challenge of requiring developers to define constraints for free inputs, a task that demands strong mathematical expertise and is prone to errors. As a component of the layer-2 infrastructure, the zkEVM's vulnerabilities could lead to powerful attacks. However, despite their importance, the security of free inputs in zkEVM remains unexplored.\nIn this paper, we present the first systematic exploration of free inputs in Polygon zkEVM. Our study reveals critical soundness and completeness issues with them. In particular, we uncover a new attack surface, termed the dual execution path attack, which targets unsound implementations of free inputs and can lead to chain splits. Moreover, we design the first tool, FreeVer, which facilitates the verification of the soundness and completeness of free inputs with formal semantics. Additionally, it automatically generates formal specifications for correct constraints by constructing prover state graphs that model both the behaviors of malicious and honest provers. It then uses the states from the honest prover as specifications to assist in the verification of states from the malicious one. FreeVer also adopts optimization strategies to reduce the complexity of constraints for effective verification. Our evaluation results show that FreeVer can correctly identify all previously disclosed free input related vulnerabilities and detect 7 new vulnerabilities in Polygon zkEVM. All detected bugs are submitted through the bug bounty program and are confirmed as high impact vulnerabilities."
  },
  {
    "id": 3787,
    "year": 2025,
    "title": "Does Finality Gadget Finalize Your Block? A Case Study of Binance Consensus",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/li-rujia",
    "abstract": "This paper studies the consensus mechanism of BNB smart chain (BSC)—a top-ranked blockchain platform developed by Binance. Since mid 2023, BSC has integrated a fast finality (FF) mechanism into its system. The FF mechanism is borrowed from the friendly finality gadget (FFG) by Ethereum Casper. The idea is to allow validators to vote for blocks and then agree on their order. Such an approach shares some similarities with the consensus mechanism in Byzantine fault-tolerant (BFT) protocols (e.g., PBFT and HotStuff). BSC claims that its FF mechanism can finalize blocks in O(1) time, simultaneously reducing latency and improving stability.\nIn this paper, we demonstrate the FF mechanism of BSC is susceptible to attacks. In particular, we provide three different attacks, showing BSC fails to finalize blocks in constant time and may even simply fail to achieve liveness. We validate our results via extensive experimental analysis and meanwhile provide mitigation solutions."
  },
  {
    "id": 3788,
    "year": 2025,
    "title": "Following Devils' Footprint: Towards Real-time Detection of Price Manipulation Attacks",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/zhang-bosi",
    "abstract": "Price manipulation attack is one of the notorious threats in decentralized finance (DeFi) applications, which allows attackers to exchange tokens at an extensively deviated price from the market. Existing efforts usually rely on reactive methods to identify such kind of attacks after they have happened, e.g., detecting attack transactions in the post-attack stage, which cannot mitigate or prevent price manipulation attacks timely. From the perspective of attackers, they usually need to deploy attack contracts in the pre-attack stage. Thus, if we can identify these attack contracts in a proactive manner, we can raise alarms and mitigate the threats. With the core idea in mind, in this work, we shift our attention from the victims to the attackers. Specifically, we propose SMARTCAT, a novel approach for identifying price manipulation attacks in the pre-attack stage proactively. For generality, it conducts analysis on bytecode and does not require any source code and transaction data. For accuracy, it depicts the control- and data-flow dependency relationships among function calls into a token flow graph. For scalability, it filters out those suspicious paths, in which it conducts inter-contract analysis as necessary. To this end, SMARTCAT can pinpoint attacks in real time once they have been deployed on a chain. The evaluation results illustrate that SMARTCAT significantly outperforms existing baselines with 91.6% recall and ∼100% precision. Moreover, SMARTCAT also uncovers 616 attack contracts in-the-wild, accounting for $9.25M financial losses, with only 19 cases publicly reported. By applying SMARTCAT as a real-time detector in Ethereum and Binance Smart Chain, it has raised 14 alarms 99 seconds after the corresponding deployment on average. These attacks have already led to $641K financial losses, and seven of them are still waiting for their ripe time."
  },
  {
    "id": 3789,
    "year": 2025,
    "title": "Recover from Excessive Faults in Partially-Synchronous BFT SMR",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/gong-tiantian",
    "abstract": "Byzantine fault-tolerant (BFT) state machine replication (SMR) protocols form the basis of modern blockchains as they maintain a consistent state across all blockchain nodes while tolerating a bounded number of Byzantine faults. We analyze BFT SMR in the excessive fault setting where the actual number of Byzantine faults surpasses a protocol's tolerance.\nWe start by devising the very first repair algorithm for linearly chained and quorum-based partially synchronous SMR to recover from faulty states caused by excessive faults. Such a procedure can be realized using any commission fault detection module—an algorithm that identifies the faulty replicas without falsely locating any correct replica. We achieve this with a slightly weaker liveness guarantee, as the original security notion is impossible to satisfy given excessive faults.\nWe implement recoverable HotStuff in Rust. The throughput resumes to the normal level (without excessive faults) after recovery routines terminate for 7 replicas and is slightly reduced by leq 4.3% for 30 replicas. On average, it increases the latency by 12.87% for 7 replicas and 8.85% for 30 replicas.\nAside from adopting existing detection modules, we also establish the sufficient condition for a general BFT SMR protocol to allow for complete and sound fault detection when up to (n-2) Byzantine replicas (out of n total replicas) attack safety. We start by providing the first closed-box fault detection algorithm for any SMR protocol without any extra rounds of communication. We then describe open-box instantiations of our fault detection routines in Tendermint and Hotstuff, further reducing the overhead, both asymptotically and concretely."
  },
  {
    "id": 3790,
    "year": 2025,
    "title": "TockOwl: Asynchronous Consensus with Fault and Network Adaptability",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/li-minghang",
    "abstract": "BFT protocols usually have a waterfall-like degradation in performance in the face of crash faults. Some BFT protocols may not experience sudden performance degradation under crash faults. They achieve this at the expense of increased communication and round complexity in fault-free scenarios. In a nutshell, existing protocols lack the adaptability needed to perform optimally under varying conditions.\nWe propose TockOwl, the first asynchronous consensus protocol with fault adaptability. TockOwl features quadratic communication and constant round complexity, allowing it to remain efficient in fault-free scenarios. TockOwl also possesses crash robustness, enabling it to maintain stable performance when facing crash faults. These properties collectively ensure the fault adaptability of TockOwl.\nFurthermore, we propose TockOwl+ that has network adaptability. TockOwl+ incorporates both fast and slow tracks and employs hedging delays, allowing it to achieve low latency comparable to partially synchronous protocols without waiting for timeouts in asynchronous environments. Compared to the latest dual-track protocols, the slow track of TockOwl+ is simpler, implying shorter latency in fully asynchronous environments."
  },
  {
    "id": 3791,
    "year": 2025,
    "title": "Thunderdome: Timelock-Free Rationally-Secure Virtual Channels",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/avarikioti",
    "abstract": "Payment channel networks (PCNs) offer a promising solution to address the limited transaction throughput of deployed blockchains. However, several attacks have recently been proposed that stress the vulnerability of PCNs to timelock and censoring attacks. To address such attacks, we introduce Thunderdome, the first timelock-free PCN. Instead, Thunderdome leverages the design rationale of virtual channels to extend a timelock-free payment channel primitive, thereby enabling multi-hop transactions without timelocks. Previous works either utilize timelocks or do not accommodate transactions between parties that do not share a channel.\nAt its core, Thunderdome relies on a committee of non-trusted watchtowers, known as wardens, who ensure that no honest party loses funds, even when offline, during the channel closure process. We introduce tailored incentive mechanisms to ensure that all participants follow the protocol's correct execution. Besides a traditional security proof that assumes an honest majority of the committee, we conduct a formal game-theoretic analysis to demonstrate the security of Thunderdome when all participants, including wardens, act rationally. We implement a proof of concept of Thunderdome on Ethereum to validate its feasibility and evaluate its costs. Our evaluation shows that deploying Thunderdome, including opening the underlying payment channel, costs approximately $15 (0.0089 ETH), while the worst-case cost for closing a channel is about $7 (0.004 ETH)."
  },
  {
    "id": 3792,
    "year": 2025,
    "title": "The Doom of Device Drivers: Your Android Device (Most Likely) has N-Day Kernel Vulnerabilities",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/maar-doom",
    "abstract": "Android's security landscape is constantly evolving to counter increasingly sophisticated attacks, with the kernel as a prime focus. Past device compromises required complex exploit chains pivoting to privileged contexts before targeting the kernel. Recently, however, the trend has been to exploit kernel GPU drivers accessible to untrusted apps to bypass privileged pivoting. While significant efforts have been made to secure GPU drivers, the broader risks of untrusted apps compromising Android devices remain underexplored at a large scale.\nIn this paper, we perform the first comprehensive analysis of kernel drivers accessible to untrusted apps on a representative set of 131 Android devices. Using our mostly automated approach to recover access control policies from device firmwares, we identify a significant attack surface beyond GPUs, comprising 11 drivers. From public information about these drivers, such as git repositories, we reconstruct 50 known vulnerabilities, including highly critical issues that allow exploit primitives such as use-after-free and out-of-bounds writes. Our subsequent vulnerability patch inclusion analysis reveals that many of these vulnerabilities remain unpatched, acting as n-days at the time of analysis or for extended periods: More than 59 % of the analyzed devices can be exploited by highly critical n-day vulnerabilities.\nWe uncover novel insights into the disparity in patch timelines and vendor practices. Our findings show that malicious actors can exploit n-day vulnerabilities accessible to untrusted apps, bypassing the need for complex zero-day vulnerabilities. We conclude that urgent action must be taken to improve overall Android security."
  },
  {
    "id": 3793,
    "year": 2025,
    "title": "NASS: Fuzzing All Native Android System Services with Interface Awareness and Coverage",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/mao",
    "abstract": "Compromised or malicious apps remain a primary security concern for Android. As Android tightens its app sandbox and further reduces the kernel's attack surface, native Android system services emerge as a promising target for privilege escalation.\nBugs in these native system services, triggerable from the app sandbox via RPC (Remote Procedure Calls), may facilitate privilege escalation. We identify the attack surface exposed by proprietary native system services and propose NASS, an approach to effectively fuzz proprietary real-world RPC servers to detect bugs triggerable via RPC. NASS addresses the challenge of extracting coverage from complex intertwined real-world RPC servers. Furthermore, NASS leverages our novel technique deserialization-guided interface extraction to recover the RPC interface definition from proprietary RPC servers. NASS' techniques all build on common RPC design principles, which broadly apply to RPC frameworks.\nWe implement NASS for Android's Binder RPC framework. NASS outperforms prior work regarding interface extraction, target exploration and bug finding capabilities, even without access to source code. NASS has identified 12 unique bugs in up-to-date Google, Samsung, Xiaomi, and OnePlus devices, with five CVEs assigned so far."
  },
  {
    "id": 3794,
    "year": 2025,
    "title": "Ariadne: Navigating through the Labyrinth of Data-Driven Customization Inconsistencies in Android",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/vyas",
    "abstract": "Vendor customization of the Android framework is known to introduce security concerns. One type of customization is data-driven, involving changes to access-controlled framework variables, which we call data holders. Analyzing the security of data-driven customization has not been explored in prior work because it faces several challenges as it requires modeling implicit access control (AC) relations among Java objects and their corresponding operation semantics. Existing Android AC inconsistency detection approaches struggle to discover data-driven AC inconsistencies.\nWe propose a novel approach, Ariadne, to address these challenges by (1) constructing an abstract representation, the AC dependency graph, to model AC relationships among framework data holders, and (2) using it to detect missing AC enforcement in data holders and their corresponding APIs. Using two AOSP and 11 custom ROMs, we show that Ariadne detects 30 unique data-driven AC inconsistencies which cannot be detected by existing approaches. Therefore Ariadne can offer more comprehensive protection by effectively complementing existing AC inconsistency detection approaches."
  },
  {
    "id": 3795,
    "year": 2025,
    "title": "Harness: Transparent and Lightweight Protection of Vehicle Control on Untrusted Android Automotive Operating System",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/gong-haochen",
    "abstract": "As modern in-vehicle infotainment (IVI) systems become more advanced and feature-rich, their complexity increases, expanding the attack surface. Since IVI systems often support vehicle controls, attackers can exploit their vulnerabilities to gain control of the car, posing a dangerous threat to property and personal safety. In this paper, we systematically analyze the attack surface of the Android Automotive Operating System (AAOS). We identify risks across the vehicle control chain, from the human-machine interface through relevant apps and services to the in-vehicle network communication. To prevent these risks, we propose Harness, a lightweight framework that transparently protects vehicle control from untrusted AAOS. Harness defines a minimal protection domain encompassing trusted software with permissions to perform security-critical vehicle control. Leveraging the hypervisor's capabilities, Harness isolates this domain from AAOS and protects its interactions with the external environment, ensuring vehicle control operations align with user intent. We implement Harness, and our evaluation shows it achieves security guarantees with only modest performance overhead."
  },
  {
    "id": 3796,
    "year": 2025,
    "title": "Scoop: Mitigation of Recapture Attacks on Provenance-Based Media Authentication",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/liu-yuxin",
    "abstract": "Continuous advances in photo and video manipulation yield increasingly sophisticated deepfakes that greatly endanger societal perception of reality. Deepfake detection is an intuitive and natural research direction, which is unfortunately shaping up to be a never-ending arms race. An alternative promising direction is provenance assertion, which blends hardware-based secure camera design with the cryptographic means of authenticating the source of visual content and any post-processing (e.g., filters) applied to it.\n\nThis work starts by highlighting a very effective attack type, called a recapture attack, against all provenance-based techniques. In such an attack, the adversary displays fake content on some form of a screen (e.g., TV, projector, or computer screen) or surface (e.g., cardboard, canvas, or paper) and uses a provenance-asserting secure camera device to capture photos and videos of the displayed content.\n\nWe then introduce Scoop, a systematic solution for mitigating recapture attacks. Scoop leverages state-of-the-art depth sensing technologies as well as learning-based depth estimation to detect misleading recaptures, i.e., a recaptured photo or video where the presence of a display medium is not visually identifiable.\n\nWe implement Scoop on both iOS and Android platforms (Apple iPhone 14 Pro and Samsung Galaxy S20 Plus), using their built-in depth sensors. To evaluate the effectiveness of Scoop, we construct a first-of-its-kind dataset consisting of 78 recapture attack scenarios. Our results show that Scoop achieves as high as ≈ 95% accuracy on the iPhone and 74% accuracy on the Samsung phone."
  },
  {
    "id": 3797,
    "year": 2025,
    "title": "Chimera: Creating Digitally Signed Fake Photos by Fooling Image Recapture and Deepfake Detectors",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/park",
    "abstract": "Deepfake detectors relying on heuristics and machine learning are locked in a perpetual struggle against evolving attacks. In contrast, cryptographic solutions provide strong safeguards against deepfakes by creating hardware-binding digital signatures when capturing (real) images. While effective, they falter when attackers misuse cameras to recapture images of digitally generated fake images from a display or other medium. This vulnerability reduces the security assurance back to the effectiveness of deepfake detectors. The main difference, however, is that a successful attack must now deceive two types of detectors simultaneously: deepfake detectors and detectors specialized for detecting image recaptures.\nThis paper introduces Chimera, an end-to-end attack strategy that crafts cryptographically signed fake images capable of deceiving both deepfake and image recapture detectors. Chimera demonstrates that current adversarial and generative models fail to effectively deceive both detector types or lack generalization across different setups. Chimera addresses this gap by using a hardware-aware adversarial compensator to craft fake images that successfully bypass state-of-the-art detection mechanisms. The key innovation is a GAN-based image generator that accounts for and compensates the physical transformations introduced during the recapture process. Through rigorous testing using commercial off-the-shelf cameras and displays, Chimera proves effective in fooling both types of detectors with a high success rate while having high visual quality (compared to the original real image). Chimera demonstrates the vulnerability of deepfake detectors even when equipped with hardware-based digital signatures. Our successful end-to-end attack on state-of-the-art detectors shows an urgent need for more robust detection and mitigation strategies."
  },
  {
    "id": 3798,
    "year": 2025,
    "title": "Principled and Automated Approach for Investigating AR/VR Attacks",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/shoaib",
    "abstract": "As Augmented and Virtual Reality (AR/VR) adoption grows across sectors, auditing systems are needed to enable provenance analysis of AR/VR attacks. However, traditional auditing systems often generate inaccurate and incomplete provenance graphs, or fail to work due to operational restrictions in AR/VR devices. This paper presents REALITYCHECK, a provenance-based auditing system designed to support accurate root cause analysis and impact assessments of complex AR/VR attacks. Our system first enhances the W3C PROV data model with additional ontology to capture AR/VR-specific entities and causal relationships. Then, we employ a novel adaptation of natural language processing and feature-based log correlation techniques to transparently extract entities and relationships from dispersed, unstructured AR/VR logs into provenance graphs. Finally, we introduce an AR/VR-aware execution partitioning technique to filter out forensically irrelevant data and false causal relationships from these provenance graphs, improving analysis accuracy and investigation speed. We built a REALITYCHECK prototype for Meta Quest 2 and evaluated it against 25 real-world AR/VR attacks. The results show that REALITYCHECK generates accurate provenance graphs for all AR/VR attacks and incurs low runtime overhead across benchmarked applications. Notably, our execution partitioning approach drastically reduces the size of the graph without sacrificing essential investigation details. Our system operates non-intrusively, requires no additional installation, and is generalizable across various AR/VR devices."
  },
  {
    "id": 3799,
    "year": 2025,
    "title": "Tracking You from a Thousand Miles Away! Turning a Bluetooth Device into an Apple AirTag Without Root Privileges",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/chen-junming",
    "abstract": "Apple's Find My network, leveraging over a billion active Apple devices, is the world's largest device-locating network. We investigate the potential misuse of this network to maliciously track Bluetooth devices. We present nRootTag, a novel attack method that transforms computers into trackable \"AirTags\" without requiring root privileges. The attack achieves a success rate of over 90% within minutes at a cost of only a few US dollars. Or, a rainbow table can be built to search keys instantly. Subsequently, it can locate a computer in minutes, posing a substantial risk to user privacy and safety. The attack is effective on Linux, Windows, and Android systems, and can be employed to track desktops, laptops, smartphones, and IoT devices. Our comprehensive evaluation demonstrates nRootTag's effectiveness and efficiency across various scenarios."
  },
  {
    "id": 3800,
    "year": 2025,
    "title": "ChoiceJacking: Compromising Mobile Devices through Malicious Chargers like a Decade ago",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/draschbacher",
    "abstract": "JuiceJacking is an attack in which malicious chargers compromise connected mobile devices. Shortly after the attack was discovered about a decade ago, mobile OSs introduced user prompts for confirming data connections from a USB host to a mobile device. Since the introduction of this countermeasure, no new USB-based attacks with comparable impact have been found.\nIn this paper, we present a novel family of USB-based attacks on mobile devices, ChoiceJacking, which is the first to bypass existing JuiceJacking mitigations. We observe that these mitigations assume that an attacker cannot inject input events while establishing a data connection. However, we show that this assumption does not hold in practice. We present a platform-agnostic attack principle and three concrete attack techniques for Android and iOS that allow a malicious charger to autonomously spoof user input to enable its own data connection. Our evaluation using a custom cheap malicious charger design reveals an alarming state of USB security on mobile platforms. Despite vendor customizations in USB stacks, ChoiceJacking attacks gain access to sensitive user files (pictures, documents, app data) on all tested devices from 8 vendors including the top 6 by market share. For two vendors, our attacks allow file extraction from locked devices. For stealthily performing attacks that require an unlocked device, we use a power line side-channel to detect suitable moments, i.e., when the user does not notice visual artifacts.\nWe responsibly disclosed all findings to affected vendors. All but one (including Google, Samsung, Xiaomi, and Apple) acknowledged our attacks and are in the process of integrating mitigations."
  },
  {
    "id": 3801,
    "year": 2025,
    "title": "PATCHAGENT: A Practical Program Repair Agent Mimicking Human Expertise",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/yu-zheng",
    "abstract": "Automated program repair (APR) techniques, which aim to triage and fix software bugs autonomously, have emerged as powerful tools against vulnerable code. Recent advancements in large language models (LLMs) have further shown promising results when applied to APR, especially on patch generation. However, without effective fault localization and patch validation, APR tools specialized in patching alone cannot handle a more practical and end-to-end setting—given a concrete input that triggers a vulnerability, how to patch the program without breaking existing tests? \nIn this paper, we introduce PatchAgent, a novel LLM-based APR tool that seamlessly integrates fault localization, patch generation, and validation within a single autonomous agent. PatchAgent employs a language server, a patch verifier, and interaction optimization techniques to mimic human-like reasoning during vulnerability repair. Evaluated on a dataset of 178 real-world vulnerabilities, PatchAgent successfully repairs over 90% of the cases, outperforming state-of-the-art APR tools where applicable. Our ablation study further offers insights into how various interaction optimizations contribute to PatchAgent's effectiveness."
  },
  {
    "id": 3802,
    "year": 2025,
    "title": "Logs In, Patches Out: Automated Vulnerability Repair via Tree-of-Thought LLM Analysis",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/kim-youngjoon",
    "abstract": "Research on automated vulnerability repair often requires extensive program analysis and expert input, making it challenging to deploy in practice. We propose SAN2PATCH, a system that generates patches using only sanitizer logs and source code, eliminating the need for costly program analysis or manual intervention. SAN2PATCH employs multi-stage reasoning with Large Language Models (LLMs) to decompose the patching process into four distinct tasks: vulnerability comprehension, fault localization, fix strategy formulation, and patch generation. Through tree-structured prompting and rigorous validation, SAN2PATCH can generate diverse, functionallycorrect patches. Evaluations on the VulnLoc dataset show that SAN2PATCH successfully patches 79.5% of vulnerabilities, surpassing state-of-the-art tools like ExtractFix (43%) and VulnFix (51%) by significant margins. On our newly curated SAN2VULN dataset of 27 new vulnerabilities from various open-source projects, SAN2PATCH achieves a 63% success rate, demonstrating its effectiveness on modern security flaws. Notably, SAN2PATCH excels at patching complex memoryrelated vulnerabilities, successfully fixing 81.8% of buffer overflows while preserving program functionality. This high performance, combined with minimal deployment requirements and elimination of manual steps, makes SAN2PATCH a practical solution for real-world vulnerability remediation."
  },
  {
    "id": 3803,
    "year": 2025,
    "title": "SoK: Automated Vulnerability Repair: Methods, Tools, and Assessments",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/hu-yiwei",
    "abstract": "The increasing complexity of software has led to the steady growth of vulnerabilities. Vulnerability repair investigates how to fix software vulnerabilities. Manual vulnerability repair is labor-intensive and time-consuming because it relies on human experts, highlighting the importance of Automated Vulnerability Repair (AVR). In this SoK, we present the systematization of AVR methods through the three steps of AVR workflow: vulnerability analysis, patch generation, and patch validation. We assess AVR tools for C/C++ and Java programs as they have been widely studied by the community. Since existing AVR tools for C/C++ programs are evaluated with different datasets, which often consist of a few vulnerabilities, we construct the first C/C++ vulnerability repair benchmark dataset, dubbed Vul4C, which contains 144 vulnerabilities as well as their exploits and patches. We use Vul4C to evaluate seven AVR tools for C/C++ programs and use the third-party Vul4J dataset to evaluate two AVR tools for Java programs. We also discuss future research directions."
  },
  {
    "id": 3804,
    "year": 2025,
    "title": "SoK: Towards Effective Automated Vulnerability Repair",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/li-ying",
    "abstract": "The increasing prevalence of software vulnerabilities necessitates automated vulnerability repair (AVR) techniques. This Systematization of Knowledge (SoK) provides a comprehensive overview of the AVR landscape, encompassing both synthetic and real-world vulnerabilities. Through a systematic literature review and quantitative benchmarking across diverse datasets, methods, and strategies, we establish a taxonomy of existing AVR methodologies, categorizing them into template-guided, search-based, constraint-based, and learning-driven approaches. We evaluate the strengths and limitations of these approaches, highlighting common challenges and practical implications. Our comprehensive analysis of existing AVR methods reveals a diverse landscape with no single \"best'' approach. Learning-based methods excel in specific scenarios but lack complete program understanding, and both learning and non-learning methods face challenges with complex vulnerabilities. Additionally, we identify emerging trends and propose future research directions to advance the field of AVR. This SoK serves as a valuable resource for researchers and practitioners, offering a structured understanding of the current state-of-the-art and guiding future research and development in this critical domain."
  },
  {
    "id": 3805,
    "year": 2025,
    "title": "VULCANBOOST: Boosting ReDoS Fixes through Symbolic Representation and Feature Normalization",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/li-yeting",
    "abstract": "Regular expressions (regexes) are widely used in modern programming languages but are susceptible to ReDoS attacks due to the inefficiencies introduced by backtracking algorithms. Existing approaches for repairing ReDoS-vulnerable regexes struggle with supporting diverse character classes and extended features, often relying on test cases for repair guidance. In this paper, we introduce VULCANBOOST, a novel framework for repairing ReDoS-vulnerable regexes that addresses these challenges.  VULCANBOOST leverages symbolic representation and feature normalization to simplify regex structures and repair them through DFA (Deterministic Finite Automaton) transformations, eliminating the need for test case-based repair. Our evaluation, conducted on a large dataset of 6,360 ReDoS-vulnerable regexes from real-world NPM projects, demonstrates that VULCANBOOST achieves a Test Coverage Repair Success Rate (TCRSR) of 93.95% and an Equivalence Repair Success Rate (ERSR) of 93.05%, outperforming existing methods. Moreover, we identify common vulnerability patterns from over 5,000 repaired regexes and summarize the top 100 repair patterns as open-source resources, offering valuable guidance to developers in enhancing the security and correctness of their regexes."
  },
  {
    "id": 3806,
    "year": 2025,
    "title": "APPATCH: Automated Adaptive Prompting Large Language Models for Real-World Software Vulnerability Patching",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/nong",
    "abstract": "Timely and effective vulnerability patching is essential for cybersecurity defense, for which various approaches have been proposed yet still struggle to generate valid and correct patches for real-world vulnerabilities. In this paper, we leverage the power and merits of pre-trained language language models (LLMs) to enable automated vulnerability patching using no test input/exploit evidence and without model training/fine-tuning. To elicit LLMs to effectively reason about vulnerable code behaviors, which is essential for quality patch generation, we introduce vulnerability semantics reasoning and adaptive prompting on LLMs and instantiate the methodology as APPATCH, an automated LLM-based patching system. Our evaluation of APPATCH on 97 zero-day vulnerabilities and 20 existing vulnerabilities demonstrates its superior performance to both existing prompting methods and state-of-the-art non-LLM-based techniques (by up to 28.33% in F1 and 182.26% in recall over the best baseline). Through APPATCH, we demonstrate what helps for LLM-based patching and how, as well as discussing what still lacks and why."
  },
  {
    "id": 3807,
    "year": 2025,
    "title": "RangeSanitizer: Detecting Memory Errors with Efficient Range Checks",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/gorter",
    "abstract": "Sanitizers for spatial and temporal memory errors have become a cornerstone of security testing. Popular redzone-based sanitizers such as AddressSanitizer (ASan) offer high compatibility and effectiveness through the use of redzones, but incur significant runtime overhead. A major cause of this overhead is the traditional use of per-object redzone metadata, which constrains the sanitizer to check individual addresses rather than entire ranges of memory at once—as is done by classic bounds checkers based on per-pointer metadata.\nIn this paper, we introduce RangeSanitizer (RSan), a redzone-based sanitizer that introduces a novel metadata and check paradigm. RSan combines the compatibility of redzones with a rich per-object metadata format that allows for range (rather than address) checks and powerful optimizations. RSan stores bounds information inside the underflow redzone associated with each memory object. By combining pointer tagging with power-of-two size classes, RSan can swiftly locate metadata and validate an access to an arbitrary memory range with a single check. RSan incurs a geomean runtime overhead of 44% on SPEC CPU2017, faster than all state-of-the-art redzone-based sanitizers and twice as fast as ASan. Additionally, fuzzing with AFL++ and RSan as sanitizer improves state-of-the-art throughput by up to 70%."
  },
  {
    "id": 3808,
    "year": 2025,
    "title": "DISPATCH: Unraveling Security Patches from Entangled Code Changes",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/sun-shiyu",
    "abstract": "Security patches are crucial for preserving the integrity, confidentiality, and availability of computing resources. However, their deployment can be significantly postponed when intertwined with non-security patches. Existing code change decomposition methods are primarily designed for code review, focusing on connecting related parts. However, they often include irrelevant statements in a bloated security patch, complicating security patch detection, verification, and deployment. In this paper, we develop a patch decomposition system named DISPATCH for unraveling individual security patches from entangled code changes. We first introduce a graph representation named PatchGraph to capture the fine-grained code modifications by retaining changed syntax and dependency. Next, we perform a two-stage patch dependency analysis to group the changed statements addressing the same vulnerability into individual security patches. The first stage focuses on the statement level, where boundaries are defined to exclude unrelated statements. The second stage analyzes the unvisited dependencies, ensuring the patch's applicability by maintaining syntactic correctness and function completeness. In the evaluation across four popular software repositories (i.e., OpenSSL, Linux Kernel, ImageMagick, and Nginx), DISPATCH can unravel individual security patches from entangled ones with over 91.9% recall, outperforming existing methods by at least 20% in accuracy."
  },
  {
    "id": 3809,
    "year": 2025,
    "title": "Attacker Control and Bug Prioritization",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/lacombe",
    "abstract": "As bug-finding methods improve, bug-fixing capabilities are exceeded, resulting in an accumulation of potential vulnerabilities. There is thus a need for efficient and precise bug prioritization based on exploitability. In this work, we explore the notion of control of an attacker over a vulnerability's parameters, which is an often overlooked factor of exploitability. We show that taint as well as straightforward qualitative and quantitative notions of control are not enough to effectively differentiate vulnerabilities. Instead, we propose to focus analysis on feasible value sets, which we call domains of control, in order to better take into account threat models and expert insight. Our new Shrink and Split algorithm efficiently extracts domains of control from path constraints obtained with symbolic execution and renders them in an easily processed, human-readable form. This in turn allows to automatically compute more complex control metrics, such as weighted Quantitative Control, which factors in the varying threat levels of different values. Experiments show that our method is both efficient and precise. In particular, it is the only one able to distinguish between vulnerabilities such as cve-2019-14192 and cve-2022-30552, while revealing a mistake in the human evaluation of cve-2022-30790. The high degree of automation of our tool also brings us closer to a fully-automated evaluation pipeline."
  },
  {
    "id": 3810,
    "year": 2025,
    "title": "VoiceWukong: Benchmarking Deepfake Voice Detection",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/yan-ziwei",
    "abstract": "With the rapid advancement of technologies like text-to-speech (TTS) and voice conversion (VC), detecting deepfake voices has become increasingly crucial. However, both academia and industry lack a comprehensive and intuitive benchmark for evaluating detectors. Existing datasets are limited in language diversity and lack many manipulations encountered in real-world production environments.\nTo fill this gap, we propose VoiceWukong, a benchmark designed to evaluate the performance of deepfake voice detectors. To build the dataset, we first collected deepfake voices generated by 19 advanced and widely recognized commercial tools and 15 open-source tools. We then created 38 data variants covering six types of manipulations, constructing the evaluation dataset for deepfake voice detection. VoiceWukong thus includes 265,200 English and 148,200 Chinese deepfake voice samples. Using VoiceWukong, we evaluated 12 state-of-the-art detectors. AASIST2 achieved the best equal error rate (EER) of 13.50%, while all others exceeded 20%. Our findings reveal that these detectors face significant challenges in real-world applications, with dramatically declining performance. In addition, we conducted a user study with more than 300 participants. The results are compared with the performance of the 12 detectors and a multimodel large language model (MLLM), i.e., Qwen2-Audio, where different detectors and humans exhibit varying identification capabilities for deepfake voices at different deception levels, while the MLLM demonstrates no detection ability at all. Furthermore, we provide a leaderboard for deepfake voice detection, publicly available at https://voicewukong.github.io."
  },
  {
    "id": 3811,
    "year": 2025,
    "title": "SafeSpeech: Robust and Universal Voice Protection Against Malicious Speech Synthesis",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/zhang-zhisheng",
    "abstract": "Speech synthesis technology has brought great convenience, while the widespread usage of realistic deepfake audio has triggered hazards. Malicious adversaries may unauthorizedly collect victims' speeches and clone a similar voice for illegal exploitation (e.g., telecom fraud). However, the existing defense methods cannot effectively prevent deepfake exploitation and are vulnerable to robust training techniques. Therefore, a more effective and robust data protection method is urgently needed. In response, we propose a defensive framework, SafeSpeech, which protects the users' audio before uploading by embedding imperceptible perturbations on original speeches to prevent high-quality synthetic speech. In SafeSpeech, we devise a robust and universal proactive protection technique, Speech PErturbative Concealment (SPEC), that leverages a surrogate model to generate universally applicable perturbation for generative synthetic models. Moreover, we optimize the human perception of embedded perturbation in terms of time and frequency domains. To evaluate our method comprehensively, we conduct extensive experiments across advanced models and datasets, both subjectively and objectively. Our experimental results demonstrate that SafeSpeech achieves state-of-the-art (SOTA) voice protection effectiveness and transferability and is highly robust against advanced adaptive adversaries. Moreover, SafeSpeech has real-time capability in real-world tests. The source code is available at https://github.com/wxzyd123/SafeSpeech."
  },
  {
    "id": 3812,
    "year": 2025,
    "title": "AUDIO WATERMARK: Dynamic and Harmless Watermark for Black-box Voice Dataset Copyright Protection",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/guo-hanqing",
    "abstract": "Many open-sourced audio datasets require that they can only be adopted for academic or educational purposes, yet there is currently no effective method to ensure compliance with these conditions. Ideally, the dataset owner can apply a watermark to their dataset, enabling them to identify any model that utilizes the watermarked data. While traditional backdoor-based approaches can achieve this objective, they present significant drawbacks: 1) they introduce harmful backdoors into the model; 2) they are ineffective with black-box models; 3) they compromise audio quality; 4) they are easily detectable due to their static backdoor patterns. In this paper, we introduce AUDIO WATERMARK, a dynamic and harmless watermark specifically designed for black-box voice dataset copyright protection. The dynamism of the watermark is achieved through a style-transfer generative model and random reference style patterns; its harmlessness is ensured by utilizing an out-of-domain (OOD) feature, which allows the watermark to be correctly recognized by the watermarked model without altering the ground truth label. The efficacy in black-box settings is accomplished through a bi-level adversarial optimization strategy, which trains a generalized model to counteract the watermark generator, thereby enhancing the watermark's stealthiness across multiple target models. We evaluate our watermark across 2 voice datasets and 10 speaker recognition models, comparing it with 10 existing protections and testing it in 8 attack scenarios. We achieve minimal harmful impact, with nearly 100% benign accuracy, a 95% verification success rate, and demonstrate resistance to all tested attacks."
  },
  {
    "id": 3813,
    "year": 2025,
    "title": "SoK: Automated TTP Extraction from CTI Reports – Are We There Yet?",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/buechel",
    "abstract": "Cyber Threat Intelligence (CTI) plays a critical role in sharing knowledge about new and evolving threats. With the increased prevalence and sophistication of threat actors, intelligence has expanded from simple indicators of compromise to extensive CTI reports describing high-level attack steps known as Tactics, Techniques and Procedures (TTPs). Such TTPs, often classified into the ontology of the MITRE ATT&CK framework, make CTI significantly more valuable, but also harder to interpret and automatically process. Natural Language Processing (NLP) makes it possible to automate large parts of the knowledge extraction from CTI reports; over 40 papers discuss approaches, ranging from named entity recognition over embedder models to generative large language models. Unfortunately, existing solutions are largely incomparable as they consider decisively different and constrained settings, rely on custom TTP ontologies, and use a multitude of custom, inaccessible CTI datasets. We take stock, systematize the knowledge in the field, and empirically evaluate existing approaches in a unified setting for fair comparisons. We gain several fundamental insights, including (1) the finding of a kind of performance limit that existing approaches seemingly cannot overcome as of yet, (2) that traditional NLP approaches (possibly counterintuitively) outperform modern embedder-based and generative approaches in realistic settings, and (3) that further research on understanding inherent ambiguities in TTP ontologies and on the creation of qualitative datasets is key to take a leap in the field."
  },
  {
    "id": 3814,
    "year": 2025,
    "title": "Whispering Under the Eaves: Protecting User Privacy Against Commercial and LLM-powered Automatic Speech Recognition Systems",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/jin-weifei",
    "abstract": "The widespread application of automatic speech recognition (ASR) supports large-scale voice surveillance, raising concerns about privacy among users. In this paper, we concentrate on using adversarial examples to mitigate unauthorized disclosure of speech privacy thwarted by potential eavesdroppers in speech communications. While audio adversarial examples have demonstrated the capability to mislead ASR models or evade ASR surveillance, they are typically constructed through time-intensive offline optimization, restricting their practicality in real-time voice communication. Recent work overcame this limitation by generating universal adversarial perturbations (UAPs) and enhancing their transferability for black-box scenarios. However, they introduced excessive noise that significantly degrades audio quality and affects human perception, thereby limiting their effectiveness in practical scenarios. To address this limitation and protect live users' speech against ASR systems, we propose a novel framework, AudioShield. Central to this framework is the concept of Transferable Universal Adversarial Perturbations in the Latent Space (LS-TUAP). By transferring the perturbations to the latent space, the audio quality is preserved to a large extent. Additionally, we propose target feature adaptation to enhance the transferability of UAPs by embedding target text features into the perturbations. Comprehensive evaluation on four commercial ASR APIs (Google, Amazon, iFlytek, and Alibaba), three widely-used voice assistants, two LLM-powered ASR and one NN-based ASR demonstrates the protection superiority of AudioShield over existing competitors, and both objective and subjective evaluations indicate that AudioShield significantly improves the audio quality. Moreover, AudioShield also shows high effectiveness in the real-time end-to-end scenarios, and demonstrates strong resilience against adaptive countermeasures."
  },
  {
    "id": 3815,
    "year": 2025,
    "title": "AudioMarkNet: Audio Watermarking for Deepfake Speech Detection",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/zong",
    "abstract": "Deep generative models have improved significantly in recent years to the point where generated fake images or audio are now indistinguishable from genuine media. As a result, humans are unable to differentiate between real and deepfake content. While this presents a huge benefit to the creative sector, its exploitation to fool the general public has resulted in a real-world threat to society. To prevent generative models from being exploited by adversaries, researchers have devoted much effort towards developing methods for differentiating between real and generated data. To date, most existing techniques are designed to reactively detect artifacts introduced by generative models. In this work, we propose a watermarking technique, called AudioMarkNet, to embed watermarks in original speech. The purpose is to prevent speech from being used for speaker adaptation (i.e., fine-tuning text-to-speech (TTS)), which is commonly used for generating high-fidelity fake speech. Our method is orthogonal to existing reactive detection methods. Experimental results demonstrate the success of our method in detecting fake speech generated by open-source and commercial TTS models. Moreover, our watermarking technique achieves robustness against common non-adaptive attacks. We also demonstrate the effectiveness of our method against adaptive attacks. Examples of watermarked speech using our proposed method can be found on a website. Our code and artifacts are also available online."
  },
  {
    "id": 3816,
    "year": 2025,
    "title": "SoK: Efficiency Robustness of Dynamic Deep Learning Systems",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/rathnasuriya",
    "abstract": "Deep Learning Systems (DLSs) are increasingly deployed in real-time applications, including those in resource-constrained environments such as mobile and IoT devices. To address efficiency challenges, Dynamic Deep Learning Systems (DDLSs) adapt inference computation based on input complexity, reducing overhead. While this dynamic behavior improves efficiency, such behavior introduces new attack surfaces. In particular, efficiency adversarial attacks exploit these dynamic mechanisms to degrade system performance.\nThis paper systematically explores efficiency robustness of DDLSs, presenting the first comprehensive taxonomy of efficiency attacks. We categorize these attacks based on three dynamic behaviors: (i) attacks on dynamic computations per inference, (ii) attacks on dynamic inference iterations, and (iii) attacks on dynamic output production for downstream tasks. Through an in-depth evaluation, we analyze adversarial strategies that target DDLSs efficiency and identify key challenges in securing these systems. In addition, we investigate existing defense mechanisms, demonstrating their limitations against increasingly popular efficiency attacks and the necessity for novel mitigation strategies to secure future adaptive DDLSs."
  },
  {
    "id": 3817,
    "year": 2025,
    "title": "From Meme to Threat: On the Hateful Meme Understanding and Induced Hateful Content Generation in Open-Source Vision Language Models",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/ma-yihan",
    "abstract": "Open-source Vision Language Models (VLMs) have rapidly advanced, blending natural language with visual modalities, leading them to achieve remarkable performance on tasks such as image captioning and visual question answering. However, their effectiveness in real-world scenarios remains uncertain, as real-world images—particularly hateful memes—often convey complex semantics, cultural references, and emotional signals far beyond those in experimental datasets. In this paper, we present an in-depth evaluation of VLMs' ability to interpret hateful memes by curating a dataset of 39 hateful memes and 12,775 responses from seven representative VLMs using carefully designed prompts. Our manual annotations of the responses' informativeness and soundness reveal that VLMs can identify visual concepts and understand cultural and emotional backgrounds, especially for the well-known hateful memes. However, we find that the VLMs lack robust safeguards to effectively detect and reject hateful content, making them vulnerable to misuse for generating harmful outputs such as hate speech and offensive slogans. Our findings show that 40% of VLM-generated hate speech and over 10% of hateful jokes and slogans were flagged as harmful, emphasizing the urgent need for stronger safety measures and ethical guidelines to mitigate misuse. We hope our study serves as a foundation for improving VLM safety and ethical standards in handling hateful content."
  },
  {
    "id": 3818,
    "year": 2025,
    "title": "When Translators Refuse to Translate: A Novel Attack to Speech Translation Systems",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/wu-haolin",
    "abstract": "Speech translation, which converts a spoken language into another spoken or written language, has experienced rapid advance recently. However, the security in this domain remains underexplored. In this work, we uncover a novel security threat unique to speech translation systems, which is dubbed \"untranslation attack\". We observe that state-of-the-art (SOTA) models, despite their strong translation capabilities, exhibit an inherent tendency to output the content in the source speech language rather than the desired target language. Leveraging this phenomenon, we propose an attack model that deceives the system into outputting the source language content instead of translating it. Interestingly, we find that this approach achieves significant attack effectiveness with minimal overhead compared to traditional semantic perturbation attacks: it achieves a high attack success rate of 87.5% with a perturbation budget of as low as 0.001. Furthermore, we extend this approach to develop a universal perturbation attack, successfully testing it in the physical world."
  },
  {
    "id": 3819,
    "year": 2025,
    "title": "MalGuard: Towards Real-Time, Accurate, and Actionable Detection of Malicious Packages in PyPI Ecosystem",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/gao-xingan",
    "abstract": "Malicious package detection has become a critical task in ensuring the security and stability of the PyPI community. Existing detection approaches have focused on advancing model selection, evolving from traditional machine learning (ML) models to large language models (LLMs). However, as model complexity increases, the time consumption also increases, which raises the question that can lightweight model achieve effective detection? Through empirical research, we demonstrate that collecting a sufficiently comprehensive feature set enables even traditional ML-models to achieve outstanding performance. But, traditional ML-models rely on manually pre-defined feature set and lack of explainability to malicious packages. Thereforce, we propose a novel approach MalGuard based on social network graphs to detect malicious packages in five traditional ML-models. To overcome this challenge, we leverage graph centrality analysis to extract sensitive APIs automatically to replace the hand-crafted features. To understand the sensitive APIs, we further refine the feature set using LLM and integrate the LIME(Local Interpretable Model-agnostic Explanations) algorithm with ML-models to provide explanations for malicious packages. We evaluated MalGuard against five SOTA baselines with the same settings. Experimental results show that our proposed MalGuard, improves precision by 0.5%-33.2% and recall by 1.8%-22.1%. With MalGuard, we successfully identified 95 previously unknown malicious packages from a pool of 51,479 newly-uploaded packages over a four-week period, and 73 out of them have been removed by the PyPI official."
  },
  {
    "id": 3820,
    "year": 2025,
    "title": "VAPD: An Anomaly Detection Model for PDF Malware Forensics with Adversarial Robustness",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/liu-side",
    "abstract": "Malicious PDFs are a prevalent threat in the modern web security landscape, often used as attack vectors in phishing campaigns and other web application attacks. With the widespread integration of PDF readers in browsers, malicious PDFs exploit vulnerabilities in web applications and browsers, posing significant risks. Despite advances in machine learning for malware detection, existing PDF classifiers struggle with adversarial attacks, where minor modifications to malicious files evade detection and lead to serious consequences like ransomware or data breaches.\nIn this paper, we propose VAPD, an anomaly detection model based on reconstruction with dual forensics objectives: 1) identifying PDF malware through the reconstruction error between input and output, and 2) pinpointing anomalous regions. We strategically leverage the notion that a model exclusively trained on benign samples struggles to reconstruct malicious counterparts, thereby yielding amplified reconstruction errors. We have evaluated VAPD on multiple datasets, including real-world Advanced Persistent Threat samples, achieving an accuracy rate of 99.54% that stands out among existing anomaly detection methods. Moreover, we measure the robustness of VAPD by utilizing four adversarial attack frameworks in both feature and problem spaces. Our findings demonstrate that our model exhibits superior robustness performance when compared to the state-of-the-art work. Notably, we achieve this level of performance at a significantly lower training cost, which is equivalent to only 4.8% of the state-of-the-art work. Additionally, VAPD offers an advanced localization capability that outperform signature-based tools."
  },
  {
    "id": 3821,
    "year": 2025,
    "title": "NOKEScam: Understanding and Rectifying Non-Sense Keywords Spear Scam in Search Engines",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/liu-mingxuan",
    "abstract": "NOKEScam (NOn-sense KEyword Spear scam) is an emerging fraud technique. NOKEScam uses uncommon and usually non-sense keywords (NSKeywords) as vectors to lure victims without complex Black Hat SEO techniques. The obscure NSKeywords ensure the top search results as only NOKEScam pages are exactly matched, misleading victims into trusting them. NOKEScam severely impacts victims and search engines, but its uniqueness has hindered prior research and efficient detection methods.\nIn this paper, we report on joint work with a leading Chinese search engine to combat NOKEScam. Based on an empirical study, we identified three key observations and developed a lightweight detection system. This system can process about 2 billion URLs within one hour. Over seven months, we identified 153,975 NSKeywords across 68,863 domains. Our measurement demonstrated that leveraging search engine trust endorsement, NOKEScam websites attract an average of over 30k page views daily, indicating significant fraudulent profit potential. Driven by this, attackers persist despite search engine crackdowns, employing evasion tactics like using more domain names. Despite these tactics, our detection system remains effective, significantly suppressing the impact of NOKEScam, with a 194-fold reduction in real-world user complaints. Our findings reveal emerging fraud activities and offer valuable governance lessons for the security community."
  },
  {
    "id": 3822,
    "year": 2025,
    "title": "The Ransomware Decade: The Creation of a Fine-Grained Dataset and a Longitudinal Study",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/sarabi",
    "abstract": "Ransomware attacks have grown and evolved considerably in the past decade and are now one of the most common and most profitable attack vectors. Successful ransomware attacks have the ability to shut hospitals down, cause massive data and financial losses, tarnish the reputations of organizations, and even cause direct physical harm to people and property. Consequently, considerable attention has been paid to various individual aspects of the ransomware ecosystem in both the research community and the popular press. However, there continues to be a lack of comprehensive long-range census of these events. This presents a significant barrier to any comprehensive analysis of the ecosystem as a whole. In this paper, we present a longitudinal study of a decade of the ransomware attack landscape. This study is built upon a sophisticated process we developed to source and curate a unique large-scale dataset of ransomware incidents with fine-grained annotations on the basis of public reports of such incidents. We detail this process in the paper and showcase a variety of analysis enabled by such a dataset. Of particular interest are findings around the downstream impact of a large ransom payment vs. a high-profile refusal to pay, the impact of double extortion, the difference in susceptibility to different attack vectors and in payment attitudes across industry sectors."
  },
  {
    "id": 3823,
    "year": 2025,
    "title": "High Stakes, Low Certainty: Evaluating the Efficacy of High-Level Indicators of Compromise in Ransomware Attribution",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/van-der-horst",
    "abstract": "As ransomware attacks grow in frequency and complexity, accurate attribution is crucial. Victim organizations often feel compelled to pay ransom, but must first attribute the attack and conduct sanction screening to ensure the threat actor receiving the payment is not a sanctioned entity, avoiding severe legal and financial risks. This cyber threat actor attribution process typically relies on Indicators of Compromise (IoCs) matching known threat profiles. However, the emergence of the Ransomware-as-a-Service (RaaS) ecosystem and rebranding behavior complicate attribution for sanction screening.\nOur mixed-methods study, combining interviews with 20 experts with an analysis of ransomware incident reports, reveals significant challenges and limitations in the current attribution process. High-level IoCs, widely regarded as more reliable, lack the necessary specificity for accurate attribution, leading to potential risks of misattribution. Practitioners rely on lower-level IoCs, which provide clearer links to threat actors but are highly volatile, further complicating sanction enforcement. These challenges highlight the need for urgent improvements in the attribution and sanction processes.\nTo mitigate these risks, we offer recommendations aimed at enhancing data-sharing practices, improving attributions frameworks, and refining the sanction violation policy to better support sanction screening efforts. While we do not recommend paying ransomware actors, we acknowledge that some organizations may face pressures to do so in certain situations. In such cases, it is vital to ensure legal compliance, particularly regarding sanctioned entities. This work aims to help victims of ransomware shield themselves from transgressing against sanctions."
  },
  {
    "id": 3824,
    "year": 2025,
    "title": "DarkGram: A Large-Scale Analysis of Cybercriminal Activity Channels on Telegram",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/roy",
    "abstract": "We present the first large-scale analysis of 339 cybercriminal activity channels (CACs). Followed by over 23.8M users, these broadcast-style channels share a wide array of malicious and unethical content with their subscribers, including compromised credentials, pirated software and media, social media manipulation tools, and blackhat hacking resources such as malware and exploit kits, and social engineering scams. To evaluate these channels, we developed DarkGram—a BERT-based framework that automatically identifies malicious posts from the CACs with an accuracy of 96%. Using DarkGram, we conducted a quantitative analysis of 53,605 posts posted on these channels between February and May 2024, revealing key characteristics of shared content. While much of this content is distributed for free, channel administrators frequently employ strategies, such as promotions and giveaways, to engage users and boost the sales of premium cybercriminal content. Interestingly, sometimes, these channels pose significant risks to their own subscribers. Notably, 28.1% of the links shared in these channels contained phishing attacks, and 38% of executable files were bundled with malware. Looking closely into how subscribers consume and react positively to the shared content paints a dangerous picture of the perpetuation of cybercriminal content at scale. We also found that the CACs can evade scrutiny or platform takedowns by quickly migrating to new channels with minimal subscriber loss, highlighting the resilience of this ecosystem. To counteract this, we utilized DarkGram to detect emerging channels and reported malicious content to Telegram and the affected organizations. This resulted in the takedown of 196 channels over the course of three months. Our findings underscore the urgent need for coordinated efforts to combat the growing threats posed by these channels. To aid this effort, we open-source our dataset and the DarkGram framework."
  },
  {
    "id": 3825,
    "year": 2025,
    "title": "\"Please don't send that bot anything\": A Mixed-methods Study of Personal Impersonation Attacks Targeting Digital Payments on Social Media",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/nguyen",
    "abstract": "Personal impersonation attacks on social media are an emerging form of social engineering that exploit trust within interpersonal relationships to redirect digital payments. Unlike brand impersonation, these attacks target everyday users, leveraging real-time public interactions to deceive victims into transferring funds to attacker-controlled accounts. In this paper, we present the first in-depth study of PROSPER (Payment Re-routing on Social media via Personal Impersonation) attacks, focusing on their operational tactics, scale, and impact. Using a mixed-methods approach, we tracked 181 PROSPER attacks over a 3-month period, uncovering 70 distinct digital payment accounts and revealing human-in-the-loop scam operations alongside automated bots, as well as longstanding campaigns involving reused payment accounts.\nOur quantitative analysis highlights the scale and persistence of these attacks, while our qualitative analysis provides deeper insights into attacker evasion strategies, victim targeting methods, and how victims are particularly vulnerable to these schemes. Based on these findings, we propose actionable recommendations for social media platforms and payment providers, including UI enhancements, stricter account handle management policies, and the sharing of blacklist information to mitigate these attacks and protect users from financial exploitation."
  },
  {
    "id": 3826,
    "year": 2025,
    "title": "'Hey mum, I dropped my phone down the toilet': Investigating Hi Mum and Dad SMS Scams in the United Kingdom",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/agarwal-sharad",
    "abstract": "SMS fraud has surged in recent years. Detection techniques have improved along with the fraud, necessitating harder-to-detect fraud techniques. We study one of these where scammers send an SMS to the victim addressing mum or dad, pretend to be their child, and ask for financial help. Unlike previous SMS phishing techniques, successful scammers interact with victims, rather than sending only one message which contains a URL. This recent impersonation technique has proven to be more effective worldwide and has been named 'hi mum and dad' SMS scam. In this paper, we collaborate with a UK-based mobile network operator to access the initial 'hi mum and dad' scam messages and related user spam reports. We then interact with suspicious scammers pretending to be potential victims. This is the first work empirically studying this particular scam. We collect 582 unique mule accounts from 711 scammer interactions where scammers ask us to pay more than £577k over three months. We find that scammers deceive their victims mainly by using kindness and distraction principles followed by the time principle. The paper presents how they abuse the services provided by mobile network operators and financial institutions to conduct this scam. We then provide suggestions to mitigate this cybercriminal operation."
  },
  {
    "id": 3827,
    "year": 2025,
    "title": "Fighting Fire with Fire: Continuous Attack for Adversarial Android Malware Detection",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/zhang-yinyuan",
    "abstract": "The pervasive adoption of Android as the leading operating system, due to its open-source nature, has simultaneously rendered it a prime target for malicious software attacks. In response, various learning-based Android malware detectors (AMDs) have been developed, achieving notable success in malware identification. However, these detectors are increasingly compromised by adversarial examples (AEs), which are subtly modified inputs designed to evade detection while maintaining malicious functionality. Recently, advanced adversarial example generation tools have been introduced that can reduce the efficacy of popular detectors to 1%. In this background, to address the critical need for more resilient AMDs, we propose a novel defense mechanism, Harnessing Attack Generativity for Defense Enhancement, i.e., HagDe. HagDe involves applying iterative perturbations in the direction of gradient ascent to all samples, aiming to exploit the high sensitivity of AEs to perturbations. This method enables the detection of adversarial samples by observing the disproportionate increase in the loss function following minor perturbations, distinguishing them from regular samples. To evaluate HagDe, we conduct an extensive evaluation on 15,000 samples and 15 different attack combinations. The experimental results show that ourtool can achieve a defense effectiveness of 88.5% on AdvDroidZero and 90.7% on BagAmmo, representing an increase of 32.45% and 11.28%, respectively, compared to the latest defense method KD_BU and LID."
  },
  {
    "id": 3828,
    "year": 2025,
    "title": "Hobbit: Space-Efficient zkSNARK with Optimal Prover Time",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/pappas",
    "abstract": "Zero-knowledge succinct non-interactive arguments (zkSNARKs) are notorious for their large prover space requirements, which almost prohibits their use for really large instances. Space-efficient zkSNARKs aim to address this by limiting the prover space usage, without critical sacrifices to its runtime. In this work, we introduce Hobbit, the only existing space-efficient zkSNARK that achieves optimal prover time O(|C|) for an arithmetic circuit C. At the same time, Hobbit is the first transparent and post-quantum secure construction of its kind. Moreover, our experimental evaluation shows that Hobbit outperforms all prior general-purpose space-efficient zkSNARKs in the literature across four different applications (arbitrary arithmetic circuits, inference of pruned Multi-Layer Perceptron, batch AES128 evaluation, and select-and-aggregate SQL query) by x8-x56 in terms or prover time while requiring up to x23 less total space.\nAt a technical level, we introduce two new building blocks that may be of independent interest: (i) the first sumcheck protocol for products of polynomials with optimal prover time in the streaming setting, and (ii) a novel multi-linear post-quantum polynomial commitment scheme that outperforms all prior works in prover time (and can be tuned to work in a space-efficient manner). We build Hobbit by combining the above with a modified version of HyperPlonk, providing an explicit routine to stream access to the circuit evaluation."
  },
  {
    "id": 3829,
    "year": 2025,
    "title": "A Tale of Two Worlds, a Formal Story of WireGuard Hybridization",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/lafourcade",
    "abstract": "PQ-WireGuard is a post-quantum variant of WireGuard Virtual Private Network, where Diffie-Hellman-based key exchange is replaced by post-quantum Key Encapsulation Mechanisms-based key exchange. In this paper, we first conduct a thorough formal analysis of PQ-WireGuard's original design, in which we point out and fix a number of weaknesses. This leads us to a new construction PQ-WireGuard^star. Secondly, we propose and formally analyze a new protocol, based on both WireGuard and PQ-WireGuardstar, named Hybrid-WireGuard, compliant with current best practices for post-quantum transition about hybridization techniques. For our analysis, we use the SAPIC+ framework that enables the generation of three state-of-the-art protocol models for the verification tools ProVerif, DeepSec and Tamarin from a single specification, leveraging the strengths of each tool. We formally prove that Hybrid-WireGuard is secure. Eventually, we propose a generic, efficient and usable Rust implementation of our new protocol."
  },
  {
    "id": 3830,
    "year": 2025,
    "title": "Improved Secure Two-party Computation from a Geometric Perspective",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/guo-hao-improved",
    "abstract": "Multiplication and non-linear operations are well known to be the most expensive protocols in secure two-party computation (2PC). Moreover, the comparison protocol (or Wrap protocol) is essential for various operations such as truncation, signed extension, and signed non-uniform multiplication. This paper aims to optimize these protocols by avoiding invoking the costly comparison protocol, thereby improving their efficiency.\nWe propose a novel approach to study 2PC from a geometric perspective. Specifically, we interpret the two shares of a secret as the horizontal and vertical coordinates of a point in a Cartesian coordinate system, with the secret itself represented as the corresponding point. This reformulation allows us to address the comparison problem by determining the region where the point lies. Furthermore, we identify scenarios where the costly comparison protocol can be replaced by more efficient evaluating AND gate protocols within a constrained range. Using this method, we improve protocols for truncation, signed extension and signed non-uniform multiplication, all of which are fundamental to 2PC. In particular, for the one-bit error truncation protocol and signed extension protocols, we reduce the state-of-the-art communication complexities of Cheetah (USENIX'22) and SirNN (S\\&P '21) from ≈ λ (l+1) to ≈λ in two rounds, where l is the input length and λ is the security parameter. For signed multiplication with non-uniform bit-width, we reduce the communication cost of SirNN's by 40% to 60%."
  },
  {
    "id": 3831,
    "year": 2025,
    "title": "Secure Caches for Compartmentalized Software",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/arikan",
    "abstract": "Compartmentalized software systems have been recently proposed in response to security challenges with traditional process-level isolation mechanisms. Compartments provide logical isolation for mutually mistrusting software components, even within the same address space. However, they do not provide side-channel isolation, leaving them vulnerable to side-channel attacks. In this paper, we take on the problem of protecting compartmentalized software from hardware cache side-channel attacks. We consider unique challenges that compartmentalized software poses in terms of securing caches, which include performance implications, efficient and secure data sharing, and avoiding leakage when shared libraries are called by multiple callers. We propose SCC - a framework that addresses these challenges by 1) multi-level cache partitioning including L1 caches with a series of optimizations to avoid performance impact; 2) the concept of domain-oriented partitioning where cache partitions are created per memory domain, instead of per compartment; and 3) creating separate partition instance of a shared library code for each caller. We formally prove the security of SCC using operational semantics and evaluate its performance using the gem5 simulator on a set of compartmentalized benchmarks."
  },
  {
    "id": 3832,
    "year": 2025,
    "title": "zk-promises: Anonymous Moderation, Reputation, and Blocking from Anonymous Credentials with Callbacks",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/shih",
    "abstract": "Anonymity is essential for free speech and expressing dissent, but platform moderators need ways to police bad actors. For anonymous clients, this may involve banning their accounts, docking their reputation, or updating their state in a complex access control scheme. Frequently, these operations happen asynchronously when some violation, e.g., a forum post, is found well after the offending action occurred. Malicious clients, naturally, wish to evade this asynchronous negative feedback. This raises a challenge: how can multiple parties interact with private state stored by an anonymous client while ensuring state integrity and supporting oblivious updates?\nWe propose zk-promises, a framework supporting stateful anonymous credentials where the state machines are Turing-complete and support asynchronous callbacks. Client state is stored in what we call a zk-object held by the client, zero-knowledge proofs ensure the object can only be updated as programmed, and callbacks allow third party updates even for anonymous clients, e.g, for downvotes or banning. Clients scan for callbacks periodically and update their state. When clients authenticate, they anonymously assert some predicate on their state and that they have scanned recently (e.g, within the past 24 hours).\nzk-promises allows us to build a privacy-preserving account model. State that would normally be stored on a trusted server can be privately outsourced to the client while preserving the server's ability to update the account.\nTo demonstrate the feasibility of our approach, we design, implement, and benchmark an anonymous reputation system with better-than-state-of-the-art performance and features, supporting asynchronous reputation updates, banning, and reputation-dependent rate limiting to better protect against Sybil attacks."
  },
  {
    "id": 3833,
    "year": 2025,
    "title": "A Formal Analysis of Apple's iMessage PQ3 Protocol",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/linker",
    "abstract": "We present the formal verification of Apple's iMessage PQ3, a highly performant, device-to-device messaging protocol offering strong security guarantees even against an adversary with quantum computing capabilities. PQ3 leverages Apple's identity services together with a custom, post-quantum secure initialization phase and afterwards it employs a double ratchet construction in the style of Signal, extended to provide post-quantum, post-compromise security.\nWe present a detailed formal model of PQ3, a precise specification of its fine-grained security properties, and machine-checked security proofs using the TAMARIN prover. Particularly novel is the integration of post-quantum secure key encapsulation into the relevant protocol phases and the detailed security claims along with their complete formal analysis. Our analysis covers both key ratchets, including unbounded loops, which was believed by some to be out of scope of symbolic provers like TAMARIN (it is not!)."
  },
  {
    "id": 3834,
    "year": 2025,
    "title": "Towards Practical, End-to-End Formally Verified X.509 Certificate Validators with Verdict",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/lin-zhengyao",
    "abstract": "Validating X.509 certificates is a critical part of Internet security, but the relevant standards are complex and ambiguous. Most X.509 validators also intentionally deviate from these standards in idiosyncratic ways, often for security or backward compatibility. Unsurprisingly, the result is a long history of security vulnerabilities.\nIn this work, we present Verdict, the first end-to-end formally verified X.509 certificate validator with customizable validation policies. Verdict's formal guarantees cover certificate parsing, path building, and path validation. To make Verdict practical to both verify and to use, we specify its correctness generically in terms of a user-supplied validation policy written concisely in first-order logic, with a proof-producing compiler to efficient Rust code.\nTo demonstrate Verdict's expressiveness, we use Verdict's policy framework to implement the X.509 validation policies in Google Chrome, Mozilla Firefox, and OpenSSL, and formally prove that they conform to a subset of RFC requirements. We instantiate Verdict with each policy and show that Verdict matches the corresponding baseline's behavior and state-of-the-art performance on over ten million certificates from Certificate Transparency logs."
  },
  {
    "id": 3835,
    "year": 2025,
    "title": "PICACHV: Formally Verified Data Use Policy Enforcement for Secure Data Analytics",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/chen-haobin",
    "abstract": "Ensuring the proper use of sensitive data in analytics under complex privacy policies is an increasingly critical challenge. Many existing approaches lack portability, verifiability, and scalability across diverse data processing frameworks. We itroduce PICACHV, a novel security monitor that automatically enforces data use policies. It works on relational algebra as an abstraction for program semantics, enabling policy enforcement on query plans generated by programs during execution. This approach simplifies analysis across diverse analytical operations and supports various front-end query languages. By formalizing both data use policies and relational algebra semantics in Coq, we prove that PICACHV correctly enforces policies. PICACHV also leverages Trusted Execution Environments (TEEs) to enhance trust in runtime, providing provable policy compliance to stakeholders that the analytical tasks comply with their data use policies. We integrated PICACHV into Polars, a state-of-the-art data analytics framework, and evaluate its performance using the TPC-H benchmark. We also apply our approach to real-world use cases. Our work demonstrates the practical application of formal methods in securing data analytics, addressing key challenges."
  },
  {
    "id": 3836,
    "year": 2025,
    "title": "OwlC: Compiling Security Protocols to Verified, Secure, High-Performance Libraries",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/singh",
    "abstract": "Cryptographic security protocols, such as TLS or WireGuard, form the foundation of a secure Internet; hence, a long line of research has shown how to formally verify their high-level designs. Unfortunately, these formal guarantees have not yet reached real-world implementations of these protocols, which still rely on testing and ad-hoc manual audits for security and correctness. This gap may be explained, in part, by the substantial performance and/or development overhead imposed by prior efforts to verify implementations.\nTo make it more practical to deploy verified implementations of security protocols, we present OwlC, the first fully automated, security-preserving compiler for verified, high-performance implementations of security protocols. From a high-level protocol specification proven computationally secure in the Owl language, OwlC emits an efficient, interoperable, side-channel resistant Rust library that is automatically formally verified to be correct.\nWe produce verified libraries for all previously written Owl protocols, and we also evaluate OwlC on two new verified case studies: WireGuard and Hybrid Public-Key Encryption (HPKE). Our verified implementations interoperate with existing implementations, and their performance matches unverified industrial baselines on end-to-end benchmarks."
  },
  {
    "id": 3837,
    "year": 2025,
    "title": "On the Virtues of Information Security in the UK Climate Movement",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/brough",
    "abstract": "We report on an ethnographic study with members of the climate movement in the United Kingdom (UK). We conducted participant observation and interviews at protests and in various activist settings. Reporting on the findings as they relate to information security, we show that members of the UK climate movement wrestled with (i) a fundamental tension between openness and secrecy; (ii) tensions between autonomy and collective interdependence in information-security decision-making; (iii) conflicting activist ideals that shape security discourses; and (iv) pressures from different social gazes—from each other, from people outside the movement and from their adversaries. Overall, our findings shed light on the social complexities of information-security research in activist settings and provoke methodological questions about programmes that aim to design for activists."
  },
  {
    "id": 3838,
    "year": 2025,
    "title": "Tracking the Takes and Trajectories of English-Language News Narratives across Trustworthy and Worrisome Websites",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/hanley",
    "abstract": "Understanding how misleading and outright false information enters and spreads within news ecosystems remains a difficult challenge that requires tracking how stories spread across thousands of fringe and mainstream news websites. To take this challenge, we introduce a novel system that utilizes encoder-based large language models and zero-shot stance detection to scalably identify and track news stories and their attitudes to different topics across thousands of factually unreliable, mixed-reliability, and factually reliable English-language news websites. Deploying our system over an 18-month period, we track the spread of 146K news stories across over 4,000 websites. Using network-based interference via the NETINF algorithm, we show that the paths of news stories and the stances of websites toward particular entities can be used to uncover slanted propaganda networks (e.g., anti-vaccine and anti-Ukraine) and to identify the most influential websites in spreading these attitudes in the broader news ecosystem. We hope that the increased visibility into news ecosystems that our system provides assists with the reporting and fact-checking of propaganda and disinformation."
  },
  {
    "id": 3839,
    "year": 2025,
    "title": "\"No, I Can't Be a Security Personnel on Your Phone\": Security and Privacy Threats From Sharing Infrastructure in Rural Ghana",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/tweneboah",
    "abstract": "We examine how rural communities in Ghana adopt workarounds to access electricity and mobile networks and the impact of these workarounds on their digital security and privacy. Through 41 field interviews, we find that participants largely rely on intermediaries to charge their mobile devices and to perform activities that require a stable mobile network. These practices often result in concerns over device loss, unauthorized access of personal information, and eavesdropping. In response, participants adopt protective measures, such as using screen and app locks when handing their devices to intermediaries. Others speak in local languages to 'encrypt' verbal communication when sharing the same 'network zone' with others. Though economically prudent, the reliance on intermediaries introduces social friction where participants suppress their concerns to preserve social relations and continual support. We conclude with recommendations on how various stakeholders, including practitioners and researchers, can work toward improving the security and privacy of users in resource-constrained settings, e.g., by rethinking access control for community-level device and network sharing."
  },
  {
    "id": 3840,
    "year": 2025,
    "title": "Regulating Smart Device Support Periods: User Expectations and the European Cyber Resilience Act",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/kustosch-regulating",
    "abstract": "Supporting consumer IoT devices with updates is crucial to ensure their security. However, this support period is usually shorter than the device's actual lifespan, resulting in millions of unsupported and vulnerable devices. The upcoming European Cyber Resilience Act (CRA) addresses this by requiring manufacturers to support their products for the expected use time, which should be based on reasonable user expectations. In this work, we thus empirically explore the concept of user expectations regarding smart devices' use times and security provision by conducting a large-scale survey in five EU countries (n = 993). We find that respondents' smart device use times and lifetime expectations exceed the CRA's baseline of five years for a majority of device categories and vary substantially across device categories, their \"\"smartness\"\", and individuals. Respondents also consider different factors for the lifetimes of smart and conventional devices. Surprisingly, a majority of respondents expected update support to correspond with devices' full lifetimes, highlighting how the current market dynamics of short support times seem to contrast expectations. Our results provide novel insights for manufacturers and market authorities who will need to determine support periods for smart products in the coming years."
  },
  {
    "id": 3841,
    "year": 2025,
    "title": "Characterizing the MrDeepFakes Sexual Deepfake Marketplace",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/han",
    "abstract": "The prevalence of sexual deepfake material has exploded over the past several years. Attackers create and utilize deepfakes for many reasons: to seek sexual gratification, to harass and humiliate targets, or to exert power over an intimate partner. In part enabling this growth, several markets have emerged to support the buying and selling of sexual deepfake material. In this paper, we systematically characterize the most prominent and mainstream marketplace, MrDeepFakes. We analyze the marketplace economics, the targets of created media, and user discussions of how to create deepfakes, which we use to understand the current state-of-the-art in deepfake creation. Our work uncovers little enforcement of posted rules (e.g., limiting targeting to well-established celebrities), previously undocumented attacker motivations, and unexplored attacker tactics for acquiring resources to create sexual deepfakes."
  },
  {
    "id": 3842,
    "year": 2025,
    "title": "Vulnerability of Text-Matching in ML/AI Conference Reviewer Assignments to Collusions",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/hsieh",
    "abstract": "In the peer review process of top-tier machine learning (ML) and artificial intelligence (AI) conferences, reviewers are assigned to papers through automated methods. These assignment algorithms consider two main factors: (1) reviewers' expressed interests indicated by their bids for papers, and (2) reviewers' domain expertise inferred from the similarity between the text of their previously published papers and the submitted manuscripts. A significant challenge these conferences face is the existence of collusion rings, where groups of researchers manipulate the assignment process to review each other's papers, providing positive evaluations regardless of their actual quality. Most efforts to combat collusion rings have focused on preventing bid manipulation, under the assumption that the text similarity component is secure. In this paper, we demonstrate that even in the absence of bidding, colluding reviewers and authors can exploit the machine learning based text-matching component of reviewer assignment used at top ML/AI venues to get assigned their target paper. We also highlight specific vulnerabilities within this system and offer suggestions to enhance its robustness."
  },
  {
    "id": 3843,
    "year": 2025,
    "title": "Dormant: Defending against Pose-driven Human Image Animation",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/zhou",
    "abstract": "Pose-driven human image animation has achieved tremendous progress, enabling the generation of vivid and realistic human videos from just one single photo. However, it conversely exacerbates the risk of image misuse, as attackers may use one available image to create videos involving politics, violence, and other illegal content. To counter this threat, we propose Dormant, a novel protection approach tailored to defend against pose-driven human image animation techniques. Dormant applies protective perturbation to one human image, preserving the visual similarity to the original but resulting in poor-quality video generation. The protective perturbation is optimized to induce misextraction of appearance features from the image and create incoherence among the generated video frames. Our extensive evaluation across 8 animation methods and 4 datasets demonstrates the superiority of Dormant over 6 baseline protection methods, leading to misaligned identities, visual distortions, noticeable artifacts, and inconsistent frames in the generated videos. Moreover, Dormant shows effectiveness on 6 real-world commercial services, even with fully black-box access."
  },
  {
    "id": 3844,
    "year": 2025,
    "title": "The Conspiracy Money Machine: Uncovering Telegram's Conspiracy Channels and their Profit Model",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/imperati",
    "abstract": "In recent years, major social media platforms have implemented increasingly strict moderation policies, resulting in bans and restrictions on conspiracy theory-related content. To circumvent these restrictions, conspiracy theorists are turning to alternatives, such as Telegram, where they can express and spread their views with fewer limitations. Telegram offers channels—virtual rooms where only administrators can broadcast messages—and a more permissive content policy. These features have created the perfect breeding ground for a complex ecosystem of conspiracy channels.\nIn this paper, we illuminate this ecosystem. First, we propose an approach to detect conspiracy channels. Then, we discover that conspiracy channels can be clustered into four distinct communities comprising over 17,000 channels. Finally, we uncover the \"Conspiracy Money Machine,\" revealing how most conspiracy channels actively seek to profit from their subscribers. We find conspiracy theorists leverage e-commerce platforms to sell questionable products or lucratively promote them through affiliate links. Moreover, we observe that conspiracy channels use donation and crowdfunding platforms to raise funds for their campaigns. We determine that this business involves hundreds of thousands of donors and generates a turnover of almost $71 million."
  },
  {
    "id": 3845,
    "year": 2025,
    "title": "SoK: Machine Learning for Misinformation Detection",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/xiao-madelyne",
    "abstract": "We examine the disconnect between scholarship and practice in applying machine learning to trust and safety problems, using misinformation detection as a case study. We survey literature on automated detection of misinformation across a corpus of 248 well-cited papers in the field. We then examine subsets of papers for data and code availability, design missteps, reproducibility, and generalizability. Our paper corpus includes published work in security, natural language processing, and computational social science. Across these disparate disciplines, we identify common errors in dataset and method design. In general, detection tasks are often meaningfully distinct from the challenges that online services actually face. Datasets and model evaluation are often non-representative of real-world contexts, and evaluation frequently is not independent of model training. We demonstrate the limitations of current detection methods in a series of three representative replication studies. Based on the results of these analyses and our literature survey, we conclude that the current state-of-the-art in fully-automated misinformation detection has limited efficacy in detecting human-generated misinformation. We offer recommendations for evaluating applications of machine learning to trust and safety problems and recommend future directions for research."
  },
  {
    "id": 3846,
    "year": 2025,
    "title": "LLFuzz: An Over-the-Air Dynamic Testing Framework for Cellular Baseband Lower Layers",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/hoang",
    "abstract": "Memory corruptions in cellular basebands are critical because they can be remotely exploited over-the-air, resulting in severe consequences such as remote code execution, denial of service, and information leakage. While previous research has made significant contributions to detecting memory corruptions in basebands, particularly in layer 3 protocols (e.g., NAS and RRC), the lower layers have received comparatively less attention, with only a few works exploring them in a limited and non-systematic manner.\nIn this paper, we present Lower-Layer Fuzzer (LLFuzz), a novel over-the-air dynamic testing framework that discovers memory corruptions in baseband lower layers. LLFuzz systematically targets lower layers, which are the PDCP, RLC, MAC, and PHY layers of the cellular stack. Testing these layers presents unique challenges due to their multiple channels and packet structures that can be dynamically configurable. To address these complexities, LLFuzz implements a channel-driven, configuration-aware fuzzing approach to systematically explore multiple channels. During the testing process, LLFuzz actively modifies layer-specific configurations through signaling messages to trigger and test diverse packet structures, particularly those rarely used in commercial networks. Moreover, LLFuzz leverages 3GPP specifications to generate test cases tailored to the packet structures of the lower layers. This ensures that the test cases are syntactically valid and capable of reaching the target layers without being prematurely discarded. In our evaluation of 15 commercial basebands from five major vendors, LLFuzz uncovered nine previously unknown memory corruptions: two in PDCP, two in RLC, and five in MAC layers. These findings demonstrate LLFuzz's effectiveness in finding critical memory corruptions in baseband lower layers."
  },
  {
    "id": 3847,
    "year": 2025,
    "title": "Preventing Artificially Inflated SMS Attacks through Large-Scale Traffic Inspection",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/huh",
    "abstract": "Artificially inflated traffic (AIT) attacks have become a prevalent threat for businesses that rely on SMS-based user verification systems: attackers use bot accounts to initiate intense volume of artificial SMS verification requests. Malicious telecommunication service providers or SMS aggregators are potential cheating entities. To date, however, there is no published literature formally characterizing AIT attacks or investigating attack detection techniques. Several online blogs provide traffic volume inspection suggestions without revealing implementation details and attack data. We bridge this gap, and for the first time formally characterize AIT attack techniques based on a large-scale dataset consisting of 9.4 million SMS request logs: our analysis reveals that attacks often use short-lived email services, and reuse common prefix values to rapidly generate unverified phone numbers and IMEI numbers. To bypass rate limit policies, bots are programmed to submit a few requests before switching to a different account, phone number or device. This distributed nature of the attack makes detection based on naive historical-event inspection extremely challenging.\nWe propose a novel AIT attack detection system that monitors such scattered attack orchestration from three different levels: machine learning features are extracted based on a single request information, multiple historical events associated with a user, phone number, or device, and country-wide suspicious traffic that has some ties to the request being inspected. A pivotal country-wide feature, for example, counts the number of distinct phone numbers associated with a given prefix value from the last 24 hour traffic. Based on this three-level feature engineering technique and a fixed threshold, we report 89.6% recall rate (false positive rate: 0.2%) on authentication requests initiated through the web client, and 91.1% recall rate (FPR: 0.1%) on the native application client traffic."
  },
  {
    "id": 3848,
    "year": 2025,
    "title": "GLaDoS: Location-aware Denial-of-Service of Cellular Networks",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/erni",
    "abstract": "Cellular communication is ubiquitous, but must be controlled in sensitive industrial and government areas. Existing cellular jamming systems rely on high-power, wide-band transmissions, which are non-selective and can cause interference in neighboring areas, e.g., blocking emergency calls. Also, meeting both the health limits of radio emissions and installation constraints while achieving effective coverage is highly challenging and sometimes even impossible.\nRecent work introduced more power-efficient uplink protocol-level DoS attacks, which can effectively neutralize a connection from anywhere in the area covered by a base station. However, these attacks still need to be made selective to block communication only within a defined area and need to be able to detect all connections for all cells in the vicinity. In practice, this detection can be difficult if the cells are far away or under adverse channel effects. In contrast, a phone might be positioned in a strong radio path, allowing it to connect to such a cell.\nTo address the above challenges, we propose GLaDoS, a system that improves existing uplink protocol-level overshadowing approaches and combines them with low-power wide-band noise jamming to resolve weak cell issues. GLaDoS further limits DoS to the controlled area by integrating overshadowing with an off-the-shelf localization system. \nWe deployed and evaluated our system in an 62500$m^2$ area, close to an urban area, where the use of cellular phones is not allowed, but is fully covered by over 100 commercial operator cells. Our deployment made use of 4 protocol-level DoS units, approximately 40 outdoor and 100 indoor low-power jamming units, along with corresponding antennas and front end units. We evaluated our system within this area against different phone models and measured that our system neutralizes 99.3% of all connections, while being able to track over 100 cells simultaneously. This is the first full-scale deployment of an overshadowing-based cellular communication control system."
  },
  {
    "id": 3849,
    "year": 2025,
    "title": "AKMA+: Security and Privacy-Enhanced and Standard-Compatible AKMA for 5G Communication",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/yang-yang",
    "abstract": "The Authentication and Key Management for Applications (AKMA) protocol is a fundamental building block for security and privacy of 5G cellular networks. Therefore, it is critical that the protocol is free of vulnerabilities that can be exploited by attackers. Unfortunately, based on a detailed analysis of AKMA, we show that AKMA has several vulnerabilities that may lead to security and privacy breaches. \nWe define AKMA+, an enhanced protocol for 5G communication that protects against security and privacy breaches while maintaining compatibility with existing standards. AKMA+ includes countermeasures for protecting communication between the user equipment (UE) and application functions (AFs) from attackers, including those within the home public land mobile network. These countermeasures ensure mutual authentication between the UE and the AKMA anchor function without altering the protocol flow. We also address vulnerabilities related to subscriber and AKMA key identifiers that could be exploited in linkability attacks. By obfuscating this data, AKMA+ prevents attackers from associating a target UE with its past application access. \nWe employ formal verification to demonstrate that AKMA+ achieves key security and privacy objectives. We conduct extensive experiments demonstrating that AKMA+ incurs acceptable computational overhead, bandwidth costs, and UE battery consumption."
  },
  {
    "id": 3850,
    "year": 2025,
    "title": "A Thorough Security Analysis of BLE Proximity Tracking Protocols",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/liu-xiaofeng",
    "abstract": "Recent advances in Bluetooth Low Energy (BLE) and the ubiquity of mobile infrastructures promote the prevalence of BLE proximity tracking services (e.g., Apple Find My and Samsung Find My Mobile) that use the proximity measured from other surrounding mobile devices (e.g., smartphones). Accordingly, it raises severe security and privacy concerns that are inherent to the basis of the technique (i.e., BLE) and the design of the proximity tracking protocol on top of it. Unfortunately, a systematic and comprehensive analysis of these protocols is still missing since the analysis of these protocols in existing research either focuses on a single participant in the service or lacks formal guarantees. As such, in this paper, we aim to fill in the missing piece by (1) recovering the closed-source protocol via reverse engineering; (2) building formal models based on reverse engineering; (3) extracting and formalizing the designed security goals of these protocols, and (4) formally verifying whether these security goals can be guaranteed. We reverse-engineered and verified two of the most popular real-world proximity tracking services, i.e., Apple Find My and Samsung Find My Mobile. In total, our analysis reveals seven new vulnerabilities confirmed by related vendors, out of which, four CVE/SVE numbers are assigned, including three high-severity vulnerabilities. We also propose mitigations to the discovered vulnerabilities and formally confirm that all security goals can be achieved with our mitigations. At the time of paper writing, Samsung has fixed five vulnerabilities with our assistance."
  },
  {
    "id": 3851,
    "year": 2025,
    "title": "Gotta Detect 'Em All: Fake Base Station and Multi-Step Attack Detection in Cellular Networks",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/mubasshir",
    "abstract": "Fake base stations (FBSes) pose a significant security threat by impersonating legitimate base stations (BSes). Though efforts have been made to defeat this threat, up to this day, the presence of FBSes and the multi-step attacks (MSAs) stemming from them can lead to unauthorized surveillance, interception of sensitive information, and disruption of network services. Therefore, detecting these malicious entities is crucial to ensure the security and reliability of cellular networks. In this paper, we develop FBSDetector-an effective and efficient detection solution that can reliably detect FBSes and MSAs from layer-3 network traces using machine learning (ML) at the user equipment (UE) side. To develop FBSDetector, we create FBSAD and MSAD, the first-ever high-quality and large-scale datasets incorporating instances of FBSes and 21 MSAs. These datasets capture the network traces in different real-world cellular network scenarios (including mobility and different attacker capabilities) incorporating legitimate BSes and FBSes. Our novel ML framework, specifically designed to detect FBSes in a multi-level approach for packet classification using stateful LSTM with attention and trace level classification and MSAs using graph learning, can effectively detect FBSes with an accuracy of 96% and a false positive rate of 2.96%, and recognize MSAs with an accuracy of 86% and a false positive rate of 3.28%. We deploy FBSDetector as a real-world solution to protect end-users through a mobile app and extensively validate it in real-world environments. Compared to the existing heuristic-based solutions that fail to detect FBSes, FBSDetector can detect FBSes in the wild in real time."
  },
  {
    "id": 3852,
    "year": 2025,
    "title": "SNI5GECT: A Practical Approach to Inject aNRchy into 5G NR",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/luo-shijie",
    "abstract": "In this paper, we propose and design SNI5GECT– a framework that sniffs messages from pre-authentication 5G communication in real-time and injects targeted attack payload in downlink communication towards the UE. As opposed to using a rogue base station which limits the practicality of many 5G attacks, SNI5GECT acts as a third-party in the communication, silently sniffs messages, and tracks the protocol state by decoding the sniffed messages during the UE attach procedure. The state information is then used to inject targeted attack payload in downlink communication. We have implemented SNI5GECT and evaluated it with five 5G enabled UE devices and with both open-source (srsRAN) and commercial (Effnet) base stations (gNBs). Our evaluation reveals that SNI5GECT obtains over 80% accuracy in uplink and downlink sniffing, and successfully injects messages at an arbitrary protocol state with a 70%-90% success rate up to 20m of distance between UE and SNI5GECT. We further evaluate SNI5GECT to launch a variety of attacks that crash the UE, downgrade the connection to lower generation or extract the UE identity with an attack success rate often over 70% with known UE distance. Finally, we discover a new multi-stage, downgrade attack leveraging the SNI5GECT framework. The risk of this attack has been acknowledged by GSMA and a coordinated vulnerability disclosure (CVD) identity has been assigned. Thus, SNI5GECT is a practical and complementary tool for evaluating current and new 5G attacks in the wild."
  },
  {
    "id": 3853,
    "year": 2025,
    "title": "CoreCrisis: Threat-Guided and Context-Aware Iterative Learning and Fuzzing of 5G Core Networks",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/dong-yilu",
    "abstract": "We develop CoreCrisis, a stateful black-box fuzz-testing framework for 5G core network (5GC) implementations. Unlike previous stateful security analysis efforts of cellular networks which rely on manually-crafted, static test inputs and are limited to identifying only logical errors, CoreCrisis employs a dynamic two-step approach. Initially, CoreCrisis builds an initial finite state machine (FSM) representation of the 5GC's implementation using only benign (i.e., positive) inputs with its efficient and scalable divide-and-conquer and property-driven equivalence checking learning. During fuzzing, it utilizes the learned FSM to target underexplored states and introduces state-aware mutations to generate and test attacking (i.e., negative) inputs. Based on the responses observed from the core network, CoreCrisis continuously refines the FSM to better guide its exploration and find vulnerabilities. Evaluating CoreCrisis on three open-source and one commercial 5GC implementations, we identified 7 categories of deviations from the technical specifications and 13 crashing vulnerabilities. These logical and crashing vulnerabilities lead to denial-of-service, authentication bypass, and billing fraud."
  },
  {
    "id": 3854,
    "year": 2025,
    "title": "eSIMplicity or eSIMplification? Privacy and Security Risks in the eSIM Ecosystem",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/motallebighomi",
    "abstract": "eSIM (Embedded Subscriber Identity Module) technology is rapidly reshaping mobile connectivity by enabling users to activate cellular services without a physical SIM card. While the flexibility of remote provisioning improves convenience and scalability, particularly for international travelers, it also introduces complex and underexplored privacy and security risks. This paper presents an empirical investigation of how eSIM adoption affects user privacy, focusing on routing transparency, reseller access, and profile control. We first show how travel eSIMs often route user data through third-party networks, including Chinese infrastructure, regardless of user location. This raises concerns about jurisdictional exposure. Second, we analyze the implications of opaque provisioning workflows, documenting how resellers can access sensitive user data, proactively communicate with devices, and assign public IPs without user awareness. Third, we validate operational risks such as deletion failures and profile lock-in using a private LTE testbed. In addition to these empirical contributions, we reflect on the evolving threat landscape of eSIM technology and analyze the shifting trust boundaries introduced by its global provisioning architecture. We conclude with actionable recommendations for improving eSIM transparency, user control, and regulatory enforcement as the technology becomes widespread across smartphones, IoT deployments, and private networks."
  },
  {
    "id": 3855,
    "year": 2025,
    "title": "Disparate Privacy Vulnerability: Targeted Attribute Inference Attacks and Defenses",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/kabir",
    "abstract": "As machine learning (ML) technologies become more prevalent in privacy-sensitive areas like healthcare and finance, eventually incorporating sensitive information in building data-driven algorithms, it is vital to scrutinize whether these data face any privacy leakage risks. One potential threat arises from an adversary querying trained models using the public, non-sensitive attributes of entities in the training data to infer their private, sensitive attributes, a technique known as the attribute inference attack. This attack is particularly deceptive because, while it may perform poorly in predicting sensitive attributes across the entire dataset, it excels at predicting the sensitive attributes of records from a few vulnerable groups, a phenomenon known as disparate vulnerability. This paper illustrates that an adversary can take advantage of this disparity to carry out a series of new attacks, showcasing a threat level beyond previous imagination. We first develop a novel inference attack called the disparity inference attack, which targets the identification of high-risk groups within the dataset. We then introduce two targeted variations of the attribute inference attack that can identify and exploit a vulnerable subset of the training data, marking the first instances of targeted attacks in this category, achieving significantly higher accuracy than untargeted versions. We are also the first to introduce a novel and effective disparity mitigation technique that simultaneously preserves model performance and prevents any risk of targeted attacks."
  },
  {
    "id": 3856,
    "year": 2025,
    "title": "Enhanced Label-Only Membership Inference Attacks with Fewer Queries",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/li-hao",
    "abstract": "Machine Learning (ML) models are vulnerable to membership inference attacks (MIAs), where an adversary aims to determine whether a specific sample was part of the model's training data. Traditional MIAs exploit differences in the model's output posteriors, but in more challenging scenarios (label-only scenarios) where only predicted labels are available, existing works directly utilize the shortest distance of samples reaching decision boundaries as membership signals, denoted as the shortestBD. However, they face two key challenges: low distinguishability between members and non-members due to sample diversity, and high query requirements stemming from direction diversity.\nTo overcome these limitations, we propose a novel label-only attack called DHAttack, designed for Higher performance and Higher stealth, focusing on the boundary distance of individual samples to mitigate the effects of sample diversity, and measuring this distance toward a fixed point to minimize query overhead. Empirical results demonstrate that DHAttack consistently outperforms other advanced attack methods. Notably, in some cases, DHAttack achieves more than an order of magnitude improvement over all baselines in terms of TPR @ 0.1% FPR with just 5 to 30 queries. Furthermore, we explore the reasons for DHAttack's success, and then analyze other crucial factors in the attack performance. Finally, we evaluate several defense mechanisms against DHAttack and demonstrate its superiority over all baseline attacks."
  },
  {
    "id": 3857,
    "year": 2025,
    "title": "For Human Ears Only: Preventing Automated Monitoring on Voice Data",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/shahid",
    "abstract": "As voice communication becomes an essential part of modern life, the exposure of sensitive information through audio calls presents significant privacy risks. Malicious actors can gain access to this data by compromising user devices, exploiting communication channels, or attacking data servers, making it vulnerable to automated monitoring systems that can identify speakers and extract speech content. To address these privacy concerns, we introduce VoiceSecure, the first microphone module designed to prevent automated monitoring of speech while preserving its natural sound for humans. By leveraging the principles of human auditory perception, VoiceSecure employs a set of speech modifications that are adaptively tuned in real-time to obscure speaker identity and speech content, without compromising the quality of the audio for human listeners. This hardware-based solution mitigates the risk of software-based attacks, integrating seamlessly with commercial devices via audio jack or Bluetooth. Comprehensive evaluation across the state-of-the-art speaker verification and speech recognition models, and a variety of speech datasets demonstrates that VoiceSecure outperforms traditional methods of protecting speech from automated monitoring while keeping it intelligible for humans"
  },
  {
    "id": 3858,
    "year": 2025,
    "title": "Towards a Re-evaluation of Data Forging Attacks in Practice",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/suliman",
    "abstract": "Data forging attacks provide counterfactual proof that a model was trained on a given dataset, when in fact, it was trained on another. These attacks work by forging (replacing) mini-batches with ones containing distinct training examples that produce nearly identical gradients. Data forging appears to break any potential avenues for data governance, as adversarial model owners may forge their training set from a dataset that is not compliant to one that is. Given these serious implications on data auditing and compliance, we critically analyse data forging from both a practical and theoretical point of view, finding that a key practical limitation of current attack methods makes them easily detectable by a verifier; namely that they cannot produce sufficiently identical gradients. Theoretically, we analyse the question of whether two distinct mini-batches can produce the same gradient. Generally, we find that while there may exist an infinite number of distinct mini-batches with real-valued training examples and labels that produce the same gradient, finding those that are within the allowed domain e.g. pixel values between 0-255 and one hot labels is a non trivial task. Our results call for the reevaluation of the strength of existing attacks, and for additional research into successful data forging, given the serious consequences it may have on machine learning and privacy."
  },
  {
    "id": 3859,
    "year": 2025,
    "title": "Free Record-Level Privacy Risk Evaluation Through Artifact-Based Methods",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/pollock",
    "abstract": "Membership inference attacks (MIAs) are widely used to empirically assess privacy risks in machine learning models, both providing model-level vulnerability metrics and identifying the most vulnerable training samples. State-of-the-art methods, however, require training hundreds of shadow models with the same architecture as the target model. This makes the computational cost of assessing the privacy of models prohibitive for many practical applications, particularly when used iteratively as part of the model development process and for large models. We propose a novel approach for identifying the training samples most vulnerable to membership inference attacks by analyzing artifacts naturally available during the training process. Our method, Loss Trace Interquartile Range (LT-IQR), analyzes per-sample loss trajectories collected during model training to identify high-risk samples without requiring any additional model training. Through experiments on standard benchmarks, we demonstrate that LT-IQR achieves 92% precision@k=1% in identifying the samples most vulnerable to state-of-the-art MIAs. This result holds across datasets and model architectures with LT-IQR outperforming both traditional vulnerability metrics, such as loss, and lightweight MIAs using few shadow models. We also show LT-IQR to accurately identify points vulnerable to multiple MIA methods and perform ablation studies. We believe LT-IQR enables model developers to identify vulnerable training samples, for free, as part of the model development process. Our results emphasize the potential of artifact-based methods to efficiently evaluate privacy risks."
  },
  {
    "id": 3860,
    "year": 2025,
    "title": "Rectifying Privacy and Efficacy Measurements in Machine Unlearning: A New Inference Attack Perspective",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/naderloui",
    "abstract": "Machine unlearning focuses on efficiently removing specific data from trained models, addressing privacy and compliance concerns while managing computational costs. Although exact unlearning ensures complete data removal equivalent to retraining, it is impractical for large-scale models, leading to growing interest in inexact unlearning methods. However, the lack of formal guarantees in these methods necessitates the need for robust evaluation frameworks to assess their privacy and effectiveness. In this work, we present RULI (Rectified Unlearning via Likelihood Inference), a novel framework designed to address critical gaps in the evaluation of inexact unlearning methods. Unlike existing approaches that emphasize average-case privacy leakage and the recent U-LiRA, RULI introduces a dual-objective attack to measure both unlearning efficacy and privacy risks at a per-sample granularity. Our findings reveal significant vulnerabilities in state-of-the-art unlearning benchmarks, where RULI achieves higher attack success rates, exposing privacy risks underestimated by existing methods. We also underscore the limitations of existing evaluation frameworks and highlight the benefits of targeted analysis for identifying vulnerable samples. Built on a game-theoretic foundation and supported by empirical evaluations, RULI provides a rigorous, scalable, and fine-grained methodology for evaluating unlearning techniques. This work lays the groundwork for future designs of unlearning algorithms, focusing on both practical privacy guarantees and robust efficacy measurements."
  },
  {
    "id": 3861,
    "year": 2025,
    "title": "Phantom: Privacy-Preserving Deep Neural Network Model Obfuscation in Heterogeneous TEE and GPU System",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/bai-juyang",
    "abstract": "In this work, we present Phantom, a novel privacy-preserving framework for obfuscating deep neural network (DNN) model deployed in heterogeneous TEE/GPU systems. Phantom employs reinforcement learning to add lightweight obfuscation layers, degrading model performance for adversaries while maintaining functionality for authorized user. To reduce the off-chip data communication between TEE and GPU, we propose a Top-K layer-wise obfuscation sensitivity analysis method. Extensive experiments demonstrate Phantom's superiority over state-of-the-art (SoTA) defense methods against model stealing and fine-tuning attacks across various architectures and datasets. It reduces unauthorized accuracy to near-random guessing (e.g., 10% for CIFAR-10 tasks, 1% for CIFAR-100 tasks) and achieves a 6.99% average attack success rate for model stealing, significantly outperforming SoTA competing methods. System implementation on Intel SGX2 and NVIDIA GPU heterogeneous system achieves 35% end-to-end latency reduction compared with most recent SoTA work."
  },
  {
    "id": 3862,
    "year": 2025,
    "title": "LOHEN: Layer-wise Optimizations for Neural Network Inferences over Encrypted Data with High Performance or Accuracy",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/nam-lohen",
    "abstract": "Fully Homomorphic Encryption (FHE) presents unique challenges in programming due to the contrast between traditional and FHE language paradigms. A key challenge is selecting ciphertext configurations (CCs) to achieve the desired level of security, performance, and accuracy simultaneously. Finding the design point satisfying the goal is often labor-intensive (probably impossible), for which reason previous works settle down to a reasonable CC that brings acceptable performance. When FHE is applied to neural networks (NNs), we have observed that the distinct layered architecture of NN models opens the door for a performance improvement by using layer-wise CCs, because a globally chosen CC may not be the best possible CC for every layer individually. This paper introduces LOHEN, a technique crafted to attain high performance of NN inference by enabling to use layer-wise CC efficiently. Empowered with a cryptographic gadget that allows switching between arbitrary CCs, LOHEN allocates layer-wise CCs for individual layers tailored to their structural properties, while minimizing the increased overhead incurred by CC switching with its capability to replace costly FHE operations. LOHEN can also be engineered to attain higher accuracy, yet deliver higher performance compared to state-of-the-art studies, by additionally adopting the multi-scheme techniques in a layer-wise manner. Moreover, the developers using LOHEN are given the capability of customizing the selection policy to adjust the desired levels of performance and accuracy, subject to their demands. Our evaluation shows that LOHEN improves the NN inference performance in both of these cases when compared to the state-of-the-art. When used to improve the CKKS-only inference, LOHEN improves the NN inference performance of various NNs 1.08–2.88x. LOHEN also improves the performance of mixed-scheme NN inference by 1.34–1.75x without accuracy loss. These two results along with other empirical analyses, advocate that LOHEN can widely help improve the performance of NN inference over FHE."
  },
  {
    "id": 3863,
    "year": 2025,
    "title": "SoK: Data Reconstruction Attacks Against Machine Learning Models: Definition, Metrics, and Benchmark",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/wen",
    "abstract": "Data reconstruction attacks, which aim to recover the training dataset of a target model with limited access, have gained increasing attention in recent years. However, there is currently no consensus on a formal definition of data reconstruction attacks or appropriate evaluation metrics for measuring their quality. This lack of rigorous definitions and universal metrics has hindered further advancement in this field. In this paper, we address this issue in the vision domain by proposing a unified attack taxonomy and formal definitions of data reconstruction attacks. We first propose a set of quantitative evaluation metrics that consider important criteria such as quantifiability, consistency, precision, and diversity. Additionally, we leverage large language models (LLMs) as a substitute for human judgment, enabling visual evaluation with an emphasis on high-quality reconstructions. Using our proposed taxonomy and metrics, we present a unified framework for systematically evaluating the strengths and limitations of existing attacks and establishing a benchmark for future research. Empirical results, primarily from a memorization perspective, not only validate the effectiveness of our metrics but also offer valuable insights for designing new attacks."
  },
  {
    "id": 3864,
    "year": 2025,
    "title": "McSee: Evaluating Advanced Rowhammer Attacks and Defenses via Automated DRAM Traffic Analysis",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/jattke",
    "abstract": "Rowhammer attacks and defenses are continuously evolving. Recent attacks rely on hammering multiple banks or keeping rows activated for long durations. On the defense side, DDR5 standard requires memory controllers to send Refresh Management (RFM) commands when a specific DRAM bank receives too many activations. Are advanced Rowhammer attacks adequately exploiting their target features and do memory controllers send RFM commands adequately? This paper answers these questions by building an automated software platform, called McSee, on top of a highfrequency oscilloscope for studying the behavior of DDR4 and DDR5 memory controllers under Rowhammer attacks. Leveraging a series of hardware and software optimizations, McSee is capable of reliably capturing and efficiently decoding single-cycle DDR4 and multi-cycle DDR5 traffic on the DRAM bus. We make a number of key discoveries using McSee: first, we show that hammering too many banks in parallel can actually be detrimental to the performance of Rowhammer attacks. Second, rows remain active far shorter than assumed when considering the recent Rowpress attack. Third, we show that neither Intel nor AMD CPUs send RFM commands even though a third of the DDR5 devices in our test pool require RFM for properly mitigating Rowhammer. Fourth, we uncover that instead of RFM, the memory controllers of Intel platforms rely on additional mitigative activations which we characterize for the first time. We conclude by discussing the implications of our findings on the landscape of Rowhammer attacks and defenses"
  },
  {
    "id": 3865,
    "year": 2025,
    "title": "Not so Refreshing: Attacking GPUs using RFM Rowhammer Mitigation",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/nazaraliyev",
    "abstract": "Graphics Processing Units (GPUs) have become a critical part of computing systems at all scales. In this paper, we demonstrate new side channel attacks targeting the Graphics DDR (GDDR) memory chips. While several studies have demonstrated attacks on CPU memory chips, revealing potential security vulnerabilities, these attacks do not easily transfer to GPU memories, due to differences in the microarchitecture and operational characteristics of GDDR memory and GPU memory controllers, as well as the distinct computational model of GPUs. We reverse-engineer the mapping of physical addresses to GDDR physical bank addresses and show that existing row buffer timing attacks on these systems are ineffective due to row buffer management policies. Instead, our attacks target the Refresh Management (RFM) feature engineered into modern memories to mitigate Rowhammer vulnerabilities. We identify RFM-based timing leakage where repeated accesses to the same bank trigger refresh events, leading to measurable differences in access times. We exploit this leakage to first construct covert channel attacks on a shared GPU, achieving a bandwidth of over 50 KBps per bank with a low error rate of 0.03%. We demonstrate two end-to-end side-channel attacks on discrete GPUs with GDDR6: application fingerprinting and 3D object rendering fingerprinting within Blender, achieving F1 scores of up to 95% and 98%, respectively. Additionally, we implement three side-channel attacks on GPU-based SoCs using LPDDR5 memory: application fingerprinting, web fingerprinting, and video fingerprinting, achieving high F1 scores. Finally, we present a Denial of Service (DoS) attack, where the attacker leverages the RFM blocking to slow down applications by over 4.8× on average."
  },
  {
    "id": 3866,
    "year": 2025,
    "title": "Posthammer: Pervasive Browser-based Rowhammer Attacks with Postponed Refresh Commands",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/de-ridder",
    "abstract": "Rowhammer attacks are pervasive in client systems when launched natively. The biggest Rowhammer threat for such systems, however, lies in the browser. Our large-scale evaluation of browser-based Rowhammer attacks shows that they can only trigger bit flips on a small fraction of DRAM devices. Postponing refresh commands that trigger in-DRAM mitigations can boost the performance of Rowhammer attacks, but it has never been demonstrated in practice. \nWe introduce Posthammer, a new Rowhammer attack in JavaScript that forces the CPU's memory controller to postpone refresh commands by creating long durations of intense Rowhammer activity followed by sufficiently long delay windows to allow the memory controller to batch refresh commands. Posthammer features a new abstraction called lane, which enables a subset of addresses in a Rowhammer pattern to be accessed more often. Lanes enable Posthammer to support effective refresh-postponed non-uniform patterns in the browser for the first time. Our evaluation shows that Posthammer is 2.8× more effective than the state of the art, triggering bit flips on 86% of our 28 DDR4 test devices."
  },
  {
    "id": 3867,
    "year": 2025,
    "title": "ECC.fail: Mounting Rowhammer Attacks on DDR4 Servers with ECC Memory",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/kamadan",
    "abstract": "Rowhammer is a hardware vulnerability present in nearly all computer memory, allowing attackers to modify bits in memory without directly accessing them. While Rowhammer has been extensively studied on client and even mobile platforms, no successful Rowhammer attack has been demonstrated on server platforms using DDR4 ECC memory.\nTackling this challenge, in this paper we demonstrate the first end-to-end Rowhammer technique effective against Intel servers using Hynix DDR4 ECC memory. To that aim, we first characterize the Hynix implementation of Target Row Refresh (TRR) on server parts, demonstrating effective hammering patterns on both FPGA and Intel-based testing platforms with ECC disabled. We then reverse engineer Intel's ECC implementation on Skylake and Cascade Lake servers. We find that it has a coding distance of four, which often allows triggering incorrect ECC correction with just two bit flips.\nCombining the two observations, we present an end-to-end Rowhammer attack which can flip bits on Intel servers, without causing crashes. Finally, we demonstrate the effectiveness of our attack by hammering RSA public keys loaded into memory, causing the server to accept messages not signed by the original key."
  },
  {
    "id": 3868,
    "year": 2025,
    "title": "Relocate-Vote: Using Sparsity Information to Exploit Ciphertext Side-Channels",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/yan-yuqin",
    "abstract": "Confidential computing implementations encrypt guest Virtual Machine (VM) memory to protect workloads from a malicious hypervisor. However, its use of system physical addresses as tweak values causes deterministic encryption for each physical memory address, creating a ciphertext side-channel. To exploit this weakness, we propose Relocate-Vote, a novel primitive that exposes frequency distributions across various memory locations by abusing management commands supported by confidential computing architectures such as SNP_PAGE_MOVE in AMD SEV-SNP. Unlike previous attacks that rely on secret information temporally written into specific locations, Relocate-Vote takes advantage of biases in the distribution of values that applications naturally exhibit, which are preserved under memory encryption with the same tweak values, and uses the spatial distribution of those values to leak sensitive information from confidential VMs. In this work, we demonstrate the generality of this attack primitive by using it to de-randomize Address Space Layout Randomization, extract 3D object data from OpenVDB, and leak token information during sparse LLM inference."
  },
  {
    "id": 3869,
    "year": 2025,
    "title": "GPUHammer: Rowhammer Attacks on GPU Memories are Practical",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/lin-shaopeng",
    "abstract": "Rowhammer is a read disturbance vulnerability in modern DRAM that causes bit-flips, compromising security and reliability. While extensively studied on Intel and AMD CPUs with DDR and LPDDR memories, its impact on GPUs using GDDR memories, critical for emerging machine learning applications, remains unexplored. Rowhammer attacks on GPUs face unique challenges: (1) proprietary mapping of physical memory to GDDR banks and rows, (2) high memory latency and faster refresh rates that hinder effective hammering, and (3) proprietary mitigations in GDDR memories, difficult to reverse-engineer without FPGA-based test platforms.\nWe introduce GPUHammer, the first Rowhammer attack on NVIDIA GPUs with GDDR6 DRAM. GPUHammer proposes novel techniques to reverse-engineer GDDR DRAM row mappings, and employs GPU-specific memory access optimizations to amplify hammering intensity and bypass mitigations. Thus, we demonstrate the first successful Rowhammer attack on a discrete GPU, injecting up to 8 bit-flips across 4 DRAM banks on an NVIDIA A6000 with GDDR6 memory. We also show how an attacker can use these to tamper with ML models, causing significant accuracy drops (up to 80%)."
  },
  {
    "id": 3870,
    "year": 2025,
    "title": "SCASE: Automated Secret Recovery via Side-Channel-Assisted Symbolic Execution",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/weber",
    "abstract": "In recent years, there has been an explosion of research on software-based side-channel attacks, which commonly require an in-depth understanding of the victim application to extract sensitive information. With evermore leakage sources and targets, an important remaining challenge is how to automatically reconstruct secrets from side-channel traces.\nThis paper proposes SCASE, a novel methodology for inferring secrets from an opaque victim binary using symbolic execution, guided by a concrete side-channel trace. Our key innovation is in utilizing the memory accesses observed in the side-channel trace to effectively prune the symbolic-execution space, thus avoiding state explosion. To demonstrate the effectiveness of our approach, we introduce Athena, a proof-of-concept framework to automatically recover secrets from Intel SGX enclaves via controlled channels. We show that Athena can automatically recover the 2048-bit secret key of an enclave running RSA within 4 minutes and the 256-bit key from an RC4 KSA implementation within 5 minutes. Furthermore, we demonstrate key recovery of OpenSSL's 256-bit AES S-Box implementation and recover the inputs to OpenSSL's binary extended Euclidean algorithm. To demonstrate the versatility of our approach beyond cryptographic applications, we further recover the input to a poker-hand evaluator. In conclusion, our findings indicate that constraining symbolic execution via side-channel traces is an effective way to automate software-based side-channel attacks without requiring an in-depth understanding of the victim application."
  },
  {
    "id": 3871,
    "year": 2025,
    "title": "Shadows in Cipher Spaces: Exploiting Tweak Repetition in Hardware Memory Encryption",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/peng-wei",
    "abstract": "Hardware memory encryption serves as the foundation for TEE security, where processors transparently encrypt data bound for DRAM while maintaining plaintext within CPU boundaries—a critical defense against physical attacks like memory bus snooping and cold-boot attacks. Although ubiquitous in major TEE implementations (Intel SGX/TDX, AMD SEV), design flaws have introduced severe vulnerabilities including ciphertext replacement attacks, ciphertext replay attacks, and ciphertext side-channel attacks.\nOur work makes three key contributions: First, we present the first comprehensive analysis of Hygon CSV's memory encryption engine, a prominent TEE in China's confidential computing market. Second, we identify a novel vulnerability class stemming from tweak value repetition within 64-byte blocks, causing identical 16-byte plaintexts to generate identical ciphertexts. Third, we demonstrate how this enables CipherShadow Attacks through: (1) an automated binary scanner detecting vulnerable code patterns, (2) end-to-end attacks demonstrating both OpenSSH authentication bypass and machine learning training data reconstruction."
  },
  {
    "id": 3872,
    "year": 2025,
    "title": "Breaking the Blindfold: Deep Learning-based Blind Side-channel Analysis",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/rezaeezade",
    "abstract": "Physical side-channel analysis (SCA) operates on the foundational assumption of access to known plaintext or ciphertext. However, this assumption can be easily invalidated in various scenarios, ranging from common encryption modes like Offset CodeBook (OCB) to complex hardware implementations, where such data may be inaccessible. Blind SCA addresses this challenge by operating without the knowledge of plaintext or ciphertext. Unfortunately, prior such approaches have shown limited success in practical settings.\nThis paper introduces the Deep Learning-based Blind Side-channel Analysis (DL-BSCA) framework, leveraging deep neural networks to recover secret keys in blind SCA settings. In addition, we propose a novel labeling method, Multi-point Cluster-based (MC) labeling, accounting for dependencies between leakage variables by exploiting multiple sample points for each variable, improving the accuracy of trace labeling. We validate our approach across four datasets, including symmetric key algorithms (AES and Ascon) and a post-quantum cryptography algorithm, Kyber, with platforms ranging from high-leakage 8-bit AVR XMEGA to noisy 32-bit ARM STM32F4. Notably, previous methods failed to recover the key on the same datasets. We demonstrate the first successful blind SCA on a desynchronization countermeasure enabled by DL-BSCA and MC labeling. All experiments are validated with real-world SCA measurements, highlighting the practicality and effectiveness of our approach."
  },
  {
    "id": 3873,
    "year": 2025,
    "title": "Evaluating Privacy Policies under Modern Privacy Laws At Scale: An LLM-Based Automated Approach",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/xie",
    "abstract": "Website privacy policies detail an online service's information practices, including how they handle user data and rights. For many sites, these disclosures are now necessitated by a growing set of privacy regulations, such as GDPR and multiple US state laws, offering visibility into privacy practices that are often not publicly observable. Motivated by this visibility, prior work has explored techniques for automated analysis of privacy policies and characterized specific aspects of real-world policies on a larger scale. However, existing approaches are constrained in the privacy practices they evaluate, as they rely upon rule-based methods or supervised classifiers, and many predate the prominent privacy laws now enacted that drastically shape privacy disclosures. Thus, we lack a comprehensive understanding of modern website privacy practices disclosed through privacy policies.\nIn this work, we seek to close this gap by providing a systematic and comprehensive evaluation of website privacy policies at scale. We first systematize the privacy practices discussed by 10 notable privacy regulations currently in effect in the European Union and the US, identifying 34 distinct clauses on privacy practices across 4 overarching themes. We then develop and evaluate an LLM-based approach for assessing these clauses in privacy policies, providing a more accurate, comprehensive, and flexible analysis compared to prior techniques. Finally, we collect privacy policies from over 100K websites, and apply our LLM method to a subset of sites to investigate in-depth the privacy practices of websites today. Ultimately, our work supports broader investigations into web privacy practices moving forward."
  },
  {
    "id": 3874,
    "year": 2025,
    "title": "Navigating Cookie Consent Violations Across the Globe",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/tang",
    "abstract": "Online services provide users with cookie banners to accept/reject the cookies placed on their web browsers. Despite the increased adoption of cookie banners, little has been done to detect and understand the behavior of cookie consent from a global perspective. Prior studies have found that cookies are often placed on browsers even after users have explicitly rejected them. These inconsistencies in cookie banner behavior circumvent users' consent preferences and are known as cookie consent violations. To address this important problem, we propose an end-to-end measurement system, called ConsentChk, that detects and analyzes cookie banner behavior. ConsentChk uses a formal model to systematically detect and categorize cookie consent violations. We investigate 8 English-speaking regions across the world, and analyze cookie banner behavior across 1,793 globally-popular websites. Cookie behavior, cookie consent violation rates, and cookie banner implementations are found to be highly dependent on region. Our evaluation reveals that consent management platforms (CMPs) and website developers likely tailor cookie banner configurations based on their (often incorrect) interpretations of regional privacy laws. We discuss various root causes behind these cookie consent violations. The resulting implementations produce misleading cookie banners, indicating the prevalence of inconsistently implemented and enforced cookie consent between various regions."
  },
  {
    "id": 3875,
    "year": 2025,
    "title": "Websites' Global Privacy Control Compliance at Scale and over Time",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/hausladen",
    "abstract": "The California Consumer Privacy Act (CCPA) gives California residents the right to opt out of the sale or sharing of their personal information via Global Privacy Control (GPC). In this study we show how to evaluate websites' compliance with GPC. Using longitudinal data collected by crawling a set of 11,708 sites, we show the extent to which sites are respecting California residents' opt out rights expressed via GPC. We do so by examining the values of four privacy strings that indicate a web user's opt out status: the US Privacy String, the Global Privacy Platform String, the OptanonConsent cookie, and the .wellknown/gpc.json. We find that about a third of sites that have evidence of selling or sharing personal information per the CCPA implement at least one of the four privacy strings. In December 2023, 44% (1,411/3,226) of such sites opted users out via all implemented privacy strings. In February 2024, this percentage decreased to 43% (1,473/3,402) before increasing to 45% (1,620/3,566) in April 2024. Despite the slight uptick between December 2023 and April 2024, compliance rates remained at a low level overall, indicating widespread disregard for California residents' right to opt out. Our findings highlight the importance of effective enforcement of the CCPA, in particular, with a focus on big web publishers."
  },
  {
    "id": 3876,
    "year": 2025,
    "title": "Privacy Law Enforcement Under Centralized Governance: A Qualitative Analysis of Four Years' Special Privacy Rectification Campaigns",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/jing",
    "abstract": "In recent years, major privacy laws like the GDPR have brought about positive changes. However, challenges remain in enforcing the laws, particularly due to under-resourced regulators facing a large number of potential privacy-violating software applications (apps) and the high costs of investigating them. Since 2019, China has launched a series of privacy enforcement campaigns known as Special Privacy Rectification Campaigns (SPRCs) to address widespread privacy violations in its mobile application (app) ecosystem. Unlike the enforcement of the GDPR, SPRCs are characterized by large-scale privacy reviews and strict sanctions, under the strong control of central authorities. In SPRCs, central government authorities issue administrative orders to mobilize various resources for market-wide privacy reviews of mobile apps. They enforce strict sanctions by requiring privacy-violating apps to rectify issues within a short timeframe or face removal from app stores. While there are a few reports on SPRCs, the effectiveness and potential problems of this campaign-style privacy enforcement approach remain unclear to the community. In this study, we conducted 18 semi-structured interviews with app-related engineers involved in SPRCs to better understand the campaign-style privacy enforcement. Based on the interviews, we reported our findings on a variety of aspects of SPRCs, such as the processes that app engineers regularly follow to achieve privacy compliance in SPRCs, the challenges they encounter, the solutions they adopt to address these challenges, and the impacts of SPRCs, etc. We found that app engineers face a series of challenges in achieving privacy compliance in their apps. For example, they receive inconsistent app privacy review reports from multiple app stores and have difficulties confirming the issues flagged by these reports; they also lack institutional support for studying privacy laws, self-validating privacy compliance of their apps, communicating effectively between multiple stakeholders, and ensuring fairness in accountability when privacy non-compliance occurs. Furthermore, we found that while SPRCs have introduced several positive changes, there remain unaddressed concerns, such as the potential existence of circumvention techniques used to evade app privacy reviews."
  },
  {
    "id": 3877,
    "year": 2025,
    "title": "A Stakeholder-Based Framework to Highlight Tensions when Implementing Privacy Features",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/netter",
    "abstract": "Preparing university students to build privacy-preserving systems requires preparing them to design around societal contexts and stakeholders. While legislation such as GDPR and CCPA provide regulatory frameworks for such design, discussions of privacy and stakeholder values can be fairly abstract for students. From an educational perspective, teaching abstract concepts such as the \"right to be forgotten\" in the concrete context of technical implementation can help students grapple with what these concepts mean in practice.\nThis paper proposes a framework for designing technical assignments that ask students to resolve tensions between conflicting stakeholders while implementing a specific technical feature. We describe a privacy-facing assignment for a second-year introductory computer systems course, and explore its efficacy. We find that students make different design choices and implement for different values based on the specific stakeholder conflict with which they work. We also find that the assignment design engages students in thinking about how abstract values affect technical design decisions in the context of privacy."
  },
  {
    "id": 3878,
    "year": 2025,
    "title": "Who Pays Whom? Anonymous EMV-Compliant Contactless Payments",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/olivier-anclin",
    "abstract": "EMV is the de-facto worldwide payment system used by Mastercard, Visa, American Express, and such. In-shop EMV contactless payments are not anonymous or private: the payers' long-term identification data leaks to Merchants or even to observers. Anti-Money Laundering (AML), Know Your Customer (KYC) and Strong Customer Authentication (SCA) are payment regulations protecting us from illegal activities, but –in so doing– contribute chiefly to this lack of privacy in EMV payments. Threading the tightrope of AML, KYC and SCA regulations, we provide two privacy-enhancing, EMV-compatible, law-abiding and practicable contactless-payments protocols: PrivBank and PrivProxy. \nWe do not use privacy-enhancing technology, like homomorphic encryption, that would break backwards-compatibility with current EMV, but rather we do privacy by engineering design, adhering to the existing EMV infrastructure, as is. So, PrivBank and PrivProxy provably achieve strong notions of payers and merchant privacy, anonymity and unlinkability as seen in e-cash or shopping vouchers, whilst being implementable in EMV as it stands."
  },
  {
    "id": 3879,
    "year": 2025,
    "title": "Atkscopes: Multiresolution Adversarial Perturbation as a Unified Attack on Perceptual Hashing and Beyond",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/zhang-yushu",
    "abstract": "Privacy and regulation are a long-lasting conflict in modern instant messaging, where the security community attempts to bridge this gap from a technological perspective. End-to-end encryption (E2EE) is a mathematically guaranteed privacy policy that has been widely built into commercial instant messaging applications. On the other hand, regulatory designs compatible with E2EE privacy are severely restricted, i.e., content auditing is (almost) impossible on ciphertext. For this reason, the community develops perceptual hash matching (PHM) as a regulation policy, where content-aware hash codes for media are computed prior to E2EE and matched against known sensitive media, e.g., child pornography images, on the server side.\nIn this paper, we systematically reveal a range of adversarial threats to such E2EE-PHM systems, leading to regulatory failures. Unlike previous case studies, our attack is a more realistic threat – uniformly fooling the famous Microsoft PhotoDNA, Facebook PDQ, Apple NeuralHash, and pHash, even with higher success rates and less training rounds. Here, we validate the above proposition in both scenarios of escaping and triggering regulation. \nOur main contribution is a new idea of multiresolution perturbation, where each perturbation element can affect image regions of adjustable scales. With this new idea and its well-formalized design, our attack encapsulates previous attacks as special cases – in some scenarios, it exhibits a huge leap in convergence efficiency compared to previous ones. Based on the above technical insights, we also discuss possible countermeasures and recommendations for social good."
  },
  {
    "id": 3880,
    "year": 2025,
    "title": "SpeechGuard: Recoverable and Customizable Speech Privacy Protection",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/zhang-jingmiao",
    "abstract": "Uploading speech data to cloud servers poses privacy risks, making the protection of both acoustic and content privacy essential. Users often need the cloud to process non-sensitive information while protecting sensitive parts, with the ability to recover original data locally. However, achieving speech privacy protection that supports fine-grained customization and full recoverability remains a significant challenge. Existing methods often rely on irreversible or inflexible techniques, such as uniformly anonymizing the entire speech or replacing sensitive texts, making them inadequate for this purpose. We introduce SpeechGuard, a system that enables recoverable and customizable speech privacy protection by applying reversible protection methods and assigning private information to permission groups. We design a multi-parameter warping function with an inverse function for voice conversion to protect acoustic privacy. We also develop a mechanism for automatic or manual detection and encryption of sensitive texts to protect content privacy. By categorizing listeners into permission groups and assigning warping parameters and encryption keys, SpeechGuard enables different listeners to recover varying levels of acoustic and content information according to their permissions, ensuring personalized access to speech data. Experiments on three datasets show that SpeechGuard outperforms three baseline systems in anonymity, sensitive content confidentiality, and attack resistance. Moreover, it provides recoverable and customizable protection for acoustic and content privacy, allowing for tailored privacy definitions and protection strength."
  },
  {
    "id": 3881,
    "year": 2025,
    "title": "Shimmer: a Provably Secure Steganography Based on Entropy Collecting Mechanism",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/bai-minhao",
    "abstract": "This paper introduces a practical and provably secure steganography scheme. Most of practical steganography methods alter the model distribution to conceal private messages, posing security risks. Prior theoretical approaches are grounded in unrealistic assumptions and are not efficiently applicable to real-world scenarios. The potential of practical and provably secure steganographic methods has not been fully realized. To address these challenges, we introduce a novel entropy collection mechanism designed to ensure security and increase capacity. This mechanism captures residual entropy from the previous embedding phase and utilizes it in subsequent embedding steps, thereby increasing embedding capacity. Leveraging this mechanism, we propose Shimmer, a practical and provably secure steganography method with high capacity. We apply an mitigation to minimize the probability of interval splitting events, which maximizes its capacity further. Our experimental results demonstrate that Shimmer achieves highest bitrate compared to other existing practical and provably secure steganography techniques."
  },
  {
    "id": 3882,
    "year": 2025,
    "title": "How Transparent is Usable Privacy and Security Research? A Meta-Study on Current Research Transparency Practices",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/klemmer",
    "abstract": "Transparent research reporting is crucial to understanding and assessing research, its results and validity, and for fostering replication. While other research fields investigated reporting and transparency practices, similar meta-research is missing for the usable privacy and security (UPS) community, which combines security, privacy, and human research. To gain insights into current research transparency practices and their development in the UPS community, we analyzed 200 UPS publications from twelve venues (including USENIX Security, IEEE S&P, CCS, SOUPS, and CHI) from 2018 to 2023. Additionally, we evaluated those venues' 81 calls for papers (CfPs) and 20 calls for artifacts (CfAs). We find that most papers report on many of 52 analyzed transparency criteria, but none achieve full transparency. Moreover, we uncover several areas that need improvements: essential artifacts like questionnaires are frequently missing and hinder replication, some information is reported inconsistently, and dead links further reduce availability. Our regression analysis indicates that paper length and the number of studies described in a paper impact reporting transparency, while we observed no effect of publication year and artifact evaluation (AE). Finally, we provide recommendations for authors, venues, and PC chairs to improve research transparency practices and suggest transparency guidelines."
  },
  {
    "id": 3883,
    "year": 2025,
    "title": "Understanding How Users Prepare for and React to Smartphone Theft",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/bhardwaj",
    "abstract": "Smartphone theft is common, yet little research explores how users prepare for or respond to such incidents. To address this gap in the literature, we conducted 20 semi-structured interviews with victims who had experienced smartphone theft in the past two years. These cases ranged from opportunistic thefts to armed robberies. Our findings show that users are often unprepared and rely on basic protection measures like screen locks. After theft, they attempt to track their phones, activate Lost Mode and frequently turn to family and friends for moral support. Many experience significant distress, particularly from privacy concerns, loss of photos, and disrupted access to essential services like online banking. Recovery is often complicated by challenges such as SMS-based two-factor authentication (2FA). Our study identifies opportunities for phone vendors and service providers to enhance security features and recovery tools that address both technical and social aspects of smartphone theft."
  },
  {
    "id": 3884,
    "year": 2025,
    "title": "Exploring User Security and Privacy Attitudes and Concerns Toward the Use of General-Purpose LLM Chatbots for Mental Health",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/kwesi",
    "abstract": "Individuals are increasingly relying on large language model (LLM)-enabled conversational agents for emotional support. While prior research has examined privacy and security issues in chatbots specifically designed for mental health purposes, these chatbots are overwhelmingly \"rule-based\" offerings that do not leverage generative AI. Little empirical research currently measures users' privacy and security concerns, attitudes, and expectations when using general-purpose LLM-enabled chatbots to manage and improve mental health. Through 21 semi-structured interviews with U.S. participants, we identified critical misconceptions and a general lack of risk awareness. Participants conflated the human-like empathy exhibited by LLMs with human-like accountability and mistakenly believed that their interactions with these chatbots were safeguarded by the same regulations (e.g., HIPAA) as disclosures with a licensed therapist. We introduce the concept of \"intangible vulnerability,\" where emotional or psychological disclosures are undervalued compared to more tangible forms of information (e.g., financial or location-based data). To address this, we propose recommendations to safeguard user mental health disclosures with general-purpose LLM-enabled chatbots more effectively."
  },
  {
    "id": 3885,
    "year": 2025,
    "title": "Investigating the Impact of Online Community Involvement on Safety Practices and Perceived Risks Among People Who Use Drugs",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/li-jiliang",
    "abstract": "Substance abuse is prevalent in contemporary society, posing significant safety risks to people who use drugs (PWUD). The advent of online communities is gradually altering PWUD's drug use behaviors and, as a consequence, their safety practices. Yet, the precise impacts and challenges these changes introduce to PWUD's safety have scarcely been explored. We conducted 19 semi-structured interviews with PWUD and analyzed content from 29 drug-related subreddits to examine how their involvement in online communities influences their safety practices. Our findings reveal that online communities have afforded PWUD broader access to information and community engagement, facilitating emotional support and better management of their drug use. Nonetheless, it has also introduced challenges such as the spread of misinformation, the promotion of risky behaviors, and the risk of deception. We further discuss the challenges PWUD face transitioning to online communities, and offer design implications to enhance their safety."
  },
  {
    "id": 3886,
    "year": 2025,
    "title": "Privacy Solution or Menace? Investigating Perceptions of Radio-Frequency Sensing",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/windl",
    "abstract": "Radio-frequency sensors are often introduced as privacy-preserving alternatives to cameras, as they enable similar use cases without relying on visual data. However, researchers argue that radio-frequency sensors cause privacy risks similar to cameras and even introduce additional risks. We conducted in-depth interviews (N=14) and a large-scale vignette survey (N=510) to understand people's perceptions and privacy concerns around radio-frequency sensing. Most interviewees were initially unaware of the full capabilities of radio-frequency sensing but expressed nuanced concerns upon learning more. Our survey revealed that, while people expressed concerns, they mostly preferred radio-frequency sensors over cameras in private locations. However, they preferred cameras when considering radio-frequency sensing from a neighbor's perspective and in security-relevant situations. Protective measures can reduce concerns, but the best protection depends on the context. Our findings can inform educational and legislative efforts to ensure a privacy-preserving future with radio-frequency technology."
  },
  {
    "id": 3887,
    "year": 2025,
    "title": "Navigating Security and Privacy Threats in Homeless Service Provision",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/wu-yuxi",
    "abstract": "People experiencing homelessness interact with service providers to access essential services.  As clients, homeless individuals are expected to reveal sensitive information about themselves to service providers, while personal security and privacy (S&P) preferences fall by the wayside.  Simultaneously, providers take on S&P-adjacent responsibilities: helping clients fill out applications, safekeeping clients' personal documents, monitoring clients' online safety, undergoing workplace S&P training, etc.  We created five storyboards to represent S&P challenges that clients can face when they interact with providers.  In interviews with homeless individuals and service providers in the Northeastern United States, we use these storyboards to explore the S&P challenges in client-provider relationships within homeless services.  We find a set of mismatches in S&P priorities between clients and providers, leading to mistrust between the two parties.  We provide design recommendations, envisioned by both parties, for providers to bridge these mismatches."
  },
  {
    "id": 3888,
    "year": 2025,
    "title": "Security and Privacy Advice for UPI Users in India",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/mungara",
    "abstract": "Unified Payments Interface (UPI) payment systems are widely used in India and are also gaining global traction. UPI enables people to make quick everyday transactions and recurring payments, including rent, gas, and electricity, using the same app. The widespread adoption of UPI has sparked significant concerns regarding users' security and privacy, especially due to an alarming number of UPI-related scams and fraudulent transactions. While prior work has explored the technical security of UPI, to address security threats effectively, we must understand user mental models, concerns, security information sources, and behaviors. In a mixed-methods study of 26 semi-structured interviews with UPI users from India and content analysis of 16 security information sources from regulatory bodies, UPI apps, and banks offering UPI, we explore user mental models, concerns, where and how they receive security advice, as well as their security-relevant behaviors. We provide an analysis of users' concerns and threats around UPI security and privacy and highlight gaps where official advice falls short. Further, we recommend UPI providers and banks to curate accessible and useful advice to better alleviate users' concerns, and increase their reach. We also recommend individual security and privacy practices for UPI users to protect themselves."
  },
  {
    "id": 3889,
    "year": 2025,
    "title": "\"Helps me Take the Post With a Grain of Salt:\" Soft Moderation Effects on Accuracy Perceptions and Sharing Intentions of Inauthentic Political Content on X",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/sharevski",
    "abstract": "In this study, we empirically evaluate the effectiveness of soft moderation interventions on X warning labels, warning bundles (labels combined with community notes), and warning covers in reducing perceived accuracy and sharing intentions of inauthentic political content across two contexts: (1) the 2024 U.S. presidential election, and (2) a non-election setting. Using a sample of n1 = 925 X users during the election campaign, we find that both the warning bundle and the warning cover significantly reduce the perceived accuracy of manipulated content related to each presidential candidate. A follow-up evaluation with n2 = 649 X users after the election confirms these findings, reinforcing the role of such interventions as interaction frictions that effectively lower perceived accuracy of inauthentic content concerning both politically affiliated individuals and global conflict topics. Thematic analysis of participants' explanations suggests that warning labels and covers - especially those incorporating third-party fact-checks - are viewed as less trustworthy than the community notes included in the warning bundles. Across both contexts, no intervention significantly impacted participants' willingness to share the content, mainly due to concerns that sharing inauthentic material could harm self-presentation on X."
  },
  {
    "id": 3890,
    "year": 2025,
    "title": "As Advertised? Understanding the Impact of Influencer VPN Ads",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/akgul",
    "abstract": "Influencer VPN ads (sponsored segments) on YouTube often disseminate misleading information about both VPNs, and security & privacy more broadly. However, it remains unclear how (or whether) these ads affect users' perceptions and knowledge about VPNs. In this work, we explore the relationship between YouTube VPN ad exposure and users' mental models of VPNs, security, and privacy. We use a novel VPN ad detection model to calculate the ad exposure of 217 participants via their YouTube watch histories, and we develop scales to characterize their mental models in relation to claims commonly made in VPN ads. Through (pre-registered) regression-based analysis, we find that exposure to VPN ads is significantly correlated with familiarity with VPN brands and increased belief in (hyperbolic) threats. While not specific to VPNs, these threats are often discussed in VPN ads. In contrast, although many participants agree with both factual and misleading mental models of VPNs that often appear in ads, we find no significant correlation between exposure to VPN ads and these mental models. These findings suggest that, if VPN ads do impact mental models, then it is predominantly emotional (i.e., threat perceptions) rather than technical."
  },
  {
    "id": 3891,
    "year": 2025,
    "title": "Fuzzing the PHP Interpreter via Dataflow Fusion",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/jiang-yuancheng",
    "abstract": "PHP, a dominant scripting language in web development, powers a vast range of websites, from personal blogs to major platforms. While existing research primarily focuses on PHP application-level security issues like code injection, memory errors within the PHP interpreter have been largely overlooked. These memory errors, prevalent due to the PHP interpreter's extensive C codebase, pose significant risks to the confidentiality, integrity, and availability of PHP servers. This paper introduces FlowFusion, the first automatic fuzzing framework to detect memory errors in the PHP interpreter. FlowFusion leverages dataflow as an efficient representation of test cases maintained by PHP developers, merging two or more test cases to produce fused test cases with more complex code semantics. Moreover, FlowFusion employs strategies such as test mutation, interface fuzzing, and environment crossover to increase bug finding. In our evaluation, FlowFusion found 158 unknown bugs in the PHP interpreter, with 125 fixed and 11 confirmed. Comparing FlowFusion against the official test suite and a naive test concatenation approach, FlowFusion can detect new bugs that these methods miss, while also achieving greater code coverage. FlowFusion also outperformed state-of-the-art fuzzers AFL++ and Polyglot, covering 24% more lines of code after 24 hours of fuzzing. FlowFusion has gained wide recognition among PHP developers and is now integrated into the official PHP toolchain."
  },
  {
    "id": 3892,
    "year": 2025,
    "title": "Waltzz: WebAssembly Runtime Fuzzing with Stack-Invariant Transformation",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/zhang-lingming",
    "abstract": "WebAssembly (Wasm) is a binary instruction format proposed by major browser vendors to achieve near-native performance on the web and other platforms. By design, Wasm modules should be executed in a memory-safe runtime, which acts as a trusted computing base. Therefore, security vulnerabilities inside runtime implementation can have severe impacts and should be identified and mitigated promptly.\nFuzzing is a practical and widely adopted technique for uncovering bugs in real-world programs. However, to apply fuzzing effectively to the domain of Wasm runtimes, it is vital to address two primary challenges: (1) Wasm is a stack-based language and runtimes should verify the correctness of stack semantics, which requires fuzzers to meticulously maintain desired stack semantics to reach deeper states. (2) Wasm acts as a compilation target and includes hundreds of instructions, making it hard for fuzzers to explore different combinations of instructions and cover the input space effectively.\nTo address these challenges, we design and implement Waltzz, a practical greybox fuzzing framework tailored for Wasm runtimes. Specifically, Waltzz proposes the concept of stack-invariant code transformation to preserve appropriate stack semantics during fuzzing. Next, Waltzz introduces a versatile suite of mutators designed to systematically traverse diverse combinations of instructions in terms of both control and data flow. Moreover, Waltzz designs a skeleton-based generation algorithm to produce code snippets that are rarely seen in the seed corpus. To demonstrate the efficacy of Waltzz, we evaluate it on seven well-known Wasm runtimes. Compared to the state-of-the-art works, Waltzz can surpass the nearest competitor by finding 12.4% more code coverage even within the large code bases and uncovering 1.38x more unique bugs. Overall, Waltzz has discovered 20 new bugs which have all been confirmed and 17 CVE IDs have been assigned."
  },
  {
    "id": 3893,
    "year": 2025,
    "title": "MBFuzzer: A Multi-Party Protocol Fuzzer for MQTT Brokers",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/song-xiangpu",
    "abstract": "MQTT is a multi-party communication protocol widely used in IoT environments, where MQTT brokers act as servers that connect with numerous devices. Consequently, any flaws in brokers will seriously impact all participants. Given the success of fuzzing techniques in finding bugs in programs, existing fuzzing works targeting MQTT brokers face the limitation of insufficient fuzzing input space because they all adopt a two-party fuzzing model. Accordingly, the code responsible for handling multi-party communication will not be examined. Moreover, existing fuzzers focus on either memory corruption bugs or logic errors without considering whether a broker implementation is specification-compliant.\nIn this paper, we design a black-box fuzzing approach, MBFuzzer, for brokers to address the above limitations. We first design a multi-party fuzzing framework containing two fuzzing input senders to facilitate the exploration of code space that handles multi-party communication. To improve fuzzing efficiency, we design a message priority scheduler and a model based on Petri net to guide test case generation and coordinate the message sending of the two senders, respectively. We leverage differential testing to identify non-compliance bugs and design an LLM-based non-compliance bug analysis method to automatically analyze the bug report and validate whether it is a non-compliance bug. We implemented a prototype MBFuzzer and evaluated it with six mainstream MQTT brokers. MBFuzzer successfully identified 73 bugs including 20 memory corruption and 53 non-compliance bugs with 11 CVEs assigned. The comparison with state-of-the-art fuzzers indicates that MBFuzzer outperforms them in both code coverage and bug finding capabilities."
  },
  {
    "id": 3894,
    "year": 2025,
    "title": "ChainFuzz: Exploiting Upstream Vulnerabilities in Open-Source Supply Chains",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/deng",
    "abstract": "Software supply chain attacks pose an increasingly severe threat to the security of downstream software worldwide. A common method to mitigate these risks is Software Composition Analysis (SCA), which helps developers identify vulnerable dependencies. However, studies show that popular SCA approaches often suffer from high false positive rates. As a result, developers spend significant time manually validating these alerts, which delays the detection and remediation of genuinely exploitable upstream vulnerabilities.\nIn this paper, we propose ChainFuzz, an automated approach for validating upstream vulnerabilities in downstream software by generating Proof-of-Concepts (PoCs). To achieve this, ChainFuzz addresses three key challenges. First, intra-layer code and constraints. Downstream software introduces custom code and sanity checks that significantly alter the triggering paths and conditions of upstream vulnerabilities. Second, inter-layer dependencies. Software supply chains often involve cross-layer control-flow and data-flow dependencies between conditional statements across different layers. Third, long supply chains. Transitive dependencies in long chains result in intricate exploitation paths, making it challenging to explore large code spaces and handle deeply nested constraints effectively.\nWe comprehensively evaluate ChainFuzz using our dataset, which comprises 66 unique vulnerability and supply chain combinations. Our results demonstrate its effectiveness and practicality in generating PoCs for both direct and transitive vulnerable dependencies. Additionally, we compare ChainFuzz with representative fuzzing tools: AFLGo, AFL++, and NestFuzz, highlighting its superior performance in downstream PoC generation."
  },
  {
    "id": 3895,
    "year": 2025,
    "title": "IDFuzz: Intelligent Directed Grey-box Fuzzing",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/chen-yiyang",
    "abstract": "Directed grey-box fuzzing aims to test target code in programs and is widely utilized in various scenarios, including patch testing, candidate vulnerability confirmation, and known vulnerability reproduction. However, we find that existing directed fuzzers generally lack effective input mutation strategies and resort to the randomness and empiricism inherent in AFL-based strategies, which prove to be inefficient in directed fuzzing contexts.\nThis paper presents IDFuzz, an intelligent input mutation solution for directed fuzzing. Our key insight is to leverage a neural network model to learn from historically mutated inputs and extract useful experience that can guide input mutation towards the target code. We introduce several novel techniques in model construction and model training, which help build a model that well captures experience on how to cover both explored and unexplored code relevant to the target. We further devise a refined model gradient-guided scheme that leverages the experience to locate critical input fields and develop a directed input mutation strategy. We implement IDFuzz as an input mutation module that complements most open-source state-of-the-art directed fuzzers. In our evaluation, IDFuzz significantly accelerates existing directed fuzzers by over 2.48x in reproducing target vulnerabilities on the Google Fuzzer Test Suite. Moreover, we demonstrate that IDFuzz helps existing directed fuzzers reduce ineffective mutations by 91.86%. Lastly, we detected 6 previously unknown vulnerabilities with 4 CVE IDs assigned so far and 1 incomplete fix of a high-severity vulnerability in well-tested real-world software using IDFuzz."
  },
  {
    "id": 3896,
    "year": 2025,
    "title": "Robust, Efficient, and Widely Available Greybox Fuzzing for COTS Binaries with System Call Pattern Feedback",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/xiao-jifan",
    "abstract": "Currently, greybox fuzzing is a crucial technique for identifying software bugs. However, applying greybox fuzzing to Commercial-Off-the-Shelf ( COTS ) binaries is still a difficult task because gathering code coverage data is challenging. Existing methods for collecting code coverage in COTS binaries often lead to program crashes, notable performance reductions, and limited compatibility with various hardware platforms. As a result, none of the current approaches can effectively handle all COTS binaries.\nThis paper introduces a new feedback mechanism called system call pattern coverage, which is designed to support binaries that cannot be handled by existing approaches. Unlike other methods, system call pattern coverage does not involve rewriting binaries, using emulators, or relying on hardware such as Intel-PT. As a result, it enables fuzzing of binaries without the risk of breaking target applications, slow performance, or the need for specific hardware. To demonstrate the effectiveness of this mechanism, we developed fuzzers called SPFuzz and SPFuzz++ and conducted an evaluation using 29 real-world benchmarks. The results of our evaluation show that SPFuzz and SPFuzz++ perform comparably to conventional code coverage guidance and are capable of identifying new bugs even without access to the source code. In fact, we discovered six new CVEs in commercial applications like CUDA using SPFuzz."
  },
  {
    "id": 3897,
    "year": 2025,
    "title": "BLuEMan: A Stateful Simulation-based Fuzzing Framework for Open-Source RTOS Bluetooth Low Energy Protocol Stacks",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/kao",
    "abstract": "Bluetooth Low Energy (BLE) is a dominant wireless communication technology widely used in low-power, short-range applications. Its broad adoption and inherent security vulnerabilities in certain implementations have prompted numerous efforts to identify flaws in BLE protocol stacks. Despite these efforts, many existing fuzz testing methods face substantial limitations in scalability and applicability. To address these challenges, we propose BLuEMan, a simulation-based fuzzing framework that integrates a Real-Time Operating System (RTOS) with a software-based physical layer simulator. BLuEMan executes the actual BLE protocol stack while simulating interactions between BLE targets. This design ensures scalability for rapid testing across various targets while maintaining high applicability to various platforms. Our evaluation demonstrates that BLuEMan achieves fuzzing rates up to 18.0 and 162.3 times faster than typical simulation-based and platform-based approaches, respectively. Moreover, BLuEMan has uncovered four new vulnerabilities in BLE protocol stacks, all of which have been reported and assigned CVEs. This approach provides valuable insights into efficient vulnerability discovery for BLE protocol stack developers."
  },
  {
    "id": 3898,
    "year": 2025,
    "title": "ELFuzz: Efficient Input Generation via LLM-driven Synthesis Over Fuzzer Space",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/chen-chuyang",
    "abstract": "Generation-based fuzzing produces appropriate testing cases according to specifications of input grammars and semantic constraints to test systems and software. However, these specifications require significant manual efforts to construct. This paper proposes a new approach, ELFuzz (Evolution Through Large Language Models for Fuzzing), that automatically synthesizes generation-based fuzzers tailored to a system under test (SUT) via LLM-driven synthesis over fuzzer space. At a high level, it starts with minimal seed fuzzers and propels the synthesis by fully automated LLM-driven evolution with coverage guidance. Compared to previous approaches, ELFuzz can 1) seamlessly scale to SUTs of real-world sizes—up to 1,791,104 lines of code in our evaluation—and 2) synthesize efficient fuzzers that catch interesting grammatical structures and semantic constraints in a human-understandable way. Our evaluation compared ELFuzz with specifications manually written by domain experts and synthesized by state-of-the-art approaches. It shows that ELFuzz achieves up to 434.8% more coverage and triggers up to 174.0% more artificially injected bugs. We also used ELFuzz to conduct a real-world fuzzing campaign on the newest version of cvc5 for 14 days, and encouragingly, it found five 0-day bugs (three are exploitable). Moreover, we conducted an ablation study, which shows that the fuzzer space model, the key component of ELFuzz, contributes the most (up to 62.5%) to the effectiveness of ELFuzz. Further analysis of the fuzzers synthesized by ELFuzz confirms that they catch interesting grammatical structures and semantic constraints in a human-understandable way. The results present the promising potential of ELFuzz for more automated, efficient, and extensible input generation for fuzzing."
  },
  {
    "id": 3899,
    "year": 2025,
    "title": "Hybrid Language Processor Fuzzing via LLM-Based Constraint Solving",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/yang-yupeng",
    "abstract": "Language processors, such as compilers and interpreters, play a crucial role in modern cyberspace. Faulty language processors can lead to severe consequences such as incorrect functionalities or malicious attacks. It is non-trivial to automatically test language processors to detect faulty behaviors, because language processors are multistaged and require various complex constraints to reach deep program states. Existing testing (fuzzing) approaches either fail to effectively generate inputs that satisfy the complex constraints or fail to generalize due to their heavy reliance on target-specific constraint modeling heuristics. In this paper, we explore the potential of using LLMs for constraint solving to address these limitations and identify two challenges regarding constraint prioritization and context construction. To effectively address these challenges, we propose two novel solutions, hybrid centrality prioritization and iterative context construction. We implement the solutions in a hybrid fuzzing framework, HLPFuzz, which leverages an LLM to overcome complex constraints and reach deep program states. In our evaluation, HLPFuzz successfully discovers 52 bugs in 9 popular language processors, of which 37 are confirmed and 14 are fixed. HLPFuzz also outperforms state-of-the-art solutions by up to 190% in code coverage and discovers 5x more bugs than the second-best fuzzer, with minimal reliance on target-specific heuristics."
  },
  {
    "id": 3900,
    "year": 2025,
    "title": "Rowhammer-Based Trojan Injection: One Bit Flip Is Sufficient for Backdooring DNNs",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/li-xiang",
    "abstract": "While conventional backdoor attacks on deep neural networks (DNNs) assume the attacker can manipulate the training data or process, recent research introduces a more practical threat model by injecting backdoors during the inference stage. These approaches exploit bit flip attacks to modify model weights, leveraging memory fault injection techniques like Rowhammer. However, they face a significant limitation—requiring multiple bits to be flipped simultaneously, which is highly difficult in practice. Additionally, they primarily target quantized models, leaving the feasibility of inference-time backdoor attacks on full-precision models unclear. To address these limitations, we propose ONEFLIP, the first one-bit-flip backdoor attack on full-precision models. Unlike prior methods that rely on optimization-based bit searches and require flipping multiple bits, our algorithm identifies the most promising weights for the attack and flips a single bit to insert a backdoor. We evaluate ONEFLIP on the CIFAR-10, CIFAR-100, GTSRB, and ImageNet datasets, covering different DNN architectures, including a vision transformer. The results demonstrate that ONEFLIP achieves high attack success rates (up to 99.9%, with an average of 99.6%) while causing minimal degradation to benign accuracy (as low as 0.005%, averaging 0.06%). Moreover, ONEFLIP is resilient to backdoor defenses. Our findings underscore a critical threat to DNNs: flipping just one bit in full-precision models is sufficient to execute a successful backdoor attack."
  },
  {
    "id": 3901,
    "year": 2025,
    "title": "From Purity to Peril: Backdooring Merged Models From \"Harmless\" Benign Components",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/wang-lijin",
    "abstract": "The expansion of capabilities in large-scale models often incurs prohibitively high training costs. Fortunately, recent advancements in model merging techniques have made it possible to efficiently combine multiple large models, each designed for a specific task, into a single multi-functional model with negligible cost. Despite these advantages, there is a notable research gap regarding the security implications of model merging, particularly concerning backdoor vulnerabilities. In this study, we introduce a novel supply chain threat under the model merging scenario: multiple ostensibly benign models can be merged into a backdoored model. To rigorously explore this threat, we propose MergeBackdoor, a versatile training framework designed to suppress backdoor behaviors in upstream models before merging, while simultaneously ensuring the emergence of the backdoor when these models are merged. Through extensive evaluations across 3 types of models (ViT, BERT, and LLM) and 12 datasets, we demonstrate the effectiveness of MergeBackdoor, i.e., the attack success rates (ASRs) of the upstream models before merging are all at a random-guessing level, and the ASRs can reach nearly 1.0 for the final merged model. Besides conducting an in-depth analysis of MergeBackdoor's underlying mechanism, we further demonstrate that even the most knowledgeable detectors fail to identify the anomalies in these models before merging. We highlight that our findings underscore the critical need for security audit throughout the entire merging pipeline."
  },
  {
    "id": 3902,
    "year": 2025,
    "title": "Revisiting Training-Inference Trigger Intensity in Backdoor Attacks",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/lin-chenhao",
    "abstract": "Backdoor attacks typically place a specific trigger on certain training data, such that the model makes prediction errors on inputs with that trigger during inference. Despite the core role of the trigger, existing studies have commonly believed a perfect match between training-inference triggers is optimal. In this paper, for the first time, we systematically explore the training-inference trigger relation, particularly focusing on their mismatch, based on a Training-Inference Trigger Intensity Manipulation (TITIM) workflow. TITIM specifically investigates the training-inference trigger intensity, such as the size or the opacity of a trigger, and reveals new insights into trigger generalization and overfitting. These new insights challenge the above common belief by demonstrating that the training-inference trigger mismatch can facilitate attacks in two practical scenarios, posing more significant security threats than previously thought. First, when the inference trigger is fixed, using training triggers with mixed intensities leads to stronger attacks than using any single intensity. For example, on CIFAR-10 with ResNet18, mixing training triggers with 1.0 and 0.1 opacities improves the worst-case attack success rate (ASR) (over different testing opacities) of the best single-opacity attack from 10.61% to 92.77%. Second, intentionally using certain mismatched training-inference triggers can improve the attack stealthiness, i.e., better bypassing defenses. For example, compared to the training/inference intensity of 1.0/1.0, using 1.0/0.7 decreases the area under the curve (AUC) of the Scale-Up defense from 0.96 to 0.62, while maintaining a high attack ASR (99.65% vs. 91.62%)."
  },
  {
    "id": 3903,
    "year": 2025,
    "title": "Persistent Backdoor Attacks in Continual Learning",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/guo-zhen",
    "abstract": "Backdoor attacks pose a significant threat to neural networks, enabling adversaries to manipulate model outputs on specific inputs, often with devastating consequences, especially in critical applications. While backdoor attacks have been studied in various contexts, little attention has been given to their practicality and persistence in continual learning, particularly in understanding how the continual updates to model parameters, as new data distributions are learned and integrated, impact the effectiveness of these attacks over time.\nTo address this gap, we introduce two persistent backdoor attacks–Blind Task Backdoor and Latent Task Backdoor–each leveraging minimal adversarial influence. Our blind task backdoor subtly alters the loss computation without direct control over the training process, while the latent task backdoor influences only a single task's training, with all other tasks trained benignly. We evaluate these attacks under various configurations, demonstrating their efficacy with static, dynamic, physical, and semantic triggers. Our results show that both attacks consistently achieve high success rates across different continual learning algorithms, while effectively evading state-of-the-art defenses, such as SentiNet and I-BAU."
  },
  {
    "id": 3904,
    "year": 2025,
    "title": "Data Duplication: A Novel Multi-Purpose Attack Paradigm in Machine Unlearning",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/ye-duplication",
    "abstract": "Duplication is a prevalent issue within datasets. Existing research has demonstrated that the presence of duplicated data in training datasets can significantly influence both model performance and data privacy. However, the impact of data duplication on the unlearning process remains largely unexplored. This paper addresses this gap by pioneering a comprehensive investigation into the role of data duplication, not only in standard machine unlearning but also in federated and reinforcement unlearning paradigms. Specifically, we propose an adversary who duplicates a subset of the target model's training set and incorporates it into the training set. After training, the adversary requests the model owner to unlearn this duplicated subset, and analyzes the impact on the unlearned model. For example, the adversary can challenge the model owner by revealing that, despite efforts to unlearn it, the influence of the duplicated subset remains in the model. Moreover, to circumvent detection by de-duplication techniques, we propose three novel near-duplication methods for the adversary, each tailored to a specific unlearning paradigm. We then examine their impacts on the unlearning process when de-duplication techniques are applied. Our findings reveal several crucial insights: 1) the gold standard unlearning method, retraining from scratch, fails to effectively conduct unlearning under certain conditions; 2) unlearning duplicated data can lead to significant model degradation in specific scenarios; and 3) meticulously crafted duplicates can evade detection by de-duplication methods. The source code is provided at: https://zenodo.org/records/14736535."
  },
  {
    "id": 3905,
    "year": 2025,
    "title": "DeBackdoor: A Deductive Framework for Detecting Backdoor Attacks on Deep Models with Limited Data",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/popovic",
    "abstract": "Backdoor attacks are among the most effective, practical, and stealthy attacks in deep learning. In this paper, we consider a practical scenario where a developer obtains a deep model from a third party and uses it as part of a safety-critical system. The developer wants to inspect the model for potential backdoors prior to system deployment. We find that most existing detection techniques make assumptions that are not applicable to this scenario. In this paper, we present a novel framework for detecting backdoors under realistic restrictions. We generate candidate triggers by deductively searching over the space of possible triggers. We construct and optimize a smoothed version of Attack Success Rate as our search objective. Starting from a broad class of template attacks and just using the forward pass of a deep model, we reverse engineer the backdoor attack. We conduct extensive evaluation on a wide range of attacks, models, and datasets, with our technique performing almost perfectly across these settings."
  },
  {
    "id": 3906,
    "year": 2025,
    "title": "SoK: Gradient Inversion Attacks in Federated Learning",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/carletti",
    "abstract": "Federated Learning (FL) is a promising paradigm for collaboratively training Machine Learning (ML) models while preserving the privacy of data owners. By allowing participants to maintain their data on-site, FL avoids sending client local data to a central server for model training. However, despite its evident privacy benefits, it is not immune to security and privacy threats. Among these, Gradient Inversion Attacks (GIAs) stand out as one of the most critical as they exploit client's model updates to reconstruct local training data, breaking participant's privacy. This work presents a comprehensive systematization of GIAs in FL. First, we identify various threat models defining the adversary's knowledge and capabilities to perform these attacks. Then, we propose a systematic taxonomy to categorize GIAs, providing practical insights into their methods and applicability. Additionally, we explore defensive mechanisms designed to mitigate these attacks. We also systematize evaluation metrics used to measure the success of GIAs and assess the model's vulnerability before an attack. Finally, based on a thorough analysis of the existing literature, we identify key challenges and outline promising future research directions."
  },
  {
    "id": 3907,
    "year": 2025,
    "title": "PoiSAFL: Scalable Poisoning Attack Framework to Byzantine-resilient Semi-asynchronous Federated Learning",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/pang-xiaoyi",
    "abstract": "Semi-asynchronous federated learning (SAFL) enhances the efficiency of privacy-preserving collaborative learning across clients with diverse processing capabilities. It updates the global model by aggregating local models from only partial fast clients without waiting for all clients to synchronize. We realize that such semi-asynchronous aggregation may expose the system to serious poisoning risks, even when defenses are in place, since it introduces considerable inconsistency among local models, giving chances for attackers to inject inconspicuous malicious ones. However, such risks remain largely underexplored. To plug this gap and fully explore the vulnerability of SAFL, in this paper, we propose a scalable stealth poisoning attack framework for Byzantine-resilient SAFL, called PoiSAFL. It can effectively impair SAFL's learning performance while bypassing three typical kinds of Byzantine-resilient defenses by strategically controlling malicious clients to upload undetectable malicious local models. The challenge lies in crafting malicious models that evade detection yet remain destructive. We construct a constrained optimization problem and propose three modules to approximate the optimization objective: the anti-training-based model initialization, loss-aware model distillation, and distance-aware model scaling. These modules initialize and refine malicious models with desired poisoning ability while keeping their performance, prediction entropy, and dissimilarity within benign ranges to bypass detection. Extensive experiments demonstrate that PoiSAFL can defeat three typical categories of defenses. Besides, PoiSAFL can further amplify its attack impact by flexibly executing three proposed modules. Note that PoiSAFL is scalable and can incorporate new modules to defeat future new types of defenses."
  },
  {
    "id": 3908,
    "year": 2025,
    "title": "Towards Lifecycle Unlearning Commitment Management: Measuring Sample-level Unlearning Completeness",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/wang-cheng-long",
    "abstract": "Growing concerns over data privacy and security highlight the importance of machine unlearning--removing specific data influences from trained models without full retraining. Techniques like Membership Inference Attacks (MIAs) are widely used to externally assess successful unlearning. However, existing methods face two key limitations: (1) maximizing MIA effectiveness (e.g., via online attacks) requires prohibitive computational resources, often exceeding retraining costs; (2) MIAs, designed for binary inclusion tests, struggle to capture granular changes in approximate unlearning. To address these challenges, we propose the Interpolated Approximate Measurement (IAM), a framework natively designed for unlearning inference. IAM quantifies sample-level unlearning completeness by interpolating the model's generalization-fitting behavior gap on queried samples. IAM achieves strong performance in binary inclusion tests for exact unlearning and high correlation for approximate unlearning--scalable to LLMs using just one pre-trained shadow model. We theoretically analyze how IAM's scoring mechanism maintains performance efficiently. We then apply IAM to recent approximate unlearning algorithms, revealing general risks of both over-unlearning and under-unlearning, underscoring the need for stronger safeguards in approximate unlearning systems. The code is available at https://github.com/Happy2Git/Unlearning_Inference_IAM."
  },
  {
    "id": 3909,
    "year": 2025,
    "title": "Addressing the Address Books' (Interdependent) Privacy Issues",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/niksirat",
    "abstract": "Interdependent privacy (IDP), which refers to situations where individuals affect the privacy of others, is a growing concern and has been studied in various contexts. Digital address books (DABs), where users store personal information about others on online services, are a compelling yet understudied case of IDP. In this paper, we present a multi-faceted analysis of DABs. In particular, we conducted two online survey studies with N = 463 and N = 459 DAB users to understand how they interact with their DABs, perceive and manage associated privacy risks, and support data protection rights. Our studies notably reveal that (i) the privacy leakage due to DABs is substantial, (ii) users are well aware of the privacy (incl. IDP) risks of DAB data but have only moderate privacy concerns and are quite comfortable granting access to this data, and (iii) users are relatively open to respecting the rights of data subjects. We conclude with concrete design recommendations for a privacy-aware DAB ecosystem."
  },
  {
    "id": 3910,
    "year": 2025,
    "title": "HyTrack: Resurrectable and Persistent Tracking Across Android Apps and the Web",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/wessels",
    "abstract": "Android apps can freely intermix native and web content using Custom Tabs and Trusted Web Activities. This blurring of the boundary between native and web, however, opens the door to HyTrack, a novel tracking technique. Custom Tabs and Trusted Web Activities have access to the default browser state to enable, e.g., seamless reuse of authentication tokens. HyTrack abuses this shared browser state to track users both in-app and across the web using the same identifier. We present several ways to hide or completely disguise the tracking from the user by integrating it into the app's UI. Depending on the used Android flavor, HyTrack leaves no visible traces at all. Furthermore, by combining basic functionalities of the Android operating system, we also show that identifiers created with HyTrack are almost impossible to get rid of. HyTrack can resurrect tracking identifiers even when users try last-resort techniques, such as changing the default browser or switching devices, making it more persistent than even evercookies were on the Web. While we do not find direct evidence that our technique is already employed, our findings indicate that all essential components are currently in place. A rapid deployment can occur at any given moment. To summarize, this paper provides an early warning of a potentially severe new tracking approach for the Android operating system that solely utilizes the intended behavior of commonly utilized Android features."
  },
  {
    "id": 3911,
    "year": 2025,
    "title": "I Can Tell Your Secrets: Inferring Privacy Attributes from Mini-app Interaction History in Super-apps",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/cai-yifeng",
    "abstract": "Super-apps have emerged as comprehensive platforms integrating various mini-apps to provide diverse services. While super-apps offer convenience and enriched functionality, they can introduce new privacy risks. This paper reveals a new privacy leakage source in super-apps: mini-app interaction history, including mini-app usage history (Mini-H) and operation history (Op-H). Mini-H refers to the history of mini-apps accessed by users, such as their frequency and categories. Op-H captures user interactions within mini-apps, including button clicks, bar drags, and image views. Super-apps can naturally collect these data without instrumentation due to the web-based feature of mini-apps. We identify these data types as novel and unexplored privacy risks through a literature review of 30 papers and an empirical analysis of 31 super-apps. We design a mini-app interaction history-oriented inference attack (THEFT), to exploit this new vulnerability. Using THEFT, the insider threats within the low-privilege business department of the super-app vendor acting as the adversary can achieve more than 95.5% accuracy in inferring privacy attributes of over 16.1% of users. THEFT only requires a small training dataset of 200 users from public breached databases on the Internet. We also engage with super-app vendors and a standards association to increase industry awareness and commitment to protect this data. Our contributions are significant in identifying overlooked privacy risks, demonstrating the effectiveness of a new attack, and influencing industry practices toward better privacy protection in the super-app ecosystem."
  },
  {
    "id": 3912,
    "year": 2025,
    "title": "Seeing Through: Analyzing and Attacking Virtual Backgrounds in Video Calls",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/weissberg",
    "abstract": "Video calls have become an essential part of remote work. They enable employees to collaborate from different locations, including their home. Transmitting video from the personal living environment, however, poses a privacy risk: Colleagues may gain insight into private information through details in the background. To limit this risk, video conferencing services implement virtual backgrounds that conceal the real environment during a video call. Unfortunately, this protection suffers from imperfections and pixels from the environment occasionally become visible. \nIn this paper, we investigate this privacy leak. We analyze the virtual background techniques used in two major video conferencing services (Zoom and Google) and determine how pixels of the environment leak. Based on this analysis, we propose a reconstruction attack: This attack removes the virtual background by re-purposing the video conferencing software and uses semantic segmentation to filter out the video caller. As a result, only pixels leaking from the environment remain and can be aggregated into a reconstructed image.\nWe examine the efficacy of this attack in a quantitative and qualitative evaluation. In comparison to previous studies, our attack recovers at least 53% more leaked pixels from a video call, exposing larger areas of the environment. We thus conclude that virtual backgrounds currently do not provide an adequate protection in practice."
  },
  {
    "id": 3913,
    "year": 2025,
    "title": "Endangered Privacy: Large-Scale Monitoring of Video Streaming Services",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/bjorklund",
    "abstract": "Despite the widespread adoption of HTTPS for enhanced web privacy, encrypted network traffic may still leave traces that can lead to privacy breaches. One such case concerns MPEG-DASH, one of the most popular protocols for video streaming, where video identification attacks have exploited the protocol's side-channel vulnerabilities. As shown by several works in recent years, the distinctive traffic patterns generated by DASH's adaptive bitrate streaming reveal streamed content despite TLS-protection. However, these earlier studies have not demonstrated that the vulnerability remains exploitable in large-scale attack scenarios, even when making strong assumptions about network details. To that end, this work presents a protocol-agnostic system capable of identifying videos independent of network layer information, and demonstrates a practical attack over the largest dataset to date, comprising over 240,000 videos covering three entire streaming services. Using a combination of k-d tree search and time series methods, our system achieves an accuracy of over 99.5% in real-time video identification and remains effective even in scenarios involving victims behind VPNs or where Wi-Fi eavesdropping occurs. Since large-scale video identification can compromise user privacy and enable potential mass surveillance of video services, we complement our work with an analysis of the vulnerability root cause when using adaptive bitrate streaming and propose a mitigation strategy to stand against such vulnerabilities. Recognizing the lack of open-source tooling in this domain, we publish an extensive dataset of video fingerprints, network capture data, and tools to foster awareness and prompt timely solutions within the video streaming community to address these privacy concerns effectively."
  },
  {
    "id": 3914,
    "year": 2025,
    "title": "Bots can Snoop: Uncovering and Mitigating Privacy Risks of Bots in Group Chats",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/chou",
    "abstract": "New privacy concerns arise with chatbots on group messaging platforms. Chatbots may access information beyond their intended functionalities, such as sender identities or messages unintended for chatbots. Chatbot developers may exploit such information to infer personal information and link users across groups, potentially leading to data breaches, pervasive tracking, or targeted advertising. Our analysis of conversation datasets shows that (1) chatbots often access far more messages than needed, and (2) when a user joins a new group with chatbots, there is a 3.6% chance that at least one of the chatbots can recognize and associate the user with their previous interactions in other groups. Although state-of-the-art (SoA) group messaging protocols provide robust end-to-end encryption and some platforms have implemented policies to limit chatbot access, no platforms successfully combine these features. This paper introduces SnoopGuard, a secure group messaging protocol that ensures user privacy against chatbots while maintaining strong end-to-end security. Our protocol offers (1) selective message access, preventing chatbots from accessing unrelated messages, and (2) sender anonymity, hiding user identities from chatbots. SnoopGuard achieves $O(\\log n + m)$ message-sending complexity for a group of $n$ users and $m$ chatbots, compared to $O(\\log(n + m))$ in SoA protocols, with acceptable overhead for enhanced privacy. Our prototype implementation shows that sending a message to a group of 50 users and 10 chatbots takes about 10 milliseconds when integrated with Message Layer Security (MLS)."
  },
  {
    "id": 3915,
    "year": 2025,
    "title": "EchoLLM: LLM-Augmented Acoustic Eavesdropping Attack on Bone Conduction Headphones with mmWave Radar",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/yao-xin",
    "abstract": "Bone conduction headphones have gained popularity due to their comfort and versatility, as they transmit sound via vibrations through the user's skull bones rather than the eardrums. However, the transmitted audio may contain sensitive information, posing serious privacy risks if intercepted by unauthorized parties. While prior research has explored acoustic eavesdropping attacks via side channels such as millimeter wave (mmWave) radar, existing methods remain constrained by limited generalizability and degraded reconstruction quality. In this paper, we propose EchoLLM, the first mmWave-based eavesdropping attack specifically targeting the semantic content of audio transmitted through a victim's bone conduction headphones. EchoLLM exploits the fact that audio signals in bone conduction headphones are transmitted as mechanical vibrations, which can be captured as a side channel. The attack is designed to be context-aware, target-aware, low-cost, and robust. To improve automatic speech recognition (ASR) under weak mmWave signals, EchoLLM introduces a novel multi-modal speech recognition model that leverages the victim's own speech as contextual input for better ASR accuracy. To provide higher-quality input to the multi-modal model, EchoLLM incorporates signal enhancement techniques such as target identification and background reflection reduction. Our experiments show that EchoLLM achieves a word error rate (WER) as low as 5.23%, and confirm that it can effectively reconstruct the content from the audio transmitted through a targeted bone conduction headphone under realistic scenarios."
  },
  {
    "id": 3916,
    "year": 2025,
    "title": "DiffLoc: WiFi Hidden Camera Localization Based on Electromagnetic Diffraction",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/zhang-xiang",
    "abstract": "The growing privacy risks posed by hidden WiFi cameras have prompted increasing interest in their detection and localization. However, existing localization solutions suffer from several limitations, such as requiring substantial user effort, large activity spaces, predefined parameters, and pre-collected training data. In this paper, we present DiffLoc, a novel and low-cost system that localizes hidden WiFi cameras by leveraging the fundamental physical principle of electromagnetic diffraction. When an obstacle passes through the direct path between a transmitter and a receiver, it causes a distinctive signal attenuation pattern. We theoretically analyze the feasibility of using this phenomenon for localization, identifying two critical requirements for building an unbiased diffraction localization model: symmetry and observability. To meet these requirements, DiffLoc introduces a controllable diffraction generation method. By precisely rotating a small metal plate around a passive WiFi receiver (e.g., a Raspberry Pi), the system produces a consistent and predictable diffraction \"shadowing\" effect. We then construct an unbiased localization model that maps this effect to the azimuth of the hidden camera. Implemented using commercially available off-the-shelf hardware, DiffLoc achieves an average angular error of 14.82° across six diverse environments and eleven different camera models, demonstrating its effectiveness. Code, implementation details, and demo are available at: https://github.com/CamLoPA/DiffLoc."
  },
  {
    "id": 3917,
    "year": 2025,
    "title": "Double-Edged Shield: On the Fingerprintability of Customized Ad Blockers",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/el-hajj-chehade",
    "abstract": "Web tracking is expanding to cookie-less techniques, like browser fingerprinting, to evade popular privacy-enhancing web extensions, namely ad blockers. To mitigate tracking, privacy-aware users are motivated to optimize their privacy setups by adopting proposed anti-fingerprinting configurations and customizing ad blocker settings to maximize the number of blocked trackers. \nHowever, users' choices can counter-intuitively undermine their privacy. In this work, we quantify the risk incurred by modifying ad-blocker filter-list selections. We evaluate the fingerprintability of ad-blocker customization and its implications on privacy. We present three scriptless attacks that evade SoTA fingerprinting detectors and mitigations. Our attacks identify 84% of filter lists, capture stable fingerprints with 0.72 normalized entropy, and reduce the relative anonymity set of users to a median of 48 users (0.2% of the population) using only 45 rules out of 577K. Finally, we provide recommendations and precautionary measures to all parties involved."
  },
  {
    "id": 3918,
    "year": 2025,
    "title": "Encrypted Access Logging for Online Accounts: Device Attributions without Device Tracking",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/ortega-perez",
    "abstract": "Despite improvements in authentication mechanisms, compromise of online accounts remains prevalent. Therefore, technologies to detect compromise retroactively are also necessary. Service providers try to help users diagnose the security status of their accounts via account security interfaces (ASIs) that display recent logins or other activity. Recent work showed how major services' ASIs are untrustworthy because they rely on easily manipulated client-provided values. The reason is a seemingly fundamental tension between accurately attributing accesses to particular devices and the need to prevent online services from tracking devices.\nWe propose client-side encrypted access logging (CSAL) as a new approach that navigates the tension between tracking privacy and ASI utility. The key idea is to add to account activity logs end-to-end (E2E) encrypted device identification information, leveraging OS support and FIDO2-style attestations. We detail a full proposal for a CSAL protocol that works alongside existing authentication mechanisms and provide a formal analysis of integrity, privacy, and unlinkability in the face of honest-but-curious adversaries. Interestingly, a key challenge is characterizing what is feasible in terms of logging in this setting. We discuss security against active adversaries, provide a proof-of-concept implementation, and overall show feasibility of how OS vendors and service providers can work together towards improved account security and user safety."
  },
  {
    "id": 3919,
    "year": 2025,
    "title": "Exploring How to Authenticate Application Messages in MLS: More Efficient, Post-Quantum, and Anonymous Blocklistable",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/hashimoto-blocklistable",
    "abstract": "The Message Layer Security (MLS) protocol has recently been standardized by the IETF. MLS is a scalable secure group messaging protocol expected to run more efficiently compared to the Signal protocol at scale, while offering a similar level of strong security. Even though MLS has undergone extensive examination by researchers, the majority of the works have focused on confidentiality.\nIn this work, we focus on the authenticity of the application messages exchanged in MLS. Currently, MLS authenticates every application message with an EdDSA signature and while manageable, the overhead is greatly amplified in the post-quantum setting as the NIST-recommended Dilithium signature results in a 40x increase in size. We view this as an invitation to explore new authentication modes that can be used instead. We start by taking a systematic view on how application messages are authenticated in MLS and categorize authenticity into four different security notions. We then propose several authentication modes, offering a range of different efficiency and security profiles. For instance, in one of our modes, COSMOS++, we replace signatures with one-time tokens and a MAC tag, offering roughly a 75x savings in the post-quantum communication overhead. While this comes at the cost of weakening security compared to the authentication mode used by MLS, the lower communication overhead seems to make it a worthwhile trade-off with security."
  },
  {
    "id": 3920,
    "year": 2025,
    "title": "How to Compare Bandwidth Constrained Two-Party Secure Messaging Protocols: A Quest for A More Efficient and Secure Post-Quantum Protocol",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/auerbach",
    "abstract": "Transitioning existing classical two-party secure messaging protocols to post-quantum protocols has been an active movement in practice in recent years: Apple's PQ3 protocol and the recent Triple Ratchet protocol being investigated by the Signal team with academics (Dodis et al. Eprint'25). However, due to the large communication overhead of post-quantum primitives, numerous design choices non-existent in the classical setting are being explored, rendering comparison of secure messaging protocols difficult, if not impossible.\nIn this work, we thus propose a new pragmatic metric to measure how secure a messaging protocol is, enabling a concrete methodology to compare secure messaging protocols. However, as we uncover that there can be no \"optimal\" protocol, we set out to find the best protocol under practical scenarios. To this end, we experimentally compare various messaging protocols under real-world constraints such as bandwidth limits and messaging behaviors. Independently, we also uncover untapped optimizations which we call opportunistic sending, leading to better post-quantum messaging protocols. To capture these optimizations, we further propose sparse continuous key agreement as a fundamental building block for secure messaging protocols, which could be of independent interest."
  },
  {
    "id": 3921,
    "year": 2025,
    "title": "S/MINE: Collecting and Analyzing S/MIME Certificates at Scale",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/oendaroe",
    "abstract": "We report on the first broad analysis of real-world S/MIME certificates for digitally signing and encrypting emails. We collected more than 41 million unique X.509 certificates from public address books, i.e., LDAP servers, of which 38 million fulfill the requirements for use with S/MIME in email clients. Despite the surprisingly complex construction of trust chains for S/MIME certificates, we could build chains for a large subset of certificates and show which are trusted in widely used applications. Our results show that many of those S/MIME certificates are issued by non-publicly trusted CAs.\nOur analysis of the cryptographic keys, certificate attributes, and new regulations, i.e., the CA/Browser Forum's S/MIME Baseline Requirements, shows that the S/MIME PKI is generally heading in the right direction. Most certificates using compromised or weak key material have expired, weak cryptographic algorithms are being phased out, and CAs are generally issuing more secure certificates. However, the underlying RFCs and email clients should be more stringent about what is considered an S/MIME certificate. Additionally, CAs should improve the distribution of certificate chains to improve user experience and security."
  },
  {
    "id": 3922,
    "year": 2025,
    "title": "Achilles: A Formal Framework of Leaking Secrets from Signature Schemes via Rowhammer",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/liang-achilles",
    "abstract": "Signature schemes are a fundamental component of cybersecurity infrastructure. While they are designed to be mathematically secure against cryptographic attacks, they are vulnerable to Rowhammer fault-injection attacks. Since all existing attacks are ad-hoc in that they target individual parameters of specific signature schemes, it remains unclear about the impact of Rowhammer on signature schemes as a whole.\nIn this paper, we present Achilles, a formal framework that aids in leaking secrets in various real-world signature schemes via Rowhammer. Particularly, Achilles can be used to find potentially more vulnerable parameters in schemes that have been studied before and also new schemes that are potentially vulnerable. Achilles mainly describes a formal procedure where Rowhammer faults are induced to key parameters of a generalized signature scheme, called G-sign, and a post-Rowhammer analysis is then performed for secret recovery on it. To illustrate the viability of Achilles, we have evaluated six signature schemes (with five CVEs assigned to track their respective Rowhammer vulnerability), covering traditional and post-quantum signatures with different mathematical problems. Based on the analysis with Achilles, all six schemes are proved to be vulnerable, and two new vulnerable parameters are identified for EdDSA. Further, we demonstrate a successful Rowhammer attack against each of these schemes, using recent cryptographic libraries including wolfssl, relic, and liboqs."
  },
  {
    "id": 3923,
    "year": 2025,
    "title": "Bundled Authenticated Key Exchange: A Concrete Treatment of Signal's Handshake Protocol and Post-Quantum Security",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/hashimoto-key-exchange",
    "abstract": "The Signal protocol relies on a special handshake protocol, formerly X3DH and now PQXDH, to set up secure conversations. Prior analysis of these protocols (or proposals for post-quantum alternatives) have all used highly tailored models to the individual protocols and generally made ad-hoc adaptations to \"standard\" AKE definitions, making the concrete security attained unclear and hard to compare. Indeed, we observe that some natural Signal handshake protocols cannot be handled by these tailored models. In this work, we introduce Bundled Authenticated Key Exchange (BAKE), a concrete treatment of the Signal handshake protocol. We formally model prekey bundles and states, enabling us to define various levels of security in a unified model. We analyze Signal's classically secure X3DH and harvest-now-decrypt-later-secure PQXDH, and show that they do not achieve what we call optimal security (as is documented). Next, we introduce RingXKEM, a fully post-quantum Signal handshake protocol achieving optimal security; as RingXKEM shares states among many prekey bundles, it could not have been captured by prior models. Lastly, we provide security and efficiency comparison of X3DH, PQXDH, and RingXKEM."
  },
  {
    "id": 3924,
    "year": 2025,
    "title": "Comprehensive Deniability Analysis of Signal Handshake Protocols: X3DH, PQXDH to Fully Post-Quantum with Deniable Ring Signatures",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/katsumata",
    "abstract": "The Signal protocol relies on a handshake protocol, formerly X3DH and now PQXDH, to set up secure conversations. One of its privacy properties, of value to Signal, is deniability, allowing users to deny participation in communications. Prior analyses of deniability for these protocols, including post-quantum variants, use models highly tailored to the individual protocols and generally make ad-hoc adaptations to \"standard\" AKE definitions, obscuring the concrete deniability guarantees and complicating comparisons across protocols. Building on Hashimoto et al.'s abstraction for Signal handshake protocols (USENIX '25), we address this gap by presenting a unified framework for analyzing their deniability.\nWe analyze Signal's classically secure X3DH and harvest-now-decrypt-later-secure PQXDH, and show that PQXDH is deniable against harvest-now-judge-later attacks, where a quantum judge retrospectively assesses the participation of classical users. We further analyze post-quantum alternatives like RingXKEM, whose deniability relies on ring signatures (RS). By introducing a novel metric inspired by differential privacy, we provide relaxed, pragmatic guarantees for deniability. We also use this metric to define deniability for RS, a relaxation of anonymity, allowing us to build an efficient RS from NIST-standardized Falcon (and MAYO), which is not anonymous, but is provably deniable."
  },
  {
    "id": 3925,
    "year": 2025,
    "title": "SparSamp: Efficient Provably Secure Steganography Based on Sparse Sampling",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/wang-yaofei",
    "abstract": "Steganography embeds confidential data within seemingly innocuous communications. Provable security in steganography, a long-sought goal, has become feasible with deep generative models. However, existing methods face a critical trade-off between security and efficiency. This paper introduces SparSamp, an efficient provably secure steganography method based on sparse sampling. SparSamp embeds messages by combining them with pseudo-random numbers to obtain message-derived random numbers for sampling. It enhances extraction accuracy and embedding capacity by increasing the sampling intervals and making the sampling process sparse. SparSamp preserves the original probability distribution of the generative model, thus ensuring security. It introduces only $O(1)$ additional complexity per sampling step, enabling the fastest embedding speed without compromising generation speed. SparSamp is designed to be plug-and-play; message embedding can be achieved by simply replacing the sampling component of an existing generative model with SparSamp. We implemented SparSamp in text, image, and audio generation models. It can achieve embedding speeds of up to 755 bits/second with GPT-2, 5046 bits/second with DDPM, and 9,223 bits/second with WaveRNN."
  },
  {
    "id": 3926,
    "year": 2025,
    "title": "A Framework for Designing Provably Secure Steganography",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/liao",
    "abstract": "Steganography is a technique to transmit secret messages over a public channel so that the very existence of these secret messages can not be detected. In this field, provably secure steganography based on shared white-box samplers is a major focus due to its capability to construct secure and efficient steganographic systems on various practical channels. However, designing a novel provably secure steganography scheme remains challenging, since the scheme must maintain a nearly identical sampling distribution to any given discrete distribution while embedding secret information. Currently, there are only a few provably secure steganography schemes available, which significantly limits both practical application and theoretical research. In this paper, we propose a framework for designing provably secure steganography, with the universal security proof for schemes derived from this framework. This framework decomposes the overall complex design into three sub-processes that can be relatively easily achieved, namely Probability Recombination Module, Bin Sampling and Uniform Steganography Module. With this framework, we present several new provably secure steganography schemes and demonstrate that the recent work, Discop(base), is also encompassed by this framework. Additionally, guided by this framework, we have identified several schemes that are theoretically optimal or very effective under specified metrics and validated their effectiveness through experimental verification."
  },
  {
    "id": 3927,
    "year": 2025,
    "title": "REVDECODE: Enhancing Binary Function Matching with Context-Aware Graph Representations and Relevance Decoding",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/ren",
    "abstract": "Binary reverse engineering is important for security tasks, including vulnerability discovery, malware analysis, and code reuse detection. These tasks often involve analyzing binaries without source code or debug symbols. A common yet challenging step in this process is function matching, i.e., comparing functions in unknown binaries to known reference corpora. Function matching becomes complicated due to variations introduced by differences in compilers, optimization levels, and versions. Existing matching techniques primarily focus on similarity but reverse engineers prioritize relevance—whether a match provides meaningful insights.\nWe present REVDECODE, a context-aware framework designed to improve function matching by leveraging interdependencies within binaries through relevance decoding, a technique that identifies meaningful matches based on contextual information. REVDECODE represents binaries as directed layered graphs and employs a Viterbi-inspired algorithm to determine the most relevant matches. Additionally, we propose GPU-optimized variants of REVDECODE which partition the graph traversal workload into independent subsets, maximizing GPU resource utilization and enabling greater parallelization. Experimental results demonstrate that REVDECODE significantly enhances the performance of existing function matchers, improving rankings for 56.3% to 98.8% of the evaluated functions across multiple datasets and matchers."
  },
  {
    "id": 3928,
    "year": 2025,
    "title": "BLens: Contrastive Captioning of Binary Functions using Ensemble Embedding",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/benoit",
    "abstract": "Function names can greatly aid human reverse engineers, which has spurred the development of machine learning-based approaches to predicting function names in stripped binaries. Much current work in this area now uses transformers, applying a metaphor of machine translation from code to function names. Still, function naming models face challenges in generalizing to projects unrelated to the training set. In this paper, we take a completely new approach by transferring advances in automated image captioning to the domain of binary reverse engineering, such that different parts of a binary function can be associated with parts of its name. We propose BLens, which combines multiple binary function embeddings into a new ensemble representation, aligns it with the name representation latent space via a contrastive learning approach, and generates function names with a transformer architecture tailored for function names. Our experiments demonstrate that BLens significantly outperforms the state of the art. In the usual setting of splitting per binary, we achieve an F1 score of 0.79 compared to 0.70. In the cross-project setting, which emphasizes generalizability, we achieve an F1 score of 0.46 compared to 0.29. Finally, in an experimental setting reducing shared components across projects, we achieve an F1 score of 0.32 compared to 0.19."
  },
  {
    "id": 3929,
    "year": 2025,
    "title": "TRex: Practical Type Reconstruction for Binary Code",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/bosamiya",
    "abstract": "A lack of high-quality source-level types plagues decompiled code despite decades of advancement in the science and art of decompilation. Accurate type information is crucial in understanding program behavior, and existing decompilers rely heavily on manual input from human experts to improve decompiled output. We propose TRex, a tool that performs automated deductive type reconstruction, using a new perspective that accounts for the inherent impossibility of recovering lost source types. Compared with Ghidra, a state-of-the-art decompiler used by practitioners, TRex shows a noticeable improvement in the quality of output types on 123 of 125 binaries. By shifting focus away from recovering lost source types and towards constructing accurate behavior-capturing types, TRex broadens the possibilities for simpler and more elegant decompilation tools, and ultimately reduces the manual effort needed to analyze and understand binary code."
  },
  {
    "id": 3930,
    "year": 2025,
    "title": "Vest: Verified, Secure, High-Performance Parsing and Serialization for Rust",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/cai-yi",
    "abstract": "Many software vulnerabilities lurk in parsers and serializers, due to their need to be both high-performance and conformant with complex binary formats. To categorically eliminate these vulnerabilities, prior efforts have sought to deliver provable guarantees for parsing and serialization. Unfortunately, security, performance, and usability issues with these efforts mean that unverified parsers and serializers remain the status quo.\nHence, we present Vest, the first framework for high-performance, formally verified binary parsers and serializers that combines expressivity and ease of use with state-of-the-art correctness and security guarantees, including—for the first time—resistance to basic digital side-channel attacks. Most developers interact with Vest by defining their binary format in an expressive, RFC-like DSL. Vest then generates and automatically verifies high-performance parser and serializer implementations in Rust. This process relies on an extensible library of verified parser/serializer combinators we have developed, and that expert developers can use directly.\nWe evaluate Vest via three case studies: the Bitcoin block format, TLS 1.3 handshake messages, and the WebAssembly binary format. We show that Vest has executable performance on-par (or better) than hand-written, unverified parsers and serializers, and has orders of magnitude better verification performance relative to comparable prior work."
  },
  {
    "id": 3931,
    "year": 2025,
    "title": "LEMIX: Enabling Testing of Embedded Applications as Linux Applications",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/tanksalkar",
    "abstract": "Dynamic analysis, through rehosting, is an important capability for security assessment in embedded systems software. Existing rehosting techniques aim to provide high-fidelity execution by accurately emulating hardware and peripheral interactions. However, these techniques face challenges in adoption due to the increasing number of available peripherals and the complexities involved in designing emulation models for diverse hardware. Additionally, contrary to the prevailing belief that guides existing works, our analysis of reported bugs shows that high-fidelity execution is not required to expose most bugs in embedded software. Our key hypothesis is that security vulnerabilities are more likely to arise at higher abstraction levels.\nTo substantiate our hypothesis, we introduce LEMIX, a framework enabling dynamic analysis of embedded applications by rehosting them as x86 Linux applications decoupled from hardware dependencies. Enabling embedded applications to run natively on Linux facilitates security analysis using available techniques and takes advantage of the powerful hardware available on the Linux platform for higher testing throughput. We develop various techniques to address the challenges involved in converting embedded applications to Linux applications. We evaluated LEMIX on 18 real-world embedded applications across four RTOSes and found 21 new bugs, in 12 of the applications and all 4 of the RTOS kernels. Wereport that LEMIX is superior to existing state-of-the-art techniques both in terms of code coverage (∼2X more coverage) and bug detection (18 more bugs)."
  },
  {
    "id": 3932,
    "year": 2025,
    "title": "TYPEPULSE: Detecting Type Confusion Bugs in Rust Programs",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/chen-hung-mao",
    "abstract": "Rust supports type conversions and safe Rust guarantees the security of these conversions through robust static type checking and strict ownership guidelines. However, there are instances where programmers need to use unsafe Rust for certain type conversions, especially those involving pointers. Consequently, these conversions may cause severe memory corruption problems. Despite extensive research on type confusion bugs in C/C++, studies on type confusion bugs in Rust are still lacking. Also, due to Rust's new features in the type system, existing solutions in C/C++ cannot be directly applied to Rust. In this paper, we develop a static analysis tool called TYPEPULSE to detect three main categories of type confusion bugs in Rust including misalignment, inconsistent layout, and mismatched scope. TYPEPULSE first performs a type conversion analysis to collect and determine trait bounds for type pairs. Moreover, it performs a pointer alias analysis to resolve the alias relationship of pointers. Following the integration of information into the property graph, it constructs type patterns and detects each type of bug in various conversion scenarios. We run TYPEPULSE on the top 3,000 Rust packages and uncover 71 new type confusion bugs, exceeding the total number of type confusion bugs reported in RUSTSEC over the past five years. We have received 32 confirmations from developers, along with one CVE ID and six RUSTSEC IDs."
  },
  {
    "id": 3933,
    "year": 2025,
    "title": "From Alarms to Real Bugs: Multi-target Multi-step Directed Greybox Fuzzing for Static Analysis Result Verification",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/bao-andrew",
    "abstract": "Effective verification of the true positives from false positives is crucial for improving the usability of static analysis tools and bolstering software security. Directed greybox fuzzing (DGF), based on dynamic execution, can confirm real vulnerabilities and provide proof-of-concept exploits, offering a promising solution. However, existing DGF tools are ineffective in verifying static analysis results because they are unaware of the semantic information about individual alarms and the correlations among multiple alarms.\nIn this paper, we fill this gap and present Lyso, the first multi-target, multi-step guided fuzzer that leverages semantic information (i.e., program flows) and correlations (i.e., shared root causes) derived from static analysis. By concurrently handling multiple alarms and prioritizing seeds that cover these root causes, Lyso efficiently explores multiple alarms. For each alarm, Lyso breaks down the goal of reaching an alarm into a sequence of manageable steps. By progressively following these steps, Lyso refines its search to reach the final step, significantly improving its ability to trigger challenging alarms.\nWe compared Lyso to eight state-of-the-art (directed) fuzzers. Our evaluation demonstrates that Lyso outperforms existing approaches, achieving an average 12.17x speedup while finding the highest absolute number of bugs. Additionally, we applied Lyso to verify static analysis results for real-world programs, and it successfully discovered eighteen new vulnerabilities."
  },
  {
    "id": 3934,
    "year": 2025,
    "title": "Low-Cost and Comprehensive Non-textual Input Fuzzing with LLM-Synthesized Input Generators",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/zhang-kunpeng",
    "abstract": "Modern software often accepts inputs with highly complex grammars. To conduct greybox fuzzing and uncover security bugs in such software, it is essential to generate inputs that conform to the software input grammar. However, this is a well-known challenging task because it requires a deep understanding of the grammar, which is often not available and hard to infer. Recent advances in large language models (LLMs) have shown that they can be used to synthesize high-quality natural language text and code that conforms to the grammar of a given input format. Nevertheless, LLMs are often incapable or too costly to generate non-textual outputs, such as images, videos, and PDF files. This limitation hinders the application of LLMs in grammar-aware fuzzing.\nWe present a novel approach to enabling grammar-aware fuzzing over non-textual inputs. We employ LLMs to synthesize and also mutate input generators, in the form of Python scripts, that generate data conforming to the grammar of a given input format. Then, non-textual data yielded by the input generators are further mutated by traditional fuzzers (AFL++) to explore the software input space effectively. Our approach, namely $G^2$FUZZ, features a hybrid strategy that combines a \"holistic search\" driven by LLMs and a \"local search\" driven by industrial quality fuzzers. Two key advantages are: (1) LLMs are good at synthesizing and mutating input generators and enabling jumping out of local optima, thus achieving a synergistic effect when combined with mutation-based fuzzers; (2) LLMs are less frequently invoked unless really needed, thus significantly reducing the cost of LLM usage. We have evaluated $G^2$FUZZ on a variety of input formats, including TIFF images, MP4 audios, and PDF files. The results show that $G^2$FUZZ outperforms SOTA tools such as AFL++, Fuzztruction, and FormatFuzzer in terms of code coverage and bug finding across most programs tested on three platforms: UNIFUZZ, FuzzBench, and MAGMA. $G^2$FUZZ also discovers 10 unique bugs in the latest real-world software, of which 3 are confirmed by CVE."
  },
  {
    "id": 3935,
    "year": 2025,
    "title": "Pig in a Poke: Automatically Detecting and Exploiting Link Following Vulnerabilities in Windows File Operations",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/xiang-bocheng",
    "abstract": "Symbolic links are widely utilized in file operations on the Windows system to facilitate seamless interaction and enhance the overall user experience. However, developers' failure to properly validate symbolic links during the process of file operations has led to the Link Following Vulnerabilities (LFVulns), enabling attackers to manipulate system files arbitrarily.\nIn this paper, we conduct a comprehensive analysis of existing LFVulns and reproduce 42 of them for in-depth empirical research. Our findings uncover the root causes of LFVulns and identify key factors hindering their detection and exploitation. To bridge this gap, we developed LinkZard, a prototype for the automated detection and exploitation of LFVulns targeting Windows systems. LinkZard consists of two main phases. The exploration phase employs efficient file state fuzzing to better uncover potential vulnerabilities, while the exploitation phase locates sinks and utilizes code wrapping strategies to achieve automatic exploitation. We applied LinkZard to 120 commercial programs from vendors such as Microsoft, Apple, and Intel, successfully detecting and exploiting 55 zero-day vulnerabilities. We responsibly reported all identified vulnerabilities to the affected vendors. Up to now, 49 of them have been confirmed and patched, resulting in 15 CVE assignments and bounty rewards."
  },
  {
    "id": 3936,
    "year": 2025,
    "title": "GNSS-WASP: GNSS Wide Area SPoofing",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/tibaldo",
    "abstract": "In this paper, we propose GNSS-WASP, a novel wide-area spoofing attack carried by a constellation of strategically-located synchronized transmitters. Unlike known attacks, which are constrained by the attacker's ability to track victim receivers, GNSS-WASP manipulates the positions measured by all the receivers in a target area without knowing the victim's positions. This allows GNSS-WASP to spoof a swarm of victims to another location while preserving their true formation (i.e., their relative distances). This opens the possibility of advanced attacks that divert entire fleets of vehicles and drones in a large area without the need to track specific victims. As such, GNSS-WASP bypasses state-of-the-art spoofing countermeasures that rely on constellations of receivers with known distances and those that rely on sudden, unpredictable movements for spoofing detection. While previous works discuss the stringent requirements for perfect spoofing of multiple receivers at known fixed locations, GNSS-WASP demonstrates how to spoof any number of moving receivers at unknown positions in a large area with an error that can remain hidden behind the legitimate noise. In addition to extensive simulations, we implement a prototype of GNSS-WASP with off-the-shelf software-defined radios and evaluate it on real GNSS receivers. Despite the error introduced by the proposed attack, GNSS-WASP can successfully spoof two receivers while maintaining their relative distance with an average error of 0.97 m for locations 1000 m away from the reference position. Finally, we also highlight possible countermeasures."
  },
  {
    "id": 3937,
    "year": 2025,
    "title": "LEO-Range: Physical Layer Design for Secure Ranging with Low Earth Orbiting Satellites",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/coppola",
    "abstract": "We propose LEO-Range, a novel physical layer design for secure ranging between Low Earth Orbiting ( LEO) satellites and devices. LEO-Range 1) is compatible with Orthogonal Frequency Division Multiplexing (OFDM ) modulation scheme which is widely used by high-bandwidth satellite communications, 2) it provides accurate distance measurements (within the limits imposed by the available bandwidth) , and 3) it is provably secure and reliable across a range of common satellite channels. The design is based on a novel verification scheme in the frequency domain. We provide a security proof that bounds the probability of a distance-reduction attack for arbitrary physical layer attack strategies. We implement a prototype of LEO-Range and we test it with a hardware satellite channel emulator. In common line of sight 3GPP channels with SNRs between 8.8dB and 12dB (worst case scenario at low elevation) in a single ranging from a single satellite the adversary has a probability of less than 2−20 to successfully reduce the LEO-Range measured distance by more than 117 meters. These results already significantly limit spoofing, which typically can be done even across continents, and if distances are measured consecutively and from different satellites or ground stations, the overall distance and location spoofing will be even further limited, pointing to the practical viability of LEO-Range."
  },
  {
    "id": 3938,
    "year": 2025,
    "title": "A Comprehensive Formal Security Analysis of OPC UA",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/diemunsch",
    "abstract": "OPC UA is a standardized Industrial Control System (ICS) protocol, deployed in critical infrastructures, that aims to ensure security. The forthcoming version 1.05 includes major changes in the underlying cryptographic design, including a Diffie-Hellmann based key exchange, as opposed to the previous RSA based version. Version 1.05 is supposed to offer stronger security, including Perfect Forward Secrecy (PFS). \nWe perform a formal security analysis of the security protocols specified in OPC UA v1.05 and v1.04, for the RSA-based and the new DH-based mode, using the state-of-the-art symbolic protocol verifier ProVerif. Compared to previous studies, our model is much more comprehensive, including the new protocol version, combination of the different sub-protocols for establishing secure channels, sessions and their management, covering a large range of possible configurations. This results in one of the largest models ever studied in ProVerif raising many challenges related to its verification mainly due to the complexity of the state machine. We discuss how we mitigated this complexity to obtain meaningful analysis results. Our analysis uncovered several new vulnerabilities, that have been reported to and acknowledged by the OPC Foundation. We designed and proposed provably secure fixes, most of which are included in the upcoming version of the standard."
  },
  {
    "id": 3939,
    "year": 2025,
    "title": "Towards Internet-Based State Learning of TLS State Machines",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/maehren",
    "abstract": "State machine learning extracts a Mealy state machine hypothesis from a given implementation. This approach was repeatedly used on open-source TLS implementations to find security vulnerabilities and bugs. Until now, TLS state learning has been conducted exclusively in controlled local environments, effectively avoiding various challenges, such as jitter, IDS interference, unknown network infrastructures (load balancers), timeouts, and most notably, non-determinism resulting from all these factors.\nFor the first time, we address these challenges by extending state learning beyond a controlled local environment and using it to learn TLS state machines over the Internet in a large-scale study. We improve the scope of state-of-the-art learning approaches by considering previously excluded features and directions, like ID-based session resumption, renegotiation, and CBC padding oracles. To enable a fully autonomous analysis of large numbers of servers, we develop novel techniques for dealing with large alphabets and automatically analyzing the retrieved Mealy automata.\nWe demonstrate the feasibility of our approach in a large-scale study across 7337 domains, successfully extracting 1304 state machine models. These models provide unique insights into the state machines deployed in the TLS ecosystem. Leveraging our automated analysis techniques, we uncovered a handshake transcript integrity vulnerability in Citrix NetScaler and the first CBC padding oracle vulnerabilities detected through state machine learning."
  },
  {
    "id": 3940,
    "year": 2025,
    "title": "Misty Registry: An Empirical Study of Flawed Domain Registry Operation",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/zhang-mingming",
    "abstract": "Domain registries manage the entire lifecycle of domain names within TLDs and interact with domain registrars through the Extensible Provisioning Protocol (EPP) specification. Although they adhere to standard policies, EPP implementations and operational practices can vary between registries. Even minor operational flaws at registries can expose their managed resources to abuse. However, registry operations' closed and opaque nature has limited understanding of these practices and their potential threats. In this study, we systematically analyzed the security of EPP operations across TLD registries. By analyzing the entire domain lifecycle and mapping operations to corresponding domain statuses, we discovered that registry operations are attributed to overlapping statuses and complex triggering factors. To uncover flaws in registry operations, we employed diverse data sources, including TLD zone files, historical domain registration data, and real-time registrar interfaces for comprehensive domain statuses. The analysis combined static and dynamic techniques, allowing us to externally assess domain existence and registration status, thereby revealing the inner workings of registry policies. Eventually, we discovered three novel EPP implementation deficiencies that pose domain abuse risks in major registries, including Identity Digital, Google, and Nominet. Evidence has shown that adversaries are covertly exploiting these vulnerabilities. Our experiments reveal that over 1.6 million domain names, spanning more than 50% of TLDs (e.g., .app and .top), are vulnerable due to these flawed operations. To address these issues, we responsibly disclosed the problem to the affected registries and assisted in implementing a solution. We believe that these registry operation issues require increased attention from the community."
  },
  {
    "id": 3941,
    "year": 2025,
    "title": "Haunted by Legacy: Discovering and Exploiting Vulnerable Tunnelling Hosts",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/beitis",
    "abstract": "This paper studies the prevalence and security impact of open tunnelling hosts on the Internet. These hosts accept legacy or modern tunnelling traffic from any source. We first scan the Internet for vulnerable IPv4 and IPv6 hosts, using 7 different scan methods, revealing more than 4 million vulnerable hosts which accept unauthenticated IP in IP (IPIP), Generic Routing Encapsulation (GRE), IPv4 in IPv6 (4in6), or IPv6 in IPv4 (6in4) traffic. These hosts can be abused as one-way proxies, can enable an adversary to spoof the source address of packets, or can permit access to an organization's private network. The discovered hosts also facilitate new Denial-of-service (DoS) attacks. Two new DoS attacks amplify traffic: one concentrates traffic in time, and another loops packets between vulnerable hosts, resulting in an amplification factor of at least 16 and 75, respectively. Additionally, we present an Economic Denial of Sustainability (EDoS) attack, where the outgoing bandwidth of a host is drained. Finally, we discuss countermeasures and hope our findings will motivate people to better secure tunnelling hosts."
  },
  {
    "id": 3942,
    "year": 2025,
    "title": "GeCos Replacing Experts: Generalizable and Comprehensible Industrial Intrusion Detection",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/wolsing",
    "abstract": "Protecting industrial control systems against cyberattacks is crucial to counter escalating threats to critical infrastructure. To this end, Industrial Intrusion Detection Systems (IIDSs) provide an easily retrofittable approach to uncover attacks quickly and before they can cause significant damage. Current research focuses either on maximizing automation, usually through heavy use of machine learning, or on expert systems that rely on detailed knowledge of the monitored systems. While the former hinders the interpretability of alarms, the latter is impractical in real deployments due to excessive manual work for each individual deployment. To bridge the gap between maximizing automation and leveraging expert knowledge, we introduce GeCo, a novel IIDS based on automatically derived comprehensible models of benign system behavior. GeCo leverages state-space models mined from historical process data to minimize manual effort for operators while maintaining high detection performance and generalizability across diverse industrial domains. Our evaluation against state-of-the-art IIDSs and datasets demonstrates GeCo's superior performance while remaining comprehensible and performing on par with expert-derived rules. GeCo represents a critical step towards empowering operators with control over their cybersecurity toolset, thereby enhancing the protection of valuable physical processes in industrial control systems and critical infrastructures."
  },
  {
    "id": 3943,
    "year": 2025,
    "title": "ORTHRUS: Achieving High Quality of Attribution in Provenance-based Intrusion Detection Systems",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/jiang-baoxiang",
    "abstract": "Past success in applying machine learning to data provenance graphs – a structured representation of the history of operating system activities – to detect host system intrusions has fueled continued interest in the security community. Recent solutions, particularly anomaly-based approaches using graph neural networks to detect previously unknown attacks, have reported near-perfect accuracy. Surprisingly, despite this high performance, the industry remains reluctant to adopt these intrusion detection systems (IDSs).\nWe identify Quality of Attribution (QoA) as the key factor contributing to this disconnect. QoA refers to the amount of effort required from a human analyst to investigate an IDS's detection output, uncover the root causes of an attack, understand its ramifications, and dismiss potential false alarms. Unfortunately, prior work often generates large volumes of low-QoA output, much of which is irrelevant to attack activities, leading to alert fatigue and analyst burnout.We introduce ORTHRUS, the first IDS to achieve high-QoA detection on data provenance graphs at the node level. ORTHRUS detects malicious hosts using a graph neural network (GNN) encoder designed to capture the fine-grained spatio-temporal dynamics of system events. It then reconstructs the attack path through dependency analysis to ensure high-QoA detection.\nWe compare ORTHRUS against five state-of-the-art IDSs. ORTHRUS reduces the number of nodes requiring manual inspection for attack attribution by several orders of magnitude, significantly easing the burden on security analysts while achieving strong detection performance."
  },
  {
    "id": 3944,
    "year": 2025,
    "title": "Sometimes Simpler is Better: A Comprehensive Analysis of State-of-the-Art Provenance-Based Intrusion Detection Systems",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/bilot",
    "abstract": "Provenance-based intrusion detection systems (PIDSs) have garnered significant attention from the research community over the past decade. Although recent studies report near-perfect detection performance, we show that these systems are not viable for practical deployment. We implemented eight state-of-the-art systems within a unified framework and identified nine key shortcomings that hinder their practical adoption. Through extensive experiments, we quantify the impact of these shortcomings using cybersecurity-oriented metrics and propose solutions to address them for real-world applicability. Building on these insights, we demonstrate that most existing systems add unnecessary complexity, whereas a simple neural network achieves state-of-the-art detection on five of seven DARPA datasets while offering a lighter, faster, and real-time detection solution. Finally, we highlight critical open research challenges that remain unaddressed in the current literature, paving the way for future advancements. To support research, we open-source our framework and provide pre-processed datasets with ground truth to support consistent evaluation."
  },
  {
    "id": 3945,
    "year": 2025,
    "title": "CAMP in the Odyssey: Provably Robust Reinforcement Learning with Certified Radius Maximization",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/wang-derui",
    "abstract": "Deep reinforcement learning (DRL) has gained widespread adoption in control and decision-making tasks due to its strong performance in dynamic environments. However, DRL agents are vulnerable to noisy observations and adversarial attacks, and concerns about the adversarial robustness of DRL systems have emerged. Recent efforts have focused on addressing these robustness issues by establishing rigorous theoretical guarantees for the returns achieved by DRL agents in adversarial settings. Among these approaches, policy smoothing has proven to be an effective and scalable method for certifying the robustness of DRL agents. Nevertheless, existing certifiably robust DRL relies on policies trained with simple Gaussian augmentations, resulting in a suboptimal trade-off between certified robustness and certified return. To address this issue, we introduce a novel paradigm dubbed Certified-rAdius-Maximizing Policy (CAMP) training. CAMP is designed to enhance DRL policies, achieving better utility without compromising provable robustness. By leveraging the insight that the global certified radius can be derived from local certified radii based on training-time statistics, CAMP formulates a surrogate loss related to the local certified radius and optimizes the policy guided by this surrogate loss. We also introduce policy imitation as a novel technique to stabilize CAMP training. Experimental results demonstrate that CAMP significantly improves the robustness-return trade-off across various tasks. Based on the results, CAMP can achieve up to twice the certified expected return compared to that of baselines. Our code is available at https://github.com/NeuralSec/camp-robust-rl."
  },
  {
    "id": 3946,
    "year": 2025,
    "title": "Towards Understanding and Enhancing Security of Proof-of-Training for DNN Model Ownership Verification",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/chang-yijia-verification",
    "abstract": "The great economic values of deep neural networks (DNNs) urge AI enterprises to protect their intellectual property (IP) for these models. Recently, proof-of-training (PoT) has been proposed as a promising solution to DNN IP protection, through which AI enterprises can utilize the record of DNN training process as their ownership proof. To prevent attackers from forging ownership proof, a secure PoT scheme should be able to distinguish honest training records from those forged by attackers. Although existing PoT schemes provide various distinction criteria, these criteria are based on intuitions or observations. The effectiveness of these criteria lacks clear and comprehensive analysis, resulting in existing schemes initially deemed secure being swiftly compromised by simple ideas. In this paper, we make the first move to identify distinction criteria in the style of formal methods, so that their effectiveness can be explicitly demonstrated. Specifically, we conduct systematic modeling to cover a wide range of attacks and then theoretically analyze the distinctions between honest and forged training records. The analysis results not only induce a universal distinction criterion, but also provide detailed reasoning to demonstrate its effectiveness in defending against attacks covered by our model. Guided by the criterion, we propose a generic PoT construction that can be instantiated into concrete schemes. This construction sheds light on the realization that trajectory matching algorithms, previously employed in data distillation, possess significant advantages in PoT construction. Experimental results demonstrate that our scheme can resist attacks that have compromised existing PoT schemes, which corroborates its superiority in security."
  },
  {
    "id": 3947,
    "year": 2025,
    "title": "AGNNCert: Defending Graph Neural Networks against Arbitrary Perturbations with Deterministic Certification",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/li-jiate",
    "abstract": "Graph neural networks (GNNs) achieve the state-of-the-art on graph-relevant tasks such as node and graph classification. However, recent works show GNNs are vulnerable to adversarial perturbations include the perturbation on edges, nodes, and node features, the three components forming a graph. Empirical defenses against such attacks are soon broken by adaptive ones. While certified defenses offer robustness guarantees, they face several limitations: 1) almost all restrict the adversary's capability to only one type of perturbation, which is impractical; 2) all are designed for a particular GNN task, which limits their applicability; and 3) the robustness guarantees of all methods except one are not 100% accurate.\nWe address all these limitations by developing AGNNCert, the first certified defense for GNNs against arbitrary (edge, node, and node feature) perturbations with deterministic robustness guarantees, and applicable to the two most common node and graph classification tasks. AGNNCert also encompass existing certified defenses as special cases. Extensive evaluations on multiple benchmark node/graph classification datasets and two real-world graph datasets, and multiple GNNs validate the effectiveness of AGNNCert to provably defend against arbitrary perturbations. AGNNCert also shows its superiority over the state-of-the-art certified defenses against the individual edge perturbation and node perturbation."
  },
  {
    "id": 3948,
    "year": 2025,
    "title": "LightShed: Defeating Perturbation-based Image Copyright Protections",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/foerster",
    "abstract": "Recently, image generation models like Stable Diffusion have gained significant popularity due to their remarkable achievements. However, their widespread use has raised concerns about potential misuse, particularly regarding acquiring training data, including using copyright-protected material. Various schemes have been proposed to address these concerns by introducing inconspicuous perturbations (poisons) to prevent models from utilizing these samples for training.\nWe present LightShed, a generalizable depoisoning attack that effectively identifies poisoned images and removes adversarial perturbations, showing the limitations of current protection schemes. LightShed exploits the wide availability of these protection schemes to generate poisoned examples and models their characteristics. The fingerprints derived from this process enable LightShed to efficiently extract and neutralize the perturbation from a protected image. We demonstrate the effectiveness of LightShed against several popular perturbation-based image protection schemes, including NightShade, recently presented at IEEE S&P 2024, and Glaze, published at Usenix Security 2023. Our results show that LightShed can accurately identify poisoned samples, achieving a TPR of 99.98% and TNR of 100% on detecting NightShade and effectively depoisoning them. We show that LightShed generalizes across perturbation techniques, enabling a single model to recognize poisoned images."
  },
  {
    "id": 3949,
    "year": 2025,
    "title": "Robustifying ML-powered Network Classifiers with PANTS",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/jin-minhao",
    "abstract": "Multiple network management tasks, from resource allocation to intrusion detection, rely on some form of ML-based network traffic classification (MNC). Despite their potential, MNCs are vulnerable to adversarial inputs, which can lead to outages, poor decision-making, and security violations, among other issues.\nThe goal of this paper is to help network operators assess and enhance the robustness of their MNC against adversarial inputs. The most critical step for this is generating inputs that can fool the MNC while being realizable under various threat models. Compared to other ML models, finding adversarial inputs against MNCs is more challenging due to the existence of non-differentiable components e.g., traffic engineering and the need to constrain inputs to preserve semantics and ensure reliability. These factors prevent the direct use of well-established gradient-based methods developed in adversarial ML (AML).\nTo address these challenges, we introduce PANTS, a practical white-box framework that uniquely integrates AML techniques with Satisfiability Modulo Theories (SMT) solvers to generate adversarial inputs for MNCs. We also embed PANTS into an iterative adversarial training process that enhances the robustness of MNCs against adversarial inputs. PANTS is 70% and 2x more likely in median to find adversarial inputs against target MNCs compared to state-of-the-art baselines, namely Amoeba and BAP. PANTS improves the robustness of the target MNCs by 52.7% (even against attackers outside of what is considered during robustification) without sacrificing their accuracy."
  },
  {
    "id": 3950,
    "year": 2025,
    "title": "THEMIS: Towards Practical Intellectual Property Protection for Post-Deployment On-Device Deep Learning Models",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/huang-yujin",
    "abstract": "On-device deep learning (DL) has rapidly gained adoption in mobile apps, offering the benefits of offline model inference and user privacy preservation over cloud-based approaches. However, it inevitably stores models on user devices, introducing new vulnerabilities, particularly model-stealing attacks and intellectual property infringement. While system-level protections like Trusted Execution Environments (TEEs) provide a robust solution, practical challenges remain in achieving scalable on-device DL model protection, including complexities in supporting third-party models and limited adoption in current mobile solutions. Advancements in TEE-enabled hardware, such as NVIDIA's GPU-based TEEs, may address these obstacles in the future. Currently, watermarking serves as a common defense against model theft but also faces challenges here as many mobile app developers lack corresponding machine learning expertise and the inherent read-only and inference-only nature of on-device DL models prevents third parties like app stores from implementing existing watermarking techniques in post-deployment models.\nTo protect the intellectual property of on-device DL models, in this paper, we propose THEMIS, an automatic tool that lifts the read-only restriction of on-device DL models by reconstructing their writable counterparts and leverages the untrainable nature of on-device DL models to solve watermark parameters and protect the model owner's intellectual property. Extensive experimental results across various datasets and model structures show the superiority of THEMIS in terms of different metrics. Further, an empirical investigation of 403 real-world DL mobile apps from Google Play is performed with a success rate of 81.14%, showing the practicality of THEMIS."
  },
  {
    "id": 3951,
    "year": 2025,
    "title": "A Crack in the Bark: Leveraging Public Knowledge to Remove Tree-Ring Watermarks",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/lin-junhua",
    "abstract": "We present a novel attack specifically designed against Tree-Ring, a watermarking technique for diffusion models known for its high imperceptibility and robustness against removal attacks. Unlike previous removal attacks, which rely on strong assumptions about attacker capabilities, our attack only requires access to the variational autoencoder that was used to train the target diffusion model, a component that is often publicly available. By leveraging this variational autoencoder, the attacker can approximate the model's intermediate latent space, enabling more effective surrogate-based attacks. Our evaluation shows that this approach leads to a dramatic reduction in the AUC of Tree-Ring detector's ROC and PR curves, decreasing from 0.993 to 0.153 and from 0.994 to 0.385, respectively, while maintaining high image quality. Notably, our attacks outperform existing methods that assume full access to the diffusion model. These findings highlight the risk of reusing public autoencoders to train diffusion models—a threat not considered by current industry practices. Furthermore, the results suggest that the Tree-Ring detector's precision, a metric that has been overlooked by previous evaluations, falls short of the requirements for real-world deployment."
  },
  {
    "id": 3952,
    "year": 2025,
    "title": "CertTA: Certified Robustness Made Practical for Learning-Based Traffic Analysis",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/yan-jinzhu",
    "abstract": "Learning-based traffic analysis models exhibit significant vulnerabilities to adversarial attacks. Attackers can compromise these models by generating adversarial network flows with precisely optimized perturbations. These perturbations typically take two forms: additive modifications, which include packet length padding and timing delays, and discrete alterations, such as dummy packet insertion. In response to these threats, certified robustness has emerged as a promising methodology for ensuring reliable model performance in the presence of adversarially manipulated network traffic. \nHowever, current approaches inadequately address the multi-modal nature of adversarial perturbations in network traffic, resulting in limited robustness guarantees against sophisticated attacks. To overcome this limitation, we introduce CertTA, the first solution providing certifiable robustness against multi-modal adversarial attacks in traffic analysis models. CertTA incorporates a novel multi-modal smoothing mechanism that explicitly accounts for attack-induced perturbations during the generation of smoothing samples, based on which CertTA rigorously derives robustness regions that are meaningful against these attacks. We implement a prototype of CertTA and extensively evaluate it against three categories of multi-modal adversarial attacks across six traffic analysis models and two datasets. Our experimental results demonstrate that CertTA provides significantly stronger robustness guarantees than the state-of-the-art approaches when confronting adversarial attacks. Further, CertTA is universally applicable across diverse model architectures and flow representations."
  },
  {
    "id": 3953,
    "year": 2025,
    "title": "Invisible but Detected: Physical Adversarial Shadow Attack and Defense on LiDAR Object Detection",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/kobayashi",
    "abstract": "This paper introduces \"Shadow Hack,\" the first adversarial attack exploiting naturally occurring object shadows in LiDAR point clouds to target object detection models in autonomous vehicles. Shadow Hack manipulates these shadows, which implicitly influence object detection even though they are not included in output results. To create \"Adversarial Shadows,\" we use materials that are difficult for LiDAR to measure accurately. We optimize the position and size of these shadows to maximize misclassification by point cloud-based object recognition models. In simulations, Shadow Hack achieves a 100% attack success rate at distances between 11m and 21m across multiple models. Our physical world experiments validate these findings, demonstrating up to 100% success rate at 10m against PointPillars and 98% against SECOND-IoU, using mirror sheets that achieve nearly 100% point cloud removal rate at distances from 1 to 14 meters. We also propose \"BB-Validator,\" a defense mechanism achieving a 100% success rate while maintaining high object detection accuracy."
  },
  {
    "id": 3954,
    "year": 2025,
    "title": "From Threat to Trust: Exploiting Attention Mechanisms for Attacks and Defenses in Cooperative Perception",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/wang-chenyi",
    "abstract": "Cooperative perception (CP) extends detection range and situational awareness in connected and autonomous vehicles by aggregating information from multiple agents. However, attackers can inject fabricated data into shared messages to achieve adversarial attacks. While prior defenses detect object spoofing, object removal attacks remain a serious threat. Nevertheless, prior attacks require unnaturally large perturbations and rely on unrealistic assumptions such as complete knowledge of participant agents, which limits their attack success. In this paper, we present SOMBRA, a stealthy and practical object removal attack exploiting the attentive fusion mechanism in modern CP algorithms. SOMBRA achieves 99% success in both targeted and mass object removal scenarios (a 90%+ improvement over prior art) with less than 1% perturbation strength and no knowledge of benign agents other than the victim. To address the unique vulnerabilities of attentive fusion within CP, we propose LUCIA, a novel trustworthiness-aware attention mechanism that proactively mitigates adversarial features. LUCIA achieves 94.93% success against targeted attacks, reduces mass removal rates by over 90%, restores detection to baseline levels, and lowers defense overhead by 300x compared to prior art. Our contributions set a new state-of-the-art for adversarial attacks and defenses in CP."
  },
  {
    "id": 3955,
    "year": 2025,
    "title": "Await() a Second: Evading Control Flow Integrity by Hijacking C++ Coroutines",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/bajo",
    "abstract": "Code reuse attacks exploit legitimate code sequences in a binary to execute malicious actions without introducing new code. Control Flow Integrity (CFI) defenses mitigate these attacks by restricting program execution to valid code paths. However, new programming paradigms, like C++20 coroutines, expose gaps in current CFI protections. We demonstrate that, despite rigorous standardization, C++ coroutines present new vulnerabilities that undermine both coarse-grained and fine-grained CFI defenses. Coroutines, widely used in asynchronous programming, store critical execution data in writable heap memory, making them susceptible to exploitation. This paper introduces Coroutine Frame-Oriented Programming (CFOP), a novel code reuse attack that leverages these vulnerabilities across major compilers. We demonstrate how CFOP allows attackers to hijack program execution and manipulate data in CFI-protected environments. Through a series of Proof of Concept (PoC) exploits, we show the practical impact of CFOP. We also propose defensive measures to enhance coroutine security and address this emerging threat."
  },
  {
    "id": 3956,
    "year": 2025,
    "title": "System Register Hijacking: Compromising Kernel Integrity By Turning System Registers Against the System",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/miller",
    "abstract": "The Linux kernel has been a battleground between security researchers identifying new exploitation techniques and those developing mitigations to protect the kernel from exploitation. This is an ongoing battle: last year, Google's KernelCTF Vulnerability Research Program paid out 44 bounties for unique exploitation techniques submitted to the program, many of which targeted control flow hijacking vulnerabilities. However, the era of control flow hijacking exploits in the kernel may be coming to an end: FineIBT, now the default Control Flow Integrity measure in the Linux kernel, blocks all known control flow hijacking exploitation techniques.\nIn this paper, we propose System Register Hijacking, a previously overlooked frontier in the exploitation of control flow hijacking vulnerabilities in the kernel context. Our approach provides a comprehensive examination of typically overlooked system registers, leading us to propose several powerful exploitation techniques targeting different x86-64 system registers (e.g., cr0, cr3, and gs) and aarch64 system registers (e.g., pan, elr_el1, and vbar_el1) to break kernel security in different ways. While all of our techniques present new avenues for attackers, one in particular, which leverages the x86-64 swapgs instruction, requires neither general purpose register nor stack control, making it one of the most powerful kernel exploitation primitives currently known. Moreover, to our knowledge, this is the first exploitation primitive capable of bypassing the FineIBT mitigation, demonstrating not only the power of our technique but also the continued relevance of control flow hijacking vulnerabilities.\nIn addition to developing these techniques, we propose mitigations to defend against most of them. Though some of our techniques appear challenging to mitigate, our swapgs mitigation restores FineIBT's security posture at a performance cost of just under 1%."
  },
  {
    "id": 3957,
    "year": 2025,
    "title": "When Good Kernel Defenses Go Bad: Reliable and Stable Kernel Exploits via Defense-Amplified TLB Side-Channel Leaks",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/maar-kernel",
    "abstract": "Over the past decade, the Linux kernel has seen a significant number of memory-safety vulnerabilities. However, exploiting these vulnerabilities becomes substantially harder as defenses increase. A fundamental defense of the Linux kernel is the randomization of memory locations for security-critical objects, which greatly limits or prevents exploitation.\nIn this paper, we show that we can exploit side-channel leakage in defenses to leak the locations of security-critical kernel objects. These location disclosure attacks enable successful exploitations on the latest Linux kernel, facilitating reliable and stable system compromise both with re-enabled and new exploit techniques. To identify side-channel leakages of defenses, we systematically analyze 127 defenses. Based on this analysis, we show that enabling any of 3 defenses – enforcing strict memory permissions or virtualizing the kernel heap or kernel stack – allows us to obtain fine-grained TLB contention patterns via an Evict+Reload TLB side-channel attack. We combine these patterns with kernel allocator massaging to present location disclosure attacks, leaking the locations of kernel objects, i.e., heap objects, page tables, and stacks. To demonstrate the practicality of these attacks, we evaluate them on recent Intel CPUs and multiple kernel versions, with a runtime of 0.3 s to 17.8 s and almost no false positives. Since these attacks work due to side-channel leakage in defenses, we argue that the virtual stack defense makes the system less secure."
  },
  {
    "id": 3958,
    "year": 2025,
    "title": "Approximation Enforced Execution of Untrusted Linux Kernel Extensions",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/sun-hao",
    "abstract": "Modern OS kernels allow untrusted extensions, such as eBPF programs, to be dynamically loaded into kernel space, with their safety ensured by an in-kernel verifier. However, this approach implicitly places the entire verifier, a complicated and error-prone component, within the trusted code base. Despite substantial efforts to verify and test the verifier, its complexity and frequent updates continue to introduce soundness bugs, leading to various security issues.\nThis paper introduces Approximation-Enforced Execution (AEE), a novel concept to ensure the safe execution of untrusted kernel extensions, even in the presence of potential verifier bugs. The verifier can be essentially abstracted into two key components: the complex state approximation and the simpler safety check based on the former. By enforcing the program execution to remain within the verifier's approximations, the soundness of state approximation is, by design, not assumed—executions with non-contained states are terminated, thereby significantly reducing the trust base. AEE also leverages the verifier, but mainly obtains the approximations. It then rewrites the program to conduct the approximation enforcement, where trust is established by combining the runtime facts with minimal reliance on the verifier's safety checks. We apply AEE to ensure the spatial memory safety of eBPF programs and formally prove its soundness w.r.t. mitigating the verifier's soundness bugs and completeness w.r.t. ensuring safety under the reduced trust base. Our evaluation shows that our prototype reduces the trusted code base by 4.5x, with an average runtime overhead of 1.2% and an average increase in binary size of 4.8%."
  },
  {
    "id": 3959,
    "year": 2025,
    "title": "EKC: A Portable and Extensible Kernel Compartment for De-Privileging Commodity OS",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/yan-jiaqin",
    "abstract": "Kernel compartmentalization through privilege separation is an effective solution for reducing the trusted computing base of modern operating systems (OS) with monolithic kernels. However, existing approaches to kernel compartmentalization often depend on higher-privileged software or platform-specific hardware features, posing challenges to their portable deployment and practical application. In this paper, we propose Embedded Kernel Compartment (EKC), a kernel compartment that embeds itself to a commodity OS as a privileged, isolated compartment. EKC is both portable across multiple ISAs without hardware modification and extensible to multiple OSes, even those developed in different languages. Moreover, EKC can serve both kernel components and user-space applications, enabling security critical tasks and providing sensitive data storage. We implemented a prototype of EKC in Rust, which has been successfully ported to run on multiple ISAs (RISC-V and ARM) and extended to be compatible with various OS kernels (FreeRTOS, rCore, and TinyLinux) with additional security services. Through comprehensive analysis and evaluation, the results demonstrate that EKC is a practical and effective solution for kernel compartmentalization."
  },
  {
    "id": 3960,
    "year": 2025,
    "title": "The Cost of Performance: Breaking ThreadX with Kernel Object Masquerading Attacks",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/shao",
    "abstract": "Microcontroller-based IoT devices often use embedded real-time operating systems (RTOSs). Vulnerabilities in these embedded RTOSs can lead to compromises of those IoT devices. Despite the significance of security protections, the absence of standardized security guidelines results in various levels of security risk across RTOS implementations. Our initial analysis reveals that popular RTOSs such as FreeRTOS lack essential security protections. While Zephyr OS and ThreadX are designed and implemented with essential security protections, our closer examination uncovers significant differences in their implementations of system call parameter sanitization. We identify a performance optimization practice in ThreadX that introduces security vulnerabilities, allowing for the circumvention of parameter sanitization processes. Leveraging this insight, we introduce a novel attack named the Kernel Object Masquerading (KOM) Attack (as the attacker needs to manipulate one or multiple kernel objects through carefully selected system calls to launch the attack), demonstrating how attackers can exploit these vulnerabilities to access sensitive fields within kernel objects, potentially leading to unauthorized data manipulation, privilege escalation, or system compromise. We introduce an automated approach involving under-constrained symbolic execution to identify the KOM attacks and to understand the implications. Experimental results demonstrate the feasibility of KOM attacks on ThreadX-powered platforms. We reported our findings to the vendors, who recognized the vulnerabilities, with Amazon and Microsoft acknowledging our contribution on their websites."
  },
  {
    "id": 3961,
    "year": 2025,
    "title": "Finding Metadata Inconsistencies in Distributed File Systems via Cross-Node Operation Modeling",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/ma-fuchen",
    "abstract": "Metadata consistency is crucial for distributed file systems (DFSes) as it ensures that different clients have a consistent view of the data. However, DFSes are inherently error-prone, leading to metadata inconsistencies. Though rare, such inconsistencies can have severe consequences, including data loss, service failures, and permission violations. Unfortunately, there is limited understanding of metadata inconsistency characteristics, let alone an effective method for detecting them.\nThis paper presents a comprehensive study of metadata inconsistencies over the past five years across four widely-used DFSes. We identified two key findings: 1) Metadata inconsistencies are mainly triggered by interrelated cross-node file operations rather than system faults. 2) The root cause of inconsistencies mainly lies in the metadata conflict resolution process. Inspired by these findings, we proposed Horcrux, a highly effective fuzzing framework for detecting metadata inconsistencies in DFSes. Horcrux uses cross-node operation modeling to reduce the infinite input combinations to a manageable space. In this way, Horcrux captures implicit cross-node operation relationships and triggers more conflict resolution logic. Currently, Horcrux has detected 10 previously unknown metadata inconsistencies. In addition, Horcrux covers 20.29%-146.21% more conflict resolution code than state-of-the-art tools."
  },
  {
    "id": 3962,
    "year": 2025,
    "title": "Save what must be saved: Secure context switching with Sailor",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/kalani",
    "abstract": "Instruction set architectures (ISAs) are complex, with hundreds of registers and instructions that can modify dozens of them during execution, variably on each instance. Prose-style ISA specifications struggle to capture these intricacies of the ISAs, where often the important details about a single register are spread out across hundreds of pages of documentation. Ensuring that all ISA-state is swapped in context switch implementations of privileged software requires meticulous examination of these pages. This manual process is tedious and error-prone.  \nWe propose a tool called Sailor that leverages machine-readable ISA specifications written in Sail and Isla symbolic execution engine for Sail to automate this task. Sailor determines the ISA-state that must be swapped during the context switch using the data collected from Isla and a novel algorithm to identify all the ISA-state that must be swapped during context switches. We use Sailor to assess the context switch code of multiple systems: from regular user process context switching code in the RISC-V Linux kernel on the StarFive VisionFive2 board, to the enclave context switching code in confidential computing frameworks, Keystone and Komodo. We identify multiple mishandled security-sensitive ISA-state. This research exposes an often overlooked attack surface that stems from mishandled ISA-state, enabling unprivileged adversaries to exploit system vulnerabilities."
  },
  {
    "id": 3963,
    "year": 2025,
    "title": "Flexway O-Sort: Enclave-Friendly and Optimal Oblivious Sorting",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/gu-tianyao",
    "abstract": "Oblivious algorithms are being deployed at large scale in real world to enable privacy-preserving applications such as Signal's private contact discovery. Oblivious sorting is a fundamental building block in the design of oblivious algorithms for numerous computation tasks. Unfortunately, there is still a theory-practice gap for oblivious sort. The commonly implemented bitonic sorting algorithm is not asymptotically optimal, whereas known asymptotically optimal algorithms suffer from large constants.\nIn this paper, we construct a new oblivious sorting algorithm called flexway o-sort, which is asymptotically optimal, concretely efficient, and suitable for implementation in hardware enclaves such as Intel SGX. For moderately large inputs of 12 GB, our flexway o-sort algorithm outperforms known oblivious sorting algorithms by 1.32x to $28.8x when the data fits within the hardware enclave, and by 4.1x to 208x when the data does not fit within the hardware enclave. We also implemented various applications of oblivious sorting, including histogram, database join, and initialization of an ORAM data structure. For these applications and data sets from 8GB to 32GB, we achieve 1.44 ∼ 2.3x speedup over bitonic sort when the data fits within the enclave, and 4.9 ∼ 5.5x speedup when the data does not fit within the enclave."
  },
  {
    "id": 3964,
    "year": 2025,
    "title": "Treebeard: A Scalable and Fault Tolerant ORAM Datastore",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/setayesh",
    "abstract": "We present Treebeard - the first scalable and fault tolerant Oblivious RAM (ORAM) based datastore designed to protect applications from access pattern attacks. Current ORAM systems face challenges in practical adoption due to their limited ability to handle concurrent workloads, scale effectively, and ensure fault tolerance. We address all three limitations in Treebeard by utilizing a multi-layer architecture that scales horizontally, handling thousands of requests in parallel, while replicating the data to prevent data loss upon failures. Experimental evaluation demonstrates Treebeard's ability to scale linearly, achieving a throughput of 160K ops/sec  with 16 machines; this behavior is similar to the enclave-based state-of-the-art, Snoopy. Being fault-tolerant, Treebeard recovers from failures with close to zero downtime and achieves 13.8x the throughput of QuORAM, the latest fault tolerant ORAM system, even without scaling."
  },
  {
    "id": 3965,
    "year": 2025,
    "title": "Learning from Functionality Outputs: Private Join and Compute in the Real World",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/falzon",
    "abstract": "Private Join and Compute (PJC) is a two-party protocol recently proposed by Google for various use-cases, including ad conversion (Asiacrypt 2021) and which generalizes their deployed private set intersection sum (PSI-SUM) protocol (EuroS&P 2020). PJC allows two parties, each holding a key-value database, to privately evaluate the inner product of the values whose keys lie in the intersection. While the functionality output is not typically considered in the security model of the MPC literature, it may pose real-world privacy risks, thus raising concerns about the potential deployment of protocols like PJC.\nIn this work, we analyze the risks associated with the PJC functionality output. We consider an adversary that is a participating party of PJC and describe four practical attacks that break the other party's input privacy, and which are able to recover both membership of keys in the intersection and their associated values. Our attacks consider the privacy threats associated with deployment and highlight the need to include the functionality output as part of the MPC security model."
  },
  {
    "id": 3966,
    "year": 2025,
    "title": "ALERT: Machine Learning-Enhanced Risk Estimation for Databases Supporting Encrypted Queries",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/wang-longxiang",
    "abstract": "While searchable symmetric encryption (SSE) offers efficient, sublinear search over encrypted data, it remains susceptible to leakage abuse attacks (LAAs), which can exploit access and search patterns to compromise data privacy. Existing methods for quantifying leakage typically require a comprehensive analysis of all queries, making them unsuitable for real-time risk assessment. Since leakages in SSE are revealed incrementally with each query, there is a pressing need for risk assessments to be conducted on the fly, enabling prompt alerts to clients about potential privacy threats. To address this challenge, we propose ALERT, a machine learning-enhanced framework for real-time risk assessment in searchable encryption. ALERT leverages sophisticated learning algorithms to automatically identify keyword features from public auxiliary information, learning them as a classifier. When a query is executed, ALERT efficiently predicts the associated keyword and estimates the likelihood of leakage. Experimental results show that ALERT can deliver predictions within seconds, achieving a substantial speed-up of 31.1x compared to existing state-of-the-art methods."
  },
  {
    "id": 3967,
    "year": 2025,
    "title": "Distributed Private Aggregation in Graph Neural Networks",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/jia-huanhuan",
    "abstract": "Graph Neural Networks (GNNs) have shown considerable promise in handling graph-structured data, yet their use is restricted in privacy-sensitive environments, especially in distributed settings. In this setting, current methods for preserving privacy in GNNs often rely on unrealistic assumptions or fail to construct effective models. In response, this paper introduces Distributed Private Aggregation (DPA), a pioneering GNN aggregation method which is built upon Secure Multi-Party Computation protocols, and is designed to ensure node-level differential privacy. We implement DPA-GNN, which to our knowledge, is the most effective privacy-preserving GNN model suitable for distributed contexts. Through extensive experiments on six real-world datasets, DPA-GNN has proven to consistently surpass existing privacy preserving GNNs, offering an optimal balance between privacy and utility."
  },
  {
    "id": 3968,
    "year": 2025,
    "title": "Suda: An Efficient and Secure Unbalanced Data Alignment Framework for Vertical Privacy-Preserving Machine Learning",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/song-lushan",
    "abstract": "Secure data alignment, which securely aligns the data between parties, is the first and crucial step in vertical privacy-preserving machine learning (VPPML). Practical applications, e.g. advertising, require VPPML for personalized services. Meanwhile, the data held by parties in these applications are usually unbalanced. Existing secure unbalanced data alignment approaches typically rely on Cuckoo Hashing, which introduces redundant data outside the intersection, leading to significantly increasing communication size during secure training in VPPML. Though secure shuffle operations can trim these redundant data, these operations would incur huge communication overhead. As a result, these secure approaches should be optimized for efficiency in VPPML scenarios.\nIn this paper, we propose Suda, an efficient and secure unbalanced data alignment framework for VPPML. By leveraging polynomial-based operations rather than Cuckoo Hashing, Suda efficiently, directly, and exclusively outputs data shares in the intersection without expensive secure shuffle operations. Consequently, Suda efficiently and seamlessly aligns with secure training in VPPML. Specifically, we first design a novel and efficient batch private information retrieval (PIR) protocol based on the oblivious polynomial reduction and evaluation protocols. Second, we design a batch PIR-to-share protocol extended from the batch PIR protocol with the oblivious polynomial interpolation protocol. Note that the batch PIR-to-share protocol securely obtains feature shares rather than the plaintext features which are the outputs of the batch PIR protocol. Comprehensive experiment results demonstrate that: (1) Suda outperforms the state-of-the-art secure data alignment framework by 31.14 x ∼ 210.78 x in communication size and up to 8.21 x in running time; and (2) Suda outperforms the state-of-the-art batch PIR framework by up to 11.53 x in server time."
  },
  {
    "id": 3969,
    "year": 2025,
    "title": "Assuring Certified Database Utility in Privacy-Preserving Database Fingerprinting",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/song-mingyang",
    "abstract": "Fingerprinting techniques allow a database owner (DO) to embed unique identifiers within relational databases to trace unauthorized redistribution. To protect its interests, the DO often prioritizes maximizing fingerprint robustness, resulting in extensive modifications to the databases. However, excessive modifications may significantly degrade the databases' utility, making recipients hesitant to purchase databases that seem compromised when they cannot evaluate the maximum number of modified bits made during fingerprinting process. Current database fingerprinting techniques focus only on boosting fingerprint robustness, without providing recipients any mechanism to verify the degree of modifications. This paper, for the first time, addresses the research gap in providing recipients the ability to verify the maximum number of modified bits in database fingerprinting. We introduce a fuzzy perturbation verification (FPV) protocol, which enables a verifier to assess the extent of modifications made to a bit-string by a prover while keeping the exact modification positions and original bit-string confidential. Using the FPV protocol, we propose UtiliClear, a novel database fingerprinting scheme that allows the recipient to specify and verify the modification degree within the fingerprinted database. We theoretically validate that UtiliClear enables recipients to verify the extent of modifications during the fingerprinting process while maintaining fingerprint robustness, database utility, and data privacy. To demonstrate its effectiveness, we evaluate UtiliClear's performance using large real-world datasets. The experimental results and analysis indicate that UtiliClear incurs modest overhead while preserving fingerprint robustness and database utility comparable to existing state-of-the-art schemes."
  },
  {
    "id": 3970,
    "year": 2025,
    "title": "Shechi: A Secure Distributed Computation Compiler Based on Multiparty Homomorphic Encryption",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/smajlovic",
    "abstract": "We present Shechi, an easy-to-use programming framework for secure high-performance computing on distributed datasets. Shechi automatically converts Pythonic code into a secure distributed equivalent using multiparty homomorphic encryption (MHE), combining homomorphic encryption (HE) and secure multiparty computation (SMC) techniques to enable efficient distributed computation. Shechi abstracts away considerations about the private and distributed aspects of the input data from end users through a familiar Pythonic syntax. Our framework introduces new data types for the efficient handling of distributed data as well as systematic compiler optimizations for cryptographic and distributed computations. We evaluate Shechi on a wide range of applications, including principal component analysis and complex genomic analysis tasks. Our results demonstrate Shechi's ability to uncover optimizations missed even by expert developers, achieving up to 15× runtime improvements over the prior state-of-the-art solutions and a 40-fold improvement in overall code expressiveness compared to manually optimized code. Shechi represents the first MHE compiler, extending secure computation frameworks to the analysis of sensitive distributed datasets."
  },
  {
    "id": 3971,
    "year": 2025,
    "title": "Private Set Intersection and other Set Operations in the Third Party Setting",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/yeo",
    "abstract": "We present a collection of protocols to perform privacy-preserving set operations in the third-party private set intersection (PSI) setting. This includes several protocols for multi-party third party PSI. In this model, there are multiple input parties (or clients) each holding a private set of elements and the receiver is an external party (termed as third-party) with no inputs. Multi-party third party PSI enables the receiver to learn only the intersection result of all input clients' private sets while revealing nothing else to the clients and the receiver. Our solutions include constructions that are provably secure against an arbitrary number of colluding parties in the semi-honest model. Additionally, we present protocols for third-party private set difference and private symmetric difference, whereby the learned output by the inputless third-party is the set difference and symmetric difference respectively of two other input parties, while preserving the same privacy guarantees. The motivation in the design of these protocols stems from their utilities in numerous real-world applications. We implemented our protocols and conducted experiments across various input and output set sizes."
  },
  {
    "id": 3972,
    "year": 2025,
    "title": "Detecting Compromise of Passkey Storage on the Cloud",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/islam",
    "abstract": "FIDO synced passkeys address account recovery challenges by enabling users to back up their FIDO2 private signing keys to the cloud storage of passkey management services (PMS). However, it introduces a serious security risk — attackers can steal users' passkeys through breaches of PMS's cloud storage. Unfortunately, existing defenses cannot eliminate this risk without reintroducing account recovery challenges or disrupting users' daily account login routines. In this paper, we present CASPER, the first passkey breach detection framework that enables web service providers to detect the abuse of passkeys leaked from PMS for unauthorized login attempts. Our analysis shows that CASPER provides compelling detection effectiveness, even against knowledgeable attackers who strategically optimize their attacks to evade CASPER's detection. We also show how CASPER can be seamlessly integrated into the existing passkey backup, synchronization, and authentication processes, with only minimal impact on user experience, negligible performance overhead, and minimum deployment and storage complexity for the participating parties."
  },
  {
    "id": 3973,
    "year": 2025,
    "title": "OneTouch: Effortless 2FA Scheme to Secure Fingerprint Authentication with Wearable OTP Token",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/yan-yihui",
    "abstract": "The security of fingerprint authentication is increasingly at risk from various attacks. Two-factor authentication (2FA) is a widely adopted approach to mitigate unauthorized access caused by compromised credentials. However, existing 2FA methods are not well-suited for direct use with fingerprint authentication devices, as they often require distinct and additional user interactions that disrupt established user habits, or they depend on specialized I/O interfaces that are not available on these devices. In this paper, we propose a novel 2FA scheme termed OneTouch, which maintains the simplicity of conventional fingerprint authentication - merely touching the scanner with a finger - while integrating a secondary challenge-response OTP (One-Time Password) authentication scheme using a wearable OTP token. This is accomplished by transforming the fingerprint scanner from a device designed for imaging fingerprints to an I/O device capable of capturing temporal voltage variations of the contact object. Consequently, OneTouch is capable of establishing touch-based communication channels between the scanner and the wearable token for OTP protocol exchange. By directly wiring the OTP token to the authentication device through human body, OneTouch minimizes the risk of interception by adversaries, thereby reducing the attack surface. We provide an extensive discussion of the security risks and evaluate the effectiveness of the touch-based channel for OTP credential exchange."
  },
  {
    "id": 3974,
    "year": 2025,
    "title": "Practically Secure Honey Password Vaults: New Design and New Evaluation against Online Guessing",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/cheng-haibo",
    "abstract": "Password vaults are used to manage multiple account passwords, encrypted with a master password. However, ciphertext stored on synchronization servers is vulnerable to leakage and offline guessing attacks, potentially compromising all accounts. Honey password vaults address this by generating decoy vaults for incorrect master passwords, making offline guessing infeasible and requiring online verification. \nExisting studies on honey vaults rely on a small dataset of only 276 vaults for model training and security evaluation, limiting their conclusions. More importantly, existing evaluations focus solely on the distinguishability between real and decoy vaults, overlooking practical security: How many accounts could be cracked via online guessing? \nIn this paper, we construct a large dataset of millions of vaults by aggregating numerous leaked password datasets. With the dataset, we employ advanced machine learning techniques for both decoy generation and identification. We show that various text classification algorithms, especially pre-trained models, significantly outperform existing attacks with distinguishing accuracy of 95.79%–83.75%. Further, we introduce a Transformer model that generates more plausible decoy vaults, no attacks achieve accuracy more than 64.35%. \nWe further assess the practical security of honey vaults against online guessing. Our new model achieves the best performance, only 0.51 accounts is cracked on average with 1,000 online attempts. By applying two simple measures, we enhance the scheme to a practical level: 1) using honey accounts for leakage detection, and 2) avoiding the encryption of passwords for websites with unlimited login attempts. These improvements reduce the cracked number to 0.11. We also offer new insights, such as that even a poor model can achieve notable practical security by using our measures."
  },
  {
    "id": 3975,
    "year": 2025,
    "title": "Password Guessing Using Large Language Models",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/zou-yunkai",
    "abstract": "Passwords are ubiquitously used for authentication/encryption, and password guessing attacks are the most effective technique for evaluating password strength. While large language models (LLMs) like ChatGPT-4o have demonstrated remarkable capabilities in text comprehension and reasoning across various general natural language processing tasks, they face limitations due to their static knowledge (e.g., fixed training data that lacks domain adaptability), especially in specialized tasks such as generating accurate password guesses.\nThis work provides a brand new technical route for password guessing, by proposing an LLM-based guessing framework, namely PassLLM, that leverages low-rank adaptation techniques. PassLLM systematically addresses four major password guessing scenarios, each of which is based on varied kinds of information available to the attacker. To reduce the high computation costs in password generation with LLMs, we propose two generation algorithms tailored for trawling and targeted guessing, respectively, enabling efficient password generation at scale (e.g., 1,000 guesses per user). Further, we apply model distillation to improve the generation speed by 11.5 times in trawling guessing scenarios without significantly reducing the success rate. Particularly, our generation algorithms are applicable to a wide range of decoder-only-based LLMs (e.g., Mistral, Llama-2/3, and Qwen-2).\nExtensive experiments on 11 real-world password datasets demonstrate the effectiveness of our framework: (1) PassLLM for trawling guessing scenarios, whose guessing success rates are generally 2.87%-17.07% higher than its foremost counterpart; (2) PassLLM-I for targeted guessing based on personally identifiable information (PII), which guesses 12.54%-31.63% of common users within 100 guesses, outperforming its foremost counterpart by 15.10%-45.98%; (3) PassLLM-II for targeted guessing based on users' password reuse behaviors, which outperforms its foremost counterpart by 6.31%-13.87%; and (4) PassLLM-III for targeted guessing based on users' PII and sister password(s), which outperforms its foremost counterpart by 13.44%-36.14%. We believe this work makes a substantial step toward introducing LLMs into the password guessing domain."
  },
  {
    "id": 3976,
    "year": 2025,
    "title": "A Framework for Abusability Analysis: The Case of Passkeys in Interpersonal Threat Models",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/daffalla",
    "abstract": "The recent rollout of passkeys by hundreds of web services online is the largest attempt yet to achieve the goal of passwordless authentication. However, new authentication mechanisms can often overlook the unique threats faced by at-risk users, such as survivors of intimate partner violence, human trafficking, and elder abuse. Such users face interpersonal threats: adversaries who routinely have physical access to devices and either know or can compel disclosure of passwords or PINs. The extent to which passkeys enable or mitigate such interpersonal threats has not yet been explored. We perform the first analysis of passkeys in interpersonal threat models. To do so, we introduce an abusability analysis framework to help practitioners and researchers identify ways in which new features can be exploited in interpersonal threat models. We then apply our framework to the setting of passkeys, ultimately investigating 19 passkey-supporting services. We identify a variety of abuse vectors that allow adversaries to use passkeys to cause harm in interpersonal settings. In the most egregious cases, flawed implementations of major passkey-supporting services allow ongoing illicit adversarial access with no way for a victim to restore security of their account. We also discover abuse vectors that prevent users from accessing their accounts or that help attackers emotionally manipulate (gaslight) users."
  },
  {
    "id": 3977,
    "year": 2025,
    "title": "CertPHash: Towards Certified Perceptual Hashing via Robust Training",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/yang-yuchen",
    "abstract": "Perceptual hashing (PHash) systems—e.g., Apple's NeuralHash, Microsoft's PhotoDNA, and Facebook's PDQ—are widely employed to screen illicit content. Such systems generate hashes of image files and match them against a database of known hashes linked to illicit content for filtering. One important drawback of PHash systems is that they are vulnerable to adversarial perturbation attacks leading to hash evasion or collision. It is desirable to bring provable guarantees to PHash systems to certify their robustness under evasion or collision attacks. However, to the best of our knowledge, there are no existing certified PHash systems, and more importantly, the training of certified PHash systems is challenging because of the unique definition of model utility and the existence of both evasion and collision attacks.\nIn this paper, we propose CertPHash, the first certified PHash system with robust training. CertPHash includes three different optimization terms, anti-evasion, anti-collision, and functionality. The anti-evasion term establishes an upper bound on the hash deviation caused by input perturbations, the anti-collision term sets a lower bound on the distance between a perturbed hash and those from other inputs, and the functionality term ensures that the system remains reliable and effective throughout robust training. Our results demonstrate that CertPHash not only achieves non-vacuous certification for both evasion and collision with provable guarantees but is also robust against empirical attacks. Furthermore, CertPHash demonstrates strong performance in real-world illicit content detection tasks."
  },
  {
    "id": 3978,
    "year": 2025,
    "title": "Phishing Attacks against Password Manager Browser Extensions",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/anliker",
    "abstract": "We study a phishing attack against password manager browser extensions. Browser extension UIs are mostly displayed on top of the web browser's viewport and, thus, hard to distinguish from website content. This enables an attacker to phish master passwords by imitating a locked password manager on a website they control.\nWe implemented this attack for four password managers and demonstrated its effectiveness in a large-scale phishing simulation with 29,800 participants, among whom we detected over 400 instances of selected third-party password managers. Notably, more than 30% of these users entered their master password, with up to 58% for one specific password manager. We compare the effectiveness of the attack across different password manager UIs, analyze user behavior through mouse tracking and a post-study survey, and discuss the implications of our findings for password managers as a means of phishing protection."
  },
  {
    "id": 3979,
    "year": 2025,
    "title": "Red Bleed: A Pragmatic Near-Infrared Presentation Attack on Facial Biometric Authentication Systems",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/hu-bowen",
    "abstract": "Facial recognition is the most prevalent biometric modality in commercial verification and identification systems (e.g. Windows Hello and Apple FaceID), which typically operate under near-infrared (NIR) illumination. Such systems are generally considered secure on the premise that no commercial screen display can readily enable a NIR-based video presentation attack. However, this work demonstrates a critical vulnerability of NIR biometric authentication systems by a presentation attack, named Red Bleed, mounted on a widely used commercial-off-the-shelf (COTS) enterprise-grade face authentication system through a custom-built liquid crystal display (LCD) that costs less than 400 USD.\nDue to the scarcity of NIR video samples, it is more feasible to sneak RGB images in the visible (VIS) spectrum through, for instance, covert secret photography, photos posted on social media or screen captures during video conferencing. Besides using live captured NIR video of the target subject's face, we also propose a novel identity-preserved NIR face generative framework that combines a Variational Autoencoder (VAE) to convert VIS images into the NIR domain for this attack. In conjunction with an advanced face swapping technique, an RGB video can be transformed into a video with NIR face, enabling a more sneaky and pragmatic 2D presentation attack on NIR face biometric authentication demonstrated on a commercially available Windows Hello face authentication module.\nThe hardware design and source code supporting our findings will be made publicly available at https://github.com following paper acceptance and the corresponding Common Vulnerabilities and Exposures (CVE) release. This vulnerability has been reported to Microsoft and the vendors of the three evaluated COTS Windows Hello face recognition modules. The reported behavior has been confirmed by the Microsoft Security Response Center (MSRC), and a CVE is scheduled for public disclosure in June 2025."
  },
  {
    "id": 3980,
    "year": 2025,
    "title": "Oblivious Digital Tokens",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/liskij",
    "abstract": "A computing device typically identifies itself by exhibiting unique measurable behavior or by proving its knowledge of a secret. In both cases, the identifying device must reveal information to a verifier. Considerable research has focused on protecting identifying entities (provers) and reducing the amount of leaked data. However, little has been done to conceal the fact that the verification occurred.\nWe show how this problem naturally arises in the context of digital emblems, which were recently proposed by the International Committee of the Red Cross to protect digital resources during cyber-conflicts. To address this new and important open problem, we define a new primitive, called an Oblivious Digital Token (ODT) that can be verified obliviously. Verifiers can use this procedure to check whether a device has an ODT without revealing to any other parties (including the device itself) that this check occurred. We demonstrate the feasibility of ODTs and present a concrete construction that provably meets the ODT security requirements, even if the prover device's software is fully compromised. We also implement a prototype of the proposed construction and evaluate its performance, thereby confirming its practicality."
  },
  {
    "id": 3981,
    "year": 2025,
    "title": "V-ORAM: A Versatile and Adaptive ORAM Framework with Service Transformation for Dynamic Workloads",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/zhang-bo-voram",
    "abstract": "Oblivious RAM (ORAM) has been attracting significant attention for building encrypted data storage systems due to its strong security guarantees and communities' continuing effort in improving its efficiency. Despite great potential, a specific ORAM scheme is normally designed and optimized for a certain type of client workloads, given the nature of its complicated cryptographic construction. Once deployed, a single ORAM service can hardly serve dynamic workloads in an efficient and cost-effective manner. To bridge the gap, in this paper, we propose a versatile ORAM framework named V-ORAM, which can efficiently and securely switch between different ORAM services to adaptively serve dynamic workloads in the real-world. In particular, V-ORAM is equipped with a service transformation protocol that leverages a base ORAM as an intermedia of transformation and can synchronize the states of tree-based ORAMs without downloading and rebuilding the ORAM by the client. We formalize the security of V-ORAM, and prove that V-ORAM holds the security of ORAMs, including the process of service transformation. V-ORAM also provides a planner to recommend the ORAM service type and ORAM parameters for adapting to the client workloads, server resources and monetary expenses. We implement V-ORAM and evaluate the cost of transformation. We also conduct real-world case studies over three medical datasets and different workloads. Compared with directly rebuilding ORAMs, V-ORAM saves up to 10^4.12x processing time and communication cost, up to 33.1% of monetary costs in real-world workloads, and generates constant impact to employed ORAM services, i.e., < 5ms in processing and < 50KB in communication."
  },
  {
    "id": 3982,
    "year": 2025,
    "title": "AUTOVR: Automated UI Exploration for Detecting Sensitive Data Flow Exposures in Virtual Reality Apps",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/kim-john",
    "abstract": "The rise of Virtual Reality (VR) has provided developers with an unprecedented platform for creating games and applications (apps) that require distinct inputs, different from those of conventional devices like smartphones. The Meta Quest VR platform, driven by Meta, has democratized VR app publishing and attracted millions of users worldwide. However, as the number of published apps grows, there is a notable lack of robust headless tools for user interface (UI) exploration and user event testing. To address this need, we present AUTOVR, an automatic framework for dynamic UI and user event interaction in VR apps built on the Unity Engine. Unlike conventional Android and GUI testers, AUTOVR analyzes the app's internal binary to reveal hidden events, resolves generative event dependencies, and utilizes them for comprehensive exploration of VR apps. Using sensitive data exposure as a performance metric, we compare AUTOVR with Android Monkey, a widely used headless Android GUI stress testing tool. Our empirical evaluation demonstrates AUTOVR's superior performance, triggering an order of magnitude of more sensitive data exposures and significantly enhancing the privacy of VR apps."
  },
  {
    "id": 3983,
    "year": 2025,
    "title": "Found in Translation: A Generative Language Modeling Approach to Memory Access Pattern Attacks",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/jia-grace",
    "abstract": "Confidential computing environments (CCEs) provide a secure way for privacy-sensitive applications to ensure the confidentiality and integrity of data and computations offloaded to the cloud, relying on a hardware root of trust. However, the cloud provider-controlled Operating System (OS) stack still manages key memory management system services such as paging. Several recent works have demonstrated that these services can leverage side channels, specifically page access patterns, to reconstruct private application data. However, related attacks have primarily targeted applications with simple one-to-one mappings between application-level objects and OS-level pages, which is seldom true for most real-world cloud applications. Moreover, these attacks tend to overlook correlations in access patterns—a common occurrence in most real-world applications—leaving untapped critical side-channel information for improving attack accuracy.\nWe propose a novel attack approach that leverages access correlations across pages in cloud applications using generative language models. Our key insight is that there are strong parallels between application page access patterns and grammatical structures in natural languages, making language modeling an excellent fit for reconstructing sensitive application data with high accuracy. Our attack, named FIT, utilizes a recurrent encoder-decoder architecture to predict application-level object accesses from a sequence of page-level accesses. Our evaluations on popular AI/ML model inference services and semantic search applications show that FIT can predict object-level access sequences with an average accuracy ranging from 71.7% to 99.9%, significantly outperforming prior state-of-the-art approaches."
  },
  {
    "id": 3984,
    "year": 2025,
    "title": "More is Less: Extra Features in Contactless Payments Break Security",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/pavlides",
    "abstract": "The EMV contactless payment system has many independent parties: payment providers, terminal companies, smartphone companies, banks and regulators. EMVCo publishes a 15 book specification that these companies use to operate together. However, many of these parties have independently added additional features, such as Square restricting offline readers to phone transactions only, Apple, Google and Samsung implementing transit modes and Visa and Mastercard complying with regional regulations on high value contactless payments. We investigate these features, and find that these parties have been independently retrofitting and overloading the core EMV specification. Subtle interactions and mismatches between the different companies' additions lead to a range of vulnerabilities, making it possible to bypass restrictions to smartphone only payments, make unauthenticated high value transactions offline, and use a cloned card to make a £25000 transaction offline. To find fixes, we build formal models of the EMV protocol with the new features we investigated and test different possible solutions. We have engaged with EMV stakeholders and worked with the company Square to implement these fixes."
  },
  {
    "id": 3985,
    "year": 2025,
    "title": "Current Affairs: A Security Measurement Study of CCS EV Charging Deployments",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/szakaly",
    "abstract": "Since its introduction in 2012, the Combined Charging System (CCS) has emerged as the leading technology for EV fast charging in Europe, North America and parts of Asia. The charging communication of CCS is defined by the ISO 15118 standards, which have been improved over the years. Most notably, in 2014, important security features such as Transport Layer Security (TLS) and usability enhancements such as Plug and Charge were introduced.\nIn this paper, we conduct the first measurement study of publicly deployed CCS DC charging stations to capture the state of deployment for different protocol versions and to better understand the attack surface of the EV charging infrastructure. In our evaluation, we examine 325 chargers manufactured between April 2013 and June 2023, and installed as late as May 2024 by 26 manufacturers across 4 European countries. We find that only 12% of the charging stations we analyzed implement TLS at all, leaving all others vulnerable to attacks that have already been demonstrated many years ago. We observe an increasing trend in support for ISO 15118-2 over the years, reaching 70% of chargers manufactured in 2023. We further notice that most chargers use a decade-old firmware for their HomePlug modems, which could contain vulnerabilities that have been patched since. Finally, we discuss design flaws with the Public Key Infrastructure system used in EV charging, and propose changes to improve the adoption and availability of TLS."
  },
  {
    "id": 3986,
    "year": 2025,
    "title": "STEK Sharing is Not Caring: Bypassing TLS Authentication in Web Servers using Session Tickets",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/hebrok",
    "abstract": "TLS session resumption with session tickets is a widely supported mechanism designed to accelerate TLS connections. It allows a server to use a symmetric Session Ticket Encryption Key (STEK) to encrypt a TLS context in a socalled session ticket, provide the ticket to the client, and later decrypt it during session resumption to obtain the context and seamlessly resume the session. Proper STEK handling is critical and may get complex in scenarios such as virtual hosting, where a single physical server accommodates multiple virtual hosts. Most importantly, these virtual hosts must remain securely isolated, even when they rely on the same TLS STEK for session protection.\nWe demonstrate how TLS session resumption in virtual hosting can introduce session ticket confusion vulnerabilities, potentially enabling the bypass of both server and client authentication. To validate the practicality of these attacks, we analyzed four implementations and conducted a large-scale evaluation. Our findings revealed that all four implementations – Apache, nginx, (Open)LiteSpeed, and Caddy – are vulnerable to client authentication bypasses. In our largescale scans, we identified six clusters of vulnerable providers, including Fastly, which are susceptible to server authentication bypasses. Our results highlight inconsistent isolation of virtual hosts following TLS session resumption, exposing critical security gaps in modern virtual hosting environments."
  },
  {
    "id": 3987,
    "year": 2025,
    "title": "Too Much of a Good Thing: (In-)Security of Mandatory Security Software for Financial Services in South Korea",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/yun",
    "abstract": "Motivated by real-world hacking incidents exploiting Korea Security Applications (KSA) 2.0 from North Korea in 2023, we conducted a comprehensive security investigation into its vulnerabilities. For over a decade, KSA 2.0 has been mandated in South Korea for financial services, making it nearly ubiquitous on PCs nationwide. While designed to enhance security through measures such as secure communication, keylogger prevention, and antivirus protections, KSA 2.0 can bypass sandbox mechanisms, violating modern web security policies.\nOur analysis uncovered critical flaws, including inconsistencies with web browser threat models, improper TLS usage, sandbox violations, and inadequate privacy safeguards. We identified 19 vulnerabilities that expose users to serious risks, such as keylogging, man-in-the-middle attacks, private key leakage, remote code execution, and device fingerprinting. These vulnerabilities were reported to government officials and vendors and have since been patched.\nTo understand the security implications of KSA 2.0, we conducted two user studies. First, our survey of 400 participants revealed widespread KSA 2.0 adoption, with 97% of banking service users having installed it, despite 59% not understanding its functions. Second, our desktop analysis of 48 users' systems found an average of 9 KSA installations per user, with many running outdated versions from 2022 or earlier. These findings suggest potential security concerns arising from the widespread deployment of KSA 2.0 in practice."
  },
  {
    "id": 3988,
    "year": 2025,
    "title": "Unsafe LLM-Based Search: Quantitative Analysis and Mitigation of Safety Risks in AI Web Search",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/luo-zeren",
    "abstract": "Recent advancements in Large Language Models (LLMs) have significantly enhanced the capabilities of AI-Powered Search Engines (AIPSEs), offering precise and efficient responses by integrating external databases with pre-existing knowledge. However, we observe that these AIPSEs raise risks such as quoting malicious content or citing malicious websites, leading to harmful or unverified information dissemination. In this study, we conduct the first safety risk quantification on seven production AIPSEs by systematically defining the threat model, risk type, and evaluating responses to various query types. With data collected from PhishTank, ThreatBook, and LevelBlue, our findings reveal that AIPSEs frequently generate harmful content that contains malicious URLs even with benign queries (e.g., with benign keywords). We also observe that directly querying a URL will increase the number of main risk-inclusive responses, while querying with natural language will slightly mitigate such risk. Compared to traditional search engines, AIPSEs outperform in both utility and safety. We further perform two case studies on online document spoofing and phishing to show the ease of deceiving AIPSEs in the real-world setting. To mitigate these risks, we develop an agent-based defense with a GPT-4.1-based content refinement tool and a URL detector. Our evaluation shows that our defense can effectively reduce the risk, with only a minor cost of reducing available information by approximately 10.7%. Our research highlights the urgent need for robust safety measures in AIPSEs."
  },
  {
    "id": 3989,
    "year": 2025,
    "title": "Generated Data with Fake Privacy: Hidden Dangers of Fine-tuning Large Language Models on Generated Data",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/akkus",
    "abstract": "Large language models (LLMs) have demonstrated significant success in various domain-specific tasks, with their performance often improving substantially after fine-tuning. However, fine-tuning with real-world data introduces privacy risks. To mitigate these risks, developers increasingly rely on synthetic data generation as an alternative to using real data, as data generated by traditional models is believed to be different from real-world data. However, with the advanced capabilities of LLMs, the distinction between real data and data generated by these models has become nearly indistinguishable. This convergence introduces similar privacy risks for generated data to those associated with real data. In this paper, we present an empirical analysis of this underexplored issue by investigating a key question: Does fine-tuning with LLM-generated data enhance privacy, or does it pose additional privacy risks?\" Our study investigates this question by examining the structural characteristics of data generated by LLMs, focusing on two primary fine-tuning approaches: supervised fine-tuning (SFT) with unstructured (plain-text) generated data and self-instruct tuning. In the scenario of SFT, the data is put into a particular instruction tuning format used by previous studies. We use Personal Information Identifier (PII) leakage and Membership Inference Attacks (MIAs) on the Pythia Model Suite and Open Pre-trained Transformer (OPT) to measure privacy risks. Notably, after fine-tuning with unstructured generated data, the rate of successful PII extractions for Pythia increased by over 20%, highlighting the potential privacy implications of such approaches. Furthermore, the ROC-AUC score of MIAs for Pythia-6.9b, the second biggest model of the suite, increases over 40% after self-instruct tuning. Our results indicate the potential privacy risks associated with fine-tuning LLMs using generated data, underscoring the need for careful consideration of privacy safeguards in such approaches."
  },
  {
    "id": 3990,
    "year": 2025,
    "title": "Cloak, Honey, Trap: Proactive Defenses Against LLM Agents",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/ayzenshteyn",
    "abstract": "Recent advances in large language models (LLMs) have enabled autonomous penetration testing tools capable of assessing network security by compromising hosts. However, the same artificial intelligence (AI)  capabilities can empower attackers to automate attacks at scale.\nThis paper presents a cost-effective defense framework using deception and counterattacks to exploit LLM weaknesses—such as biases, memory limitations, and tokenization issues—to disrupt, detect, or neutralize malicious agents. For example, we are able to cloak assets with misdirection, lure, and expose AI adversaries by using LLM-specific honey-tokens and trap agents using loops and other techniques. We also demonstrate several novel exploits such as inducing an agent to execute untrusted code, potentially giving defenders reverse access to the attacker's infrastructure. Overall, our approach introduces 6 strategies and 15 techniques, most of which do not rely on prompt injection.\nWith black box assumptions, we are able to protect a variety of 11 different Capture the Flag (CTF) machines with a 100% success rate. To help the community, we release CHeaT, an open-source tool that automatically inserts traps, cloaks, and honey-tokens seamlessly into network assets. This work establishes a scalable proactive defense paradigm leveraging LLM vulnerabilities to counter AI-driven threats."
  },
  {
    "id": 3991,
    "year": 2025,
    "title": "Big Help or Big Brother? Auditing Tracking, Profiling, and Personalization in Generative AI Assistants",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/vekaria",
    "abstract": "Browser assistants have started to integrate powerful capabilities of GenAI in web browsers to offer functionalities such as question answering, content summarization, and agentic web navigation. These assistants, available today as browser extensions, raise significant privacy concerns because they can track detailed browsing activity (e.g., searches, clicks) and autonomously perform tasks such as form filling. In this paper, we analyze the design and behavior of GenAI browser extensions, focusing on how they collect, process, and share user data, and whether they profile users based on explicit or inferred demographic attributes and interests. We develop a novel prompting framework and perform network traffic analysis to audit the nine GenAI browser assistants for tracking, profiling, and personalization. \nWe find that GenAI browser assistants typically rely on server-side APIs rather than local models, and can be invoked automatically without explicit user interaction. GenAI browser assistants often collect and share full webpage content, including the HTML DOM and user form inputs in some cases, with their first-party servers. Some also share identifiers and user prompts with third-party trackers such as Google Analytics. This data collection and sharing happens even on pages containing sensitive information, such as health records or personal information such as names or social security numbers entered in a web form. Moreover, several GenAI browser assistants infer attributes (e.g., age, gender, income, interests) and use them to personalize responses across browsing contexts. Our findings show that GenAI browser assistants collect and share personal and sensitive information for profiling and personalization, highlighting the need for safeguards as they increasingly mediate web browsing."
  },
  {
    "id": 3992,
    "year": 2025,
    "title": "SOFT: Selective Data Obfuscation for Protecting LLM Fine-tuning against Membership Inference Attacks",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/zhang-kaiyuan",
    "abstract": "Large language models (LLMs) have achieved remarkable success and are widely adopted for diverse applications. However, fine-tuning these models often involves private or sensitive information, raising critical privacy concerns. In this work, we conduct the first comprehensive study evaluating the vulnerability of fine-tuned LLMs to membership inference attacks (MIAs). Our empirical analysis demonstrates that MIAs exploit the loss reduction during fine-tuning, making them highly effective in revealing membership information. These findings motivate the development of our defense. We propose SOFT (Selective data Obfuscation in LLM Fine-Tuning, a novel defense technique that mitigates privacy leakage by leveraging influential data selection with an adjustable parameter to balance utility preservation and privacy protection. Our extensive experiments span six diverse domains and multiple LLM architectures and scales. Results show that SOFT effectively reduces privacy risks while maintaining competitive model performance, offering a practical and scalable solution to safeguard sensitive information in fine-tuned LLMs."
  },
  {
    "id": 3993,
    "year": 2025,
    "title": "Effective PII Extraction from LLMs through Augmented Few-Shot Learning",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/cheng-shuai",
    "abstract": "Large Language Models (LLMs) exhibit strong natural language processing capabilities but also pose significant privacy risks, particularly regarding the leakage of Personally Identifiable Information (PII) embedded in their training data. Existing PII extraction methods suffer from the limitations of low success rates or impracticality for large-scale PII extraction. In this study, we propose a novel PII extraction approach based on enhanced few-shot learning techniques, which achieves efficient and cost-effective PII retrieval without relying on fine-tuning or jailbreaking. We evaluated our approach on both open-source and closed-source LLMs. The experimental results demonstrate that, for non-targeted PII extraction, the attack success rate reaches 48.9%, extracting one authentic PII per two queries at a cost of $0.012 per PII. For targeted PII extraction, our approach surpassed state-of-the-art methods, achieving a 10% to 60% improvement in attack success rates. Additionally, an exploratory analysis of the origins of extracted PII revealed the significant scale of potential privacy breaches. Our work advances the understanding of LLM-induced privacy risks and underscores the vulnerability of partial personal data to large-scale exploitation."
  },
  {
    "id": 3994,
    "year": 2025,
    "title": "Private Investigator: Extracting Personally Identifiable Information from Large Language Models Using Optimized Prompts",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/keum",
    "abstract": "Recent studies on training data extraction attacks have demonstrated significant threats to the language model ecosystem. In a typical machine learning deployment scenario where a pre-trained language model is fine-tuned on users' private data, an adversary may attempt to leak personally identifiable information (PII) memorized by the fine-tuned model. Prior work has demonstrated this privacy risk by inducing a model to output PII in response to handcrafted or outsourced prompts. However, little attention has been given to how a smart adversary will design optimal prompts for successful PII extraction.\nIn this work, we address this knowledge gap. We propose Private Investigator, an attack framework designed to optimize prompts for querying a target language model to extract PII used for its fine-tuning process. We propose a new prompt generation method that aims to craft promising prompts, which induce the target language model to emit as many PII items as possible by exploring diverse contexts. Private Investigator then exploits these generated prompts to conduct extraction attacks. To this end, we develop a prompt selection strategy that prioritizes the most promising prompts for successful PII extraction, taking full advantage of each extraction attack opportunity. In evaluation, we demonstrate that Private Investigator extracts up to 1,254 more email addresses, 634 more phone numbers, and 5,087 more personal names, outperforming existing attacks in extracting PII items."
  },
  {
    "id": 3995,
    "year": 2025,
    "title": "PrivacyXray: Detecting Privacy Breaches in LLMs through Semantic Consistency and Probability Certainty",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/he-jinwen",
    "abstract": "Large Language Models (LLMs) are widely used in sensitive domains, including healthcare, finance, and legal services, raising concerns about potential private information leaks during inference. Privacy extraction attacks, such as jailbreaking, expose vulnerabilities in LLMs by crafting inputs that force the models to output sensitive information. However, these attacks cannot verify whether the extracted private information is accurate, as no public datasets exist for cross-validation, leaving a critical gap in private information detection during inference. To address this, we propose PrivacyXray, a novel framework detecting privacy breaches by analyzing LLM inner states. Our analysis reveals that LLMs exhibit higher semantic coherence and probabilistic certainty when generating correct private outputs. Based on this, PrivacyXray detects privacy breaches using four metrics: intra-layer and inter-layer semantic similarity, token-level and sentence-level probability distributions. PrivacyXray addresses critical challenges in private information detection by overcoming the lack of open-source private datasets and eliminating reliance on external data for validation. It achieves this through the synthesis of realistic private data and a detection mechanism based on the inner states of LLMs. Experiments show that PrivacyXray achieves consistent performance, with an average accuracy of 92.69% across five LLMs. Compared to state-of-the-art methods, PrivacyXray achieves significant improvements, with an average accuracy increase of 20.06%, highlighting its stability and practical utility in real-world applications."
  },
  {
    "id": 3996,
    "year": 2025,
    "title": "JBShield: Defending Large Language Models from Jailbreak Attacks through Activated Concept Analysis and Manipulation",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/zhang-shenyi",
    "abstract": "Despite the implementation of safety alignment strategies, large language models (LLMs) remain vulnerable to jailbreak attacks, which undermine these safety guardrails and pose significant security threats. Some defenses have been proposed to detect or mitigate jailbreaks, but they are unable to withstand the test of time due to an insufficient understanding of jailbreak mechanisms. In this work, we investigate the mechanisms behind jailbreaks based on the Linear Representation Hypothesis (LRH), which states that neural networks encode high-level concepts as subspaces in their hidden representations. We define the toxic semantics in harmful and jailbreak prompts as toxic concepts and describe the semantics in jailbreak prompts that manipulate LLMs to comply with unsafe requests as jailbreak concepts. Through concept extraction and analysis, we reveal that LLMs can recognize the toxic concepts in both harmful and jailbreak prompts. However, unlike harmful prompts, jailbreak prompts activate the jailbreak concepts and alter the LLM output from rejection to compliance. Building on our analysis, we propose a comprehensive jailbreak defense framework, JBShield, consisting of two key components: jailbreak detection JBShield-D and mitigation JBShield-M. JBShield-D identifies jailbreak prompts by determining whether the input activates both toxic and jailbreak concepts. When a jailbreak prompt is detected, JBShield-M adjusts the hidden representations of the target LLM by enhancing the toxic concept and weakening the jailbreak concept, ensuring LLMs produce safe content. Extensive experiments demonstrate the superior performance of JBShield, achieving an average detection accuracy of 0.95 and reducing the average attack success rate of various jailbreak attacks to 2% from 61% across distinct LLMs."
  },
  {
    "id": 3997,
    "year": 2025,
    "title": "Web Execution Bundles: Reproducible, Accurate, and Archivable Web Measurements",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/hantke",
    "abstract": "Recently, reproducibility has become a cornerstone in the security and privacy research community, including artifact evaluations and even a new symposium topic. However, Web measurements lack tools that can be reused across many measurement tasks without modification, while being robust to circumvention, and accurate across the wide range of behaviors in the Web. As a result, most measurement studies use custom tools and varied archival formats, each of unknown correctness and significant limitations, systematically affecting the research's accuracy and reproducibility.\nTo address these limitations, we present WebREC, a Web measurement tool that is, compared against the current state-of-the-art, accurate (i.e., correctly measures and attributes events not possible with existing tools), general (i.e., reusable without modification for a broad range of measurement tasks), and comprehensive (i.e., handling events from all relevant browser behaviors). We also present .web, an archival format for the accurate and reproducible measurement of a wide range of website behaviors. We empirically evaluate WebREC's accuracy by replicating well-known Web measurement studies and showing that WebREC's results more accurately match our baseline. We then assess if WebREC and .web succeed as general-purpose tools, which could be used to accomplish many Web measurement tasks without modification. We find that this is so: 70% of papers discussed in a 2024 web crawling SoK paper could be conducted using WebREC as is, and a larger number (48%) could be leveraged against .web archives without requiring any new crawling."
  },
  {
    "id": 3998,
    "year": 2025,
    "title": "XSSky: Detecting XSS Vulnerabilities through Local Path-Persistent Fuzzing",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/shi-youkun",
    "abstract": "The Cross-Site Scripting (XSS) vulnerability is one of the most prevalent security issues in PHP web applications. To detect XSS vulnerabilities, existing dynamic techniques are commonly hindered by insufficient code exploration capabilities and non-trivial execution environment setup. Comparably, static techniques offer more flexible detection of target code by identifying vulnerable source-sink paths. However, these paths would probably be guarded by custom sanitizers (i.e., implemented to filter malicious inputs). Without establishing reliable sanitizer modeling and analysis techniques, existing work can hardly achieve satisfactory effectiveness.\nIn light of this, we propose a static sanitizer-tolerant XSS detector, named XSSky. Our key insight is that concrete malicious inputs, which evade sanitizers and trigger XSS vulnerabilities, serve as strong proof of a vulnerability's existence. Based on this idea, XSSky attempts to deterministically curate malicious inputs for potentially vulnerable source-sink paths using a path-persistent fuzzing strategy. Specifically, XSSky first converts each given source-sink path into locally executable Programs Under Test (PUTs). Then it uses XSS-oriented exploit primitives and PHP interpreter feedback to generate malicious inputs to efficiently confirm the existence of vulnerabilities. Evaluation results show that XSSky successfully detected 60 previously unknown XSS vulnerabilities (including 31 caused by sanitizer evasion) across 20 popular PHP web applications. Compared with several existing state-of-the-art techniques, XSSky achieved a precision improvement of 11.48%~642.49% and a recall improvement of 87.51%~172.70%. Furthermore, XSSky identified 18 unique vulnerabilities that none of the baselines could detect."
  },
  {
    "id": 3999,
    "year": 2025,
    "title": "ZIPPER: Static Taint Analysis for PHP Applications with Precision and Efficiency",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/wang-xinyi",
    "abstract": "PHP-based web applications constitute a significant portion of the Web infrastructure and are frequently targeted by attackers exploiting taint-style vulnerabilities. While static analysis has emerged as a preferred approach for detecting these vulnerabilities, two major challenges persist: accurately inferring dynamic values from PHP's dynamic features, and efficiently detecting taint vulnerabilities in large-scale applications. This paper presents ZIPPER, a novel static analysis framework that addresses these challenges through two key innovations. First, we introduce a context-sensitive, flow-sensitive value-set algorithm that precisely infers dynamic values by leveraging input validation patterns and framework API characteristics. Second, we implement an efficient, on-demand approach to taint analysis that incorporates object-sensitive and array index-sensitive analyses while maintaining efficiency through sparse data dependency graphs. Evaluation on 429 known taint-style vulnerabilities demonstrates ZIPPER's effectiveness with the highest precision of 68.34% and an impressive recall of 98.14%, outperforming existing approaches. Furthermore, application of ZIPPER to 100 popular PHP applications led to the discovery of 11 previously unknown vulnerabilities, resulting in 6 CVE assignments."
  },
  {
    "id": 4000,
    "year": 2025,
    "title": "The DOMino Effect: Detecting and Exploiting DOM Clobbering Gadgets via Concolic Execution with Symbolic DOM",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/liu-zhengyu",
    "abstract": "DOM Clobbering is a type of code-reuse attack on the web that exploits naming collisions between DOM elements and JavaScript variables for malicious consequences such as Cross-site Scripting (XSS). An important step of DOM clobbering is the usage of \"gadgets\", which are code snippets in existing JavaScript libraries that allow attacker-injected, scriptless HTML markups to flow to sinks. To the best of our knowledge, there is only one prior work on detecting DOM clobbering gadgets. However, it adopts a set of predefined HTML payloads, which fail to discover DOM clobbering gadgets with complex constraints that have never been seen before.\nIn this paper, we present Hulk, the first dynamic analysis framework to automatically detect and exploit DOM Clobbering gadgets. Our key insight is to model attacker-controlled HTML markups as Symbolic DOM—a formalized representation to define and solve DOM-related constraints within the gadgets—so that it can be used to generate exploit HTML markups. Our evaluation of Hulk against Tranco Top 5,000 sites discovered 497 exploitable DOM Clobbering gadgets that were not, and cannot be, identified by prior work. Examples of our findings include popular client-side libraries, such as Webpack and the Google API client library, both of which have acknowledged and patched the vulnerability. We further evaluate the impact of our newly-found, zero-day gadgets through successful end-to-end exploitation against widely-used web applications, including Jupyter Notebook/JupyterLab and Canvas LMS, with 19 CVE identifiers being assigned so far."
  },
  {
    "id": 4001,
    "year": 2025,
    "title": "FIXX: FInding eXploits from eXamples",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/thimmaiah",
    "abstract": "Comprehensively analyzing modern-day web applications to detect different vulnerabilities and related exploits is challenging and time-consuming. Security researchers spend significant time discovering and creating vulnerabilities and exploiting disclosures. However, such disclosures are often limited to single vulnerability instances and do not contain information about other instances of the same vulnerability in the application. In this paper, we propose FIXX, a tool that can automatically find multiple similar exploits from taint-style vulnerabilities inside the same PHP application. FIXX aims to help web application developers detect all possible instances of a known exploit within the program's code. To do this, FIXX combines novel notions of path and graph similarity over graph representations of code. We evaluate FIXX on 32 CVE reports containing cross-site scripting and SQL injection vulnerabilities associated with 19 PHP applications and discover 1097 similar exploitable paths leading to 10 new CVE entries."
  },
  {
    "id": 4002,
    "year": 2025,
    "title": "Careless Retention and Management: Understanding and Detecting Data Retention Denial-of-Service Vulnerabilities in Java Web Containers",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/lian",
    "abstract": "Denial-of-Service (DoS) attacks have long been a major threat to the availability of the World Wide Web. While prior works have extensively studied network-layer DoS and certain types of application-layer DoS, such as Regular Expression DoS (ReDoS), little attention has been paid to memory exhaustion DoS, especially in Java Web containers. Our research target is a special type of memory exhaustion DoS vulnerabilities that retain user data in web containers, which is defined as Data Retention DoS (DRDoS) in this paper. To the best of our knowledge, there are no systematic academic studies of such DRDoS vulnerabilities of Java Web Containers except for a few manually found vulnerabilities in the Common Vulnerabilities and Exposures (CVE) database.\nIn this paper, we design and implement a novel static analysis approach, called DR. D, to detect and assess DRDoS vulnerabilities in Java web containers. Our key insight is to analyze the request handling process of web containers and detect whether client-controlled request data may be retained in the containers, thus leading to DRDoS vulnerabilities. We apply DR. D on four popular open-source Java web containers, discovering that all of them have DRDoS vulnerabilities. Specifically, DR. D finds 25 zero-day, exploitable vulnerabilities. We have responsibly reported all of them to corresponding developers and received confirmations. So far, we have received seventeen CVE identifiers (three of them assigned with high severity). Based on scan results from search engine, e.g., Shodan, we identify that over 1.5 million public IP addresses are hosting vulnerable versions of Java web containers potentially with DRDoS found by DR. D, demonstrating the spread of DRDoS vulnerability."
  },
  {
    "id": 4003,
    "year": 2025,
    "title": "Effective Directed Fuzzing with Hierarchical Scheduling for Web Vulnerability Detection",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/lin-zihan",
    "abstract": "Java web applications play a pivotal role in the modern digital landscape. Due to their widespread use and significant importance, Java web applications have been one prime target for cyber attacks. In this work, we propose a novel directed fuzzing approach, called WDFuzz, that can effectively vet the security of Java web applications. To achieve this, we address two main challenges: (1) efficiently exploring numerous web entries and parameters, and (2) generating structured and semantically constrained inputs. Our WDFuzz approach is two-fold. First, we develop a semantic constraint extraction technique to accurately capture the expected input structures and constraints of web parameters. Second, we implement a hierarchical scheduling strategy that evaluates the potential of each seed to trigger vulnerabilities and prioritizes the most promising seeds. In our evaluation against 15 real-world Java web applications, WDFuzz achieved a 92.6% recall rate in the known vulnerability dataset, finding 3.2 times more vulnerabilities and detecting them 7.1 times faster than the state-of-the-art web fuzzer. We also identified 92 previously unknown vulnerabilities, with 4 CVE IDs and 15 CNVD IDs assigned to date."
  },
  {
    "id": 4004,
    "year": 2025,
    "title": "Towards Automatic Detection and Exploitation of Java Web Application Vulnerabilities via Concolic Execution guided by Cross-thread Object Manipulation",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/huang-xinyou",
    "abstract": "Java Web applications are of great importance for information systems deployed across critical sections of our society as demonstrated in the severe impacts caused by notorious log4j vulnerability. One major challenge in detecting Java Web Application vulnerabilities is cross-thread dataflows, which are caused by shared Java objects and triggered by multiple web requests in the same session. To the best of our knowledge, none of the prior works can handle such cross-thread dataflows in Java Web applications. \nIn this paper, we design and implement the first framework, called JAEX, to automatically detect and exploit Java Web Application vulnerabilities via concolic execution guided by so-called Cross-thread Object Manipulation. Our key insight is that cross-thread dataflows can be triggered by manipulation of shared Java objects using different requests, thus guiding concolic execution to reach the sink and generate exploits. We also evaluate JAEX on popular Java applications, which discovers 35 zero-day vulnerabilities. We responsibly disclosed all the vulnerabilities to their vendors and received acknowledgments for all of them."
  },
  {
    "id": 4005,
    "year": 2025,
    "title": "Efficient Batchable Secure Outsourced Computation: Depth-Aware Arithmetization of Common Primitives for BFV & BGV",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/vos",
    "abstract": "Homomorphic encryption enables secure outsourced computation, in which computations on sensitive data can be confidentially outsourced to another party. Homomorphic encryption cryptographically guarantees confidentiality while allowing an evaluator to manipulate the encrypted data using additions and multiplications. However, a remaining challenge is to translate complex computations into efficient circuits consisting of only additions and multiplications. We refer to this problem as arithmetization. The objective in arithmetization has typically been to minimize the number of multiplications (multiplicative size), as multiplications in most secure computation techniques are significantly more expensive than additions. However, the multiplicative depth of a circuit arguably plays an even more important role in deciding the computational cost: For homomorphic encryption schemes like BFV and BGV, it determines the choice of cryptographic parameters that allow evaluating the circuit without requiring expensive bootstrapping operations. We argue that arithmetization should be treated as a multi-objective minimization problem, in which a trade-off can be made between a circuit's multiplicative size and depth. We present efficient depth-aware arithmetization methods for many primitive operations such as exponentiation, univariate functions, equality checks, comparisons, and ANDs and ORs, which further take into account that squaring can be cheaper than multiplying, and we study how to compose these operations. We show that our circuits can outperform more recent homomorphic encryption schemes like TFHE, which can perform significantly faster homomorphic operations but only on one input at a time by batching several inputs into one ciphertext."
  },
  {
    "id": 4006,
    "year": 2025,
    "title": "Arbitrary-Threshold Fully Homomorphic Encryption with Lower Complexity",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/chang-yijia-encryption",
    "abstract": "Threshold fully homomorphic encryption (ThFHE) enables multiple parties to compute functions over their sensitive data without leaking data privacy. Most of existing ThFHE schemes are restricted to full threshold and require the participation of all parties to output computing results. Compared with these full-threshold schemes, arbitrary threshold (ATh)-FHE schemes are robust to non-participants and can be a promising solution to many real-world applications. However, existing AThFHE schemes are either inefficient to be applied with a large number of parties and a large data size, or insufficient to tolerate all types of non-participants. In this paper, we propose an AThFHE scheme to handle all types of non-participants with lower complexity over existing schemes. At the core of our scheme is the reduction from AThFHE construction to the design of a new primitive called approximate secret sharing (ApproxSS). Particularly, we formulate ApproxSS and prove the correctness and security of AThFHE on top of arbitrary-threshold (ATh)-ApproxSS's properties. Such a reduction reveals that existing AThFHE schemes implicitly design ATh-ApproxSS following a similar idea called \"noisy share\". Nonetheless, their ATh-ApproxSS design has high complexity and become the performance bottleneck. By developing ATASSES, an ATh-ApproxSS scheme based on a novel \"encrypted share'' idea, we reduce the computation (resp. communication) complexity from O(N^2K) to O(N^2+K) (resp. from O(NK) to O(N+K)). We not only theoretically prove the (approximate) correctness and security of ATASSES, but also empirically evaluate its efficiency against existing baselines. Particularly, when applying to a system with one thousand parties, ATASSES achieves a speedup of 3.83x – 15.4x over baselines."
  },
  {
    "id": 4007,
    "year": 2025,
    "title": "Leuvenshtein: Efficient FHE-based Edit Distance Computation with Single Bootstrap per Cell",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/legiest",
    "abstract": "This paper presents a novel approach to calculating the Levenshtein (edit) distance within the framework of Fully Homomorphic Encryption (FHE), specifically targeting third-generation schemes like TFHE. Edit distance computations are essential in applications across finance and genomics, such as DNA sequence alignment. We introduce an optimised algorithm that significantly reduces the cost of edit distance calculations called Leuvenshtein. This algorithm specifically reduces the number of programmable bootstraps (PBS) needed per cell of the calculation, lowering it from approximately 94 operations—required by the conventional Wagner-Fisher algorithm—to just 1. Additionally, we propose an efficient method for performing equality checks on characters, reducing ASCII character comparisons to only 2 PBS operations. Finally, we explore the potential for further performance improvements by utilising preprocessing when one of the input strings is unencrypted. Our Leuvenshtein achieves up to 278x faster performance compared to the best available TFHE implementation and up to 39x faster than an optimised implementation of the Wagner-Fisher algorithm. Moreover, when offline preprocessing is possible due to the presence of one unencrypted input on the server side, an additional 3x speedup can be achieved."
  },
  {
    "id": 4008,
    "year": 2025,
    "title": "Engorgio: An Arbitrary-Precision Unbounded-Size Hybrid Encrypted Database via Quantized Fully Homomorphic Encryption",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/bian",
    "abstract": "This work proposes an encrypted hybrid database framework that combines vectorized data search and relational data query over quantized fully homomorphic encryption (FHE). We observe that, due to the lack of efficient encrypted data ordering capabilities, most existing encrypted database (EDB) frameworks do not support hybrid queries involving both vectorized and relational data. To further enrich query expressiveness while retaining evaluation efficiency, we propose Engorgio, a hybrid EDB framework based on quantized data ordering techniques over FHE. Specifically, we design a new quantized data encoding scheme along with a set of novel comparison and permutation algorithms to accurately generate and apply orders between large-precision data items. Furthermore, we optimize specific query types, including full table scan, batched query, and Top-k query to enhance the practical performance of the proposed framework. In the experiment, we show that, compared to the state-of-the-art EDB frameworks, Engorgio is up to 28x–854x faster in homomorphic comparison, 65x–687x faster in homomorphic sorting and 15x–1,640x faster over a variety of end-to-end relational, vectorized, and hybrid SQL benchmarks. Using Engorgio, the amortized runtime for executing a relational and hybrid query on a 48-core processor is under 3 and 75 seconds, respectively, over a 10K-row hybrid database."
  },
  {
    "id": 4009,
    "year": 2025,
    "title": "Qelect: Lattice-based Single Secret Leader Election Made Practical",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/wang-yunhao",
    "abstract": "In a single secret leader election (SSLE) protocol, all parties collectively and obliviously elect one leader. No one else should learn its identity unless it reveals itself as the leader. The problem is first formalized by Boneh et al. (AFT '20), which proposes an efficient construction based on the Decision Diffie-Hellman (DDH) assumption. Considering the potential risk of quantum computers, several follow-ups focus on designing a post-quantum secure SSLE protocol based on pure lattices or fully homomorphic encryption. However, no concrete benchmarks demonstrate the feasibility of deploying such heavy cryptographic primitives.\nIn this work, we present Qelect, the first practical constant-round post-quantum secure SSLE protocol. We first adapt the commitment scheme in Boneh et al. (AFT '23) into a multi-party randomizable commitment scheme, and propose our novel construction based on an adapted version of ring learning with errors (RLWE) problem. We then use it as a building block and construct a constant-round single secret leader election (crSSLE) scheme. We utilize the single instruction multiple data (SIMD) property of a specific threshold fully homomorphic encryption (tFHE) scheme to evaluate our election circuit efficiently. Finally, we built Qelect from the crSSLE scheme, with performance optimizations including a preprocessing phase to amortize the local computation runtime and a retroactive detection phase to avoid the heavy zero-knowledge proofs during the election phase. Qelect achieves asymptotic improvements and is concretely practical. We implemented a prototype of Qelect and evaluated its performance in a WAN. Qelect is at least two orders of magnitude faster than the state-of-the-art."
  },
  {
    "id": 4010,
    "year": 2025,
    "title": "GlitchFHE: Attacking Fully Homomorphic Encryption Using Fault Injection",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/mankali",
    "abstract": "Fully homomorphic encryption (FHE) enables outsourced computation on encrypted data, thereby ensuring confidentiality by design. However, a critical vulnerability remains for FHE: cloud-based adversaries could tamper with the encrypted data itself, undermining the integrity of FHE applications. Fault-injection attacks (FIAs) are particularly concerning, as they allow attackers to directly manipulate the encrypted data during computation within FHE hardware.\nHere, we present the first in-depth study of FIAs on FHE accelerators. We identify and overcome key challenges for such attacks, namely (i) understanding when and where to glitch encrypted data across different FHE applications and formats, (ii) limiting the number of required faults, and (iii) controlling the errors' impact on the final, decrypted output. We develop GlitchFHE, an analytical framework that guides toward such adversarial security assessment of FHE applications against FIAs. We run through a set of timely and relevant case studies, covering established applications like image processing, neural networks, and polynomial evaluation, for the prominent CKKS and BFV schemes, both at the analytical/software level and the physical/real-world level. Ultimately, we show that attacks on data integrity are a serious threat for FHE. Our work is equally relevant for real-world attackers and to educate FHE developers on this largely overlooked threat. We release GlitchFHE and our case studies at https://doi.org/10.5281/zenodo.15615934."
  },
  {
    "id": 4011,
    "year": 2025,
    "title": "H2O2RAM: A High-Performance Hierarchical Doubly Oblivious RAM",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/zheng",
    "abstract": "The combination of Oblivious RAM (ORAM) with Trusted Execution Environments (TEE) has found numerous real-world applications due to their complementary nature. TEEs alleviate the performance bottlenecks of ORAM, such as network bandwidth and roundtrip latency, and ORAM provides general-purpose protection for TEE applications against attacks exploiting memory access patterns. The defining property of this combination, which sets it apart from traditional ORAM designs, is its ability to ensure that memory accesses, both inside and outside of TEEs, are made oblivious, thus termed doubly oblivious RAM (O2RAM). Efforts to develop O2RAM with enhanced performance have been ongoing.\nIn this work, we propose H2O2RAM, a high-performance doubly oblivious RAM construction. The distinguishing feature of our approach, compared with the existing tree-based doubly oblivious designs, is its first adoption of the hierarchical framework that enjoys inherently better data locality and parallelization. While the latest hierarchical solution, FutORAMa, achieves concrete efficiency in the classic client-server model by leveraging a relaxed assumption of sublinear-sized client-side private memory, adapting it to our scenario poses challenges due to the conflict between this relaxed assumption and our doubly oblivious requirement. To this end, we introduce several new efficient oblivious components to build a high-performance hierarchical O2RAM (H2O2RAM). We implement our design and evaluate it on various scenarios. The results indicate that H2O2RAM reduces execution time by up to ∼10^3 times and saves memory usage by a factor of 5∼44 compared with state-of-the-art solutions."
  },
  {
    "id": 4012,
    "year": 2025,
    "title": "OBLIVIATOR: OBLIVIous Parallel Joins and other OperATORs in Shared Memory Environments",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/mavrogiannakis",
    "abstract": "We introduce oblivious parallel operators designed for both non-foreign key and foreign key equi-joins. Obliviousness ensures nothing is revealed about the data besides input/output sizes, even against a strong adversary that can observe memory access patterns. Our solution achieves this by combining trusted hardware with efficient oblivious primitives for compaction and sorting, and two oblivious algorithms: (i) an oblivious aggregation tree, which can be described as a variation of the parallel prefix sum, customized for trusted hardware, and (ii) a novel algorithm for obliviously expanding the elements of a relation. In the sequential setting, our oblivious join performs 4.6x - 5.14x faster than the prior state-of-the-art solution (Krastnikov et al., VLDB 2020) on data sets of size n=2^24. In the parallel setting, our algorithm achieves a speedup of up to roughly 16x over the sequential version, when running with 32 threads (becoming up to 80x compared to the sequential algorithm of Krastnikov et al.). Finally, our oblivious operators can be used independently to support other oblivious relational database queries, such as oblivious selection and oblivious group-by."
  },
  {
    "id": 4013,
    "year": 2025,
    "title": "Efficient Ranking, Order Statistics, and Sorting under CKKS",
    "publication": "USENIX Sec",
    "paper": "https://www.usenix.org/conference/usenixsecurity25/presentation/mazzone",
    "abstract": "Fully Homomorphic Encryption (FHE) enables operations on encrypted data, making it extremely useful for privacy-preserving applications, especially in cloud computing environments. In such contexts, operations like ranking, order statistics, and sorting are fundamental functionalities often required for database queries or as building blocks of larger protocols. However, the high computational overhead and limited native operations of FHE pose significant challenges for an efficient implementation of these tasks. These challenges are exacerbated by the fact that all these functionalities are based on comparing elements, which is a severely expensive operation under encryption.\nPrevious solutions have typically based their designs on swap-based techniques, where two elements are conditionally swapped based on the results of their comparison. These methods aim to reduce the primary computational bottleneck: the comparison depth, which is the number of non-parallelizable homomorphic comparisons in the algorithm. The current state of the art solutions for sorting by Lu et al. (IEEE S&P '21) and Hong et al. (IEEE TIFS 2021), for instance, achieve a comparison depth of log^2 N and k logk^2N, respectively.\nIn this paper, we address the challenge of reducing the comparison depth by shifting away from the swap-based paradigm. We present solutions for ranking, order statistics, and sorting, that achieve a comparison depth of up to 2 (constant), making our approach highly parallelizable and suitable for hardware acceleration. Leveraging the SIMD capabilities of the CKKS FHE scheme, our approach re-encodes the input vector under encryption to allow for simultaneous comparisons of all elements with each other. The homomorphic re-encoding incurs a minimal computational overhead of O(log N) rotations. Experimental results show that our approach ranks a 128-element vector in approximately 5.76s, computes its argmin/argmax in 12.83s, and sorts it in 78.64s."
  }
]